<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>当然我在扯淡</title>
<link>http://www.yinwang.org/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Thu, 26 May 2016 11:03:31 +0800</lastBuildDate>
<item>
<title>我的 tweet 系统</title>
<link>http://yinwang.org/blog-cn/2016/05/25/my-tweet</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;我的 tweet 系统&lt;/h2&gt;&lt;p&gt;有时候灵光乍现，却又不想写成完整的文章，所以尝试过使用 twitter 和微博，然而最终我发现它们有各种缺点。所以我想出一个圡办法：自己手动整理一个列表，把想说的放进去，加上日期，就算是我的 tweet 系统。&lt;/p&gt;&lt;p&gt;这个系统有一系列强大的功能：无法 follow 或订阅，不能评论，不方便转载。可以随意修改，随意排序，不限字数。心诚的人必须主动来这里看，理解更深入，自动过滤心理不正常的人，等等…… 这是迄今为止最好最完善的 social network 系统。本系统的座右铭是：我想写 tweet，所以我就写了。你们想看就看，不想看就算了。&lt;/p&gt;&lt;p&gt;请点击&lt;a href=&quot;http://www.yinwang.org/tweet.html&quot;&gt;这里&lt;/a&gt;访问我的 tweet 系统。&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">my-tweet</guid>
<pubDate>Wed, 25 May 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>正面思维的误区</title>
<link>http://yinwang.org/blog-cn/2016/05/22/positive-thinking</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;正面思维的误区&lt;/h2&gt;&lt;p&gt;有些人喜欢宣扬所谓“正面思维”（positive thinking），而不顾事实真相。每当你批评一些事情，他们就会拿出正面思维这个万能法宝来压制你，说：“你这人怎么这么 negative？要 positive，要看到事物好的方面才对！”&lt;/p&gt;&lt;p&gt;比如这次有人说：“你把之前每个东家都喷了一遍。这里面难道就没有你自己的问题吗？” 我只能说，如果它们真的就是那么恶劣，那我有什么办法呢？由于没来得及选择，连续进入好几家问题公司，其实很正常。我不是一个完美的人，然而在公司的人际关系上，我可以说是仁至义尽了。我没架子，容易相处，这点很多同事都知道，甚至厨师和扫地大妈都知道。然而我绝对不是好欺负的。&lt;/p&gt;&lt;p&gt;像 Coverity，Sourcegraph 这类极品，欺压员工，无耻利用，行为极其恶劣，难道我还能说它们好话不成？我的心理不知道要扭曲到什么程度，才能发掘出他们好的地方来。这些公司的恶劣行径，严重损害了员工的身心健康，伤害了他们的事业发展，在某种程度上可以说是犯罪行为，没有把这些人告上法庭就已经不错了。关于这些公司，有很多骇人听闻的细节我还没有说出来，我保留对这些进行进一步揭露的权利。&lt;/p&gt;&lt;p&gt;然而这不是今天的主题，我今天想谈的是所谓“正面思维”。很多人没有意识到，盲目的正面思维，其实是一个很严重的问题。正面并没有什么问题，快乐是好事，然而它们应该是结果，而不应该是目的。如果一个社会需要刻意去提倡“正面”和“快乐”，去宣扬它们，通过舆论压力或者暴力，迫使每个人都“正面思维”，那就有严重问题了。文化大革命的时候，人们的思维可真是很正面啊，各种歌颂…… 你要是敢说任何不好听的话，立即被打成反革命右派。可是今天，我发现这种文革似的“正面思潮”，又有抬头之势。其实，它在美国已经泛滥成灾，以至于有人专门写了一本书来批判这种“正面思维”：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Bright-sided-Relentless-Promotion-Positive-Undermined-ebook/dp/B002SKDGQ0&quot;&gt;
&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-28fd151402f7b345.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/200&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;当你遇到困难的时候，美国人喜欢说：“别担心，一切都会好起来的……”，“要专注于事物好的方面……”，“只要你努力，就会有好结果……”，“困难是临时的，面包会有的，Go 语言会改进的……”，“危机会过去的，经济会持续增长的⋯⋯” “美国是世界上最伟大的国家，上帝保佑美利坚……” 看看这本书，你就知道这些说法有多大的欺骗性。整个美国，其实都沉浸在人们不切实际的“正面幻想”之中。&lt;/p&gt;&lt;p&gt;“正面思维”跟美国的剥削制度和资本主义，是密不可分的。有人说美国是民主，自由的国家，那只是口号而已。美国其实是一个剥削和压迫非常严重的国家，美国人民并不幸福。实际上，正面思维就是剥削者想出来，用于安抚人民，让人安心做廉价劳动力的工具。一些所谓“成功人士”，总是鼓励大家要上进，要看到事物好的方面，要安于现状，一步一步奋斗，往上爬！然后呢，自己却在背后玩弄权术，利用人们的正面不设防的心理，招摇撞骗，投机取巧，踩在他人头上，压低雇员工资，让别人加班加点，自己却不劳而获，靠着一口官腔（所谓“领导才能”）飞黄腾达。&lt;/p&gt;&lt;p&gt;在美国，正面思维是一个产业。号称“快乐民族”的美国人，每年消耗掉世界上三分之二的抗抑郁症药物。美国出产许多的所谓人生导师，职业教练，宗教领袖，知心大妈，心理医生，鸡汤和蛇油商人…… 他们的谋生方式，就是教你要怎么正面思维，要怎么“奋斗”，要怎么把社会的不合理，不公平，都想成自己的思想有问题，或者自己不够努力，不够好。&lt;/p&gt;&lt;p&gt;美国的正面思维产业是如此的发达，哈佛大学甚至因此创造了一门红极一时的课程，叫做『&lt;a href=&quot;https://positivepsychologyprogram.com/harvard-positive-psychology-course-1504&quot;&gt;正面心理学&lt;/a&gt;』（所谓“幸福课”）。这课程的&lt;a href=&quot;https://www.youtube.com/watch?v=K8qpn6kNfPc&amp;amp;list=PL28D16304BA57DD7E&quot;&gt;视频&lt;/a&gt;我看了一阵子，发现课程进行到快一半了，教授没有传授任何实质性的东西，他只是反反复复地在说服你，为什么你应该学正面心理学……&lt;/p&gt;&lt;p&gt;你知道为什么自从小布什以来，美国的正面思维产业越来越红火了吗？因为小布什本来就是拉拉队长（cheerleader）出生，是给大家加油鼓气的。小布什要求美国人民，一定要正面，一定要认为美国是世界上最伟大的国家 ;)&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-8c0c6feb3e7cffc8.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/300&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;在 Cornell 和 Google 的时候，我饱尝了盲目的正面思维所带来的危害。Cornell 这学校有个奇怪的现象，跟同学聊天时，如果你想打听某个教授的学术或者为人，得到的回应必然是：“他好牛！” “好厉害！” “非常聪明！” 之类的语言。你听不到任何人说不好的方面，比如：“他讲课像是背书”，“他的研究没有实质意义”，“他的学生都很累”之类的负面信息。所以在 Cornell，你无法从同学那里得到任何信息，每个人都饱尝了与某些教授打交道的辛酸，可是每个人都把那些秘密藏在心底。他们对你说：“嗯，他很厉害，他的研究很伟大……”&lt;/p&gt;&lt;p&gt;这种铺天盖地的正面信息，是无益甚至有害的。如果你只听到正面的声音，那你就无法做出正确的决定。这就像你在网上买东西，如果只看正面的评价，那你很可能买到有问题的商品。正确的作法，应该是正面负面的信息都看。特别是负面的信息，必须仔细看。它们可以告诉你，这个产品有哪些烦扰其他人的缺陷，会不会影响到你的使用。一般我在网上如果被一个产品吸引，我首先看的是一颗星的评价，因为给一颗星的人，一般是恨透了这个产品。当然里面有些无知或者不知好歹的人，你可以忽略，但是大部分人会告诉你，他们不喜欢这个产品的具体原因。我很会分析这些评价，这就是为什么我家里的很多产品，都是非常好用的。&lt;/p&gt;&lt;p&gt;Cornell 这个学校，就是缺乏这种有益的负面评价。你总是听说每个教授都很牛，人都很好，…… 然而当你真正跟他们接触，就发现事实并非如此。你一次次的跳入火坑，然后才开始希望，要是开头的时候听到一些负面的信息，该多好。可是每个人表面上都是那么的 positive，每个人都认为 negative 是错误的心理，每个人都在强装笑容。这是一个多么可怕的地方！&lt;/p&gt;&lt;p&gt;Google 的气氛非常类似于 Cornell。Google 员工吃饭时，谈论每个项目或者团队，都带着玫瑰色的光环，仿佛 Google 做的一切都是美好的，先进的，有前途的。在每个星期的 TGIF（Tell Googlers It&#39;s Friday）大会上，founder 们都在大讲台上宣布各种好消息，而对坏消息闭口不提或者一笔带过。下面的 Google 员工们群情激昂，对一些小不点的事情各种欢呼鼓掌尖叫，跟传销大会似的。事实上，Google 内部有许多穷途末路的项目。表面看上去很厉害的样子，等你进去才发现是死路一条，垂死挣扎。项目领导平时紧紧张张，生怕上面来人调查，把自己的项目杀掉。在公司内部搞各种政治，东拉西扯建立各种依赖关系，这样自己的项目才得以生存。&lt;/p&gt;&lt;p&gt;这种虚伪的正面氛围，存在于很多的美国公司，员工每个星期都被领导打各种鸡血针，保持激昂向上的状态。我曾经跟英国，法国，德国，意大利，瑞典，波兰等国家的同事聊天，他们都暗自嘲笑美国人，说过度正面，传销式的群情激昂，吃错药了一样，确实是美国文化的一大特色。欧洲人比较务实，不搞这套，好的就说好，坏的就批评或者嘲笑，直率坦荡。当然，我不能说所有美国公司都有这种问题，所以我仍然存在希望，找到稍微实在点的公司。&lt;/p&gt;&lt;p&gt;盲目的正面思维，忽略问题，并不能解决问题。你必须看到负面的事实，才有可能避免困难，得到好的结果。正面思维和浮夸的气氛，正在侵蚀 Google 和很多其它美国公司。为了看清楚正面思维的危害性，我推荐你看看这本书，名叫『负面思维的威力』：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://www.amazon.com/Power-Negative-Thinking-Unconventional-Achieving/dp/054402771X&quot;&gt;
&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-f879b3a439066457.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/200&quot;&gt;&lt;/a&gt;&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">positive-thinking</guid>
<pubDate>Sun, 22 May 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>文章更新通知</title>
<link>http://yinwang.org/blog-cn/2016/05/19/update</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;文章更新通知&lt;/h2&gt;&lt;p&gt;有些人可能看过我之前写的『&lt;a href=&quot;http://www.yinwang.org/blog-cn/2012/08/01/interpreter&quot;&gt;怎样写一个解释器&lt;/a&gt;』。之前的文章虽然深入浅出，然而它仍然存在一些废话和误导。文章中实现的程序语言，缺少一些重要的构造（比如 let），使得例子程序，特别是关于 static/dynamic scoping 部分的例子代码，比较难看清楚。&lt;/p&gt;&lt;p&gt;所以最近更新并且提炼了这篇文章，使得它更加精炼，深入和易懂。新的文章比起以前的，使用了一些完全不同的思维方法。所以就算你以前看过这篇文章，我觉得它都值得再看一遍。没有看我微博的人，可能不知道文章有更新，所以在这里告知一下。&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">update</guid>
<pubDate>Thu, 19 May 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>未来计划</title>
<link>http://yinwang.org/blog-cn/2016/05/14/future</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;未来计划&lt;/h2&gt;&lt;p&gt;生活就像一出戏，一环扣着一环。很多人对我说，我是一个非常有才华的人，只是没有被放到合适的位置。他们说的是实话。虽然我通过努力，得到了精华的知识和独立深入的思维能力，然而由于一些早期的错误抉择，再加上遇到一些错误的人，我的生活一度陷入困境。直到现在缓过气来，我才可以开始考虑一个更好的未来。&lt;/p&gt;&lt;h3&gt;曲折的过去&lt;/h3&gt;&lt;p&gt;我的第一个错误，来自于一个不切实际的浪漫幻想。我把爱情看得太简单，太容易，太伟大。我错误地改变了我爱的女孩的生活轨迹。这一个错误，我用了十年的时间来偿还，同时又导致了另外一系列的错误，以至于我颠沛流离。&lt;/p&gt;&lt;p&gt;我的第二个错误，是进入 Google 做实习。本来就不喜欢那里，为了养家糊口挣点小钱，下一年却还去同一个地方，结果弄得自己很不舒服，而且失去了其它更好的机会。&lt;/p&gt;&lt;p&gt;我的第三个错误，在于离开 Indiana 大学之后，进入 Coverity 工作。虽然 Glassdoor 上面恶评如潮，说那里“氛围有毒”，我却因为 Coverity 似乎有很强的技术实力，拥有像 NASA，Boeing，Lockheed Martin 一类的高大上客户，而对这个公司产生了尊敬。结果呢，我花了几个月的时间，修补别人过去一年里留下来的各种蹊跷 bug。加班加点的工作，人家却完全不拿你当个东西。一知半解的所谓 architect，从来不写代码，却指手画脚，不切实际地给你设置每个任务的“时间上限”。拿着低廉的薪水，还被 manager 各种蛮横威胁，慢一点就要炒你鱿鱼的味道。&lt;/p&gt;&lt;p&gt;离开 Coverity 之后，困境却远远没有结束。我饱尝了三藩市区各种 startup 面试的肤浅和无理。也有些公司（比如 Twitter）面试一切都很顺利，最后却莫名其妙没有 offer。以至于两个月过去了，一个 offer 都没有拿到。学生签证毕业后的“OPT”，最多只能有三个月没有工作。Coverity 的 founder 倒不是个坏人，在他的介绍帮助下，我找到了下一份工作，在一个做语音 app 的公司。这公司也是个肤浅小店，而且人家连“Software Engineer”的职位都没给我，让我去做被公司里的 iOS 和 Android developer 都看不起的“Data Engineer”的工作。于是饱尝了所谓“Data Scientist”的辛酸，折腾 Neo4J 这类垃圾数据库的痛苦。每次跟那些 app 程序员聊天，别人都显示出一副“你会写代码吗？”一样的神情……&lt;/p&gt;&lt;p&gt;最后就遇到了 Sourcegraph 的两位 founder。开头受到如此“三顾茅庐”的礼遇，采用了我精深的代码，而且两位貌似比较懂行，所以以为能得到应有的尊重。哪知道花了两个月把 RubySonar 做完之后才发现，人家可没把你当回事，反而说你 performance 有问题，说你做这东西“居然花了两个月”，找借口开掉！我让你们自己做，做个两年看能不能做出来？不理解，不满意，也不能用正确的方式表达出来，却在我背后把键盘敲得猛响发泄。我察觉到有人不爽，还礼貌的问，我是不是有些地方做得不够好？结果跟我说没事，然后继续在背后使闷气……&lt;/p&gt;&lt;p&gt;其实这两位 founder 都是 Go 语言的拥鳖。整个 server 是 Go 语言写的，乱得不成样子，各种 bug，却仍然因为自己用 Go 语言而自豪，鄙视 Python，Ruby，Java 和所有其它语言。自己选错了工具，却写 blog 把 AngularJS 骂了一顿，说换用了 Go 的 HTML template 之后很开心，而其实 Go HTML template 其实是个烂东西。开源会议的时候去给 Go 语言的团队捧场，使用“live blog”的方式给 Go 语言团队各种有失身份的吹牛拍马。每次有 Stanford 学生来面试，founder 们可真是兴奋异常，校友来校友去的。虽然我的职位叫做“Lead Researcher”，可经常是面试的“Stanford校友”来了，跟我连个正式的介绍都没有。有次一个 Stanford 本科生来面试，跟 founder 们说：“我上过一门 CSxxxx 的课。” 我在旁边听到了，好奇这是什么有趣的课，就问：“CSxxxx 是什么？” 本科生瞟了我一眼，答：“哦，这是 Stanford 的一门课，叫做‘算法’”。言下之意就是我们 Stanford 的人会算法，算法是什么，你知道么？最后招了一个 Stanford 的学生来实习，想给 Clojure 做一个类似 PySonar 的类型推导，也不虚心请教，自以为是，最后一筹莫展，连门都没有摸到就结束了。&lt;/p&gt;&lt;p&gt;Sourcegraph founder 们的忽然翻脸，最后才导致了我第一次使用自己的 blog 发出求救信息。跟 OPT 不一样，H1-b 签证有苛刻的限制，一旦工作突然中止，外国人不可能有足够时间找到下一份工作，他们必须在很短时间内离境。美国名牌大学的学生，做出如此卑劣的事情，由此可见美国的“世界一流大学”，树造的是什么样的人。罗素（Bertrand Russell）在一百年前就说，美国是商人开的国家，美国的教授只不过是商人的仆人。在美国待得越久，我对此的感悟就越深。&lt;/p&gt;&lt;p&gt;幸好当时许多的同胞，伸出了援助的双手，让我感觉到中华民族作为一家人的温暖。在此我要感谢在那段时间帮助和鼓励过我的所有人，才让我顺利走到了今天。&lt;/p&gt;&lt;p&gt;由于时间紧迫，我迅速拿到两个 offer 之后，就从其中选择了一个，却仍然没能避免必须飞回国内重新签证的麻烦。谁知我到了国内感觉很好，就不想再回到美国，可惜当时有重任在身，不得已又回来了。这在当时看来是一个不错的 offer，它解决了我的燃眉之急，我顺利的完成了为前女友付完学费的任务。&lt;/p&gt;&lt;h3&gt;更好的未来&lt;/h3&gt;&lt;p&gt;所以很多人说，我没有处于合适的地位，确实是这样。一方面我有天赋才能，有名师指点。另一方面我的生活却支离破碎，没有自由。有谁知道在这“天才”的光环下，有多少的苦楚。虽然解决了危机，然而我的生活却远远没有开始。我的收入远远落后于跟我同等水平，甚至刚毕业的人。收入除去美国的重税和高房租，欠下的车贷，基本的生活费用，过了一年我的账上仍然是负数。现有的收入远远无法满足在这个地区过上基本生活的需要，连房子的首付都付不起。有些人期望我对社会做出“贡献”，可是社会给了我什么呢？这样的生活还怎么做贡献？谁是社会？什么是贡献？&lt;/p&gt;&lt;p&gt;我很感谢帮助我找到现在工作的人，我也喜欢我的队友们，但是由于各种原因，我不觉得现在的公司能够发挥我应有的作用。虽然有深入的见解，我却没有处于让它们可以被采纳的地位。做出了大的贡献，也没有得到相应的奖励和加薪。这就是我的现状，也许你没有想到。&lt;/p&gt;&lt;p&gt;所以我决定在世界范围之内寻找新的机会和合作伙伴。我已经拿到不错的 offer，但我可能漏掉了考虑某些很好的公司。所以还是希望扩展一下搜索范围，开阔一下眼界，走出更好的下一步。如果你理解我说的一些东西，你有一颗类似的心，自知却不傲慢，踏踏实实做事，你有比较好的机会或者合作项目，请&lt;a href=&quot;mailto:shredderyin@gmail.com&quot;&gt;联系我&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;由于这么多次的惨痛经历，我不再想为 startup 公司工作，除非是作为 founder。我尊敬一些成熟低调的大公司，比如 IBM，Intel，AMD，微软，Oracle（Sun）…… 对 Google 和 Tesla 这样年轻浮躁的公司不感兴趣。我感兴趣的领域包括系统平台，数据库，程序语言，编译器，运行时系统（比如 JVM），并行和分布式计算，硬件设备，以及一切跟性能相关的问题。&lt;/p&gt;&lt;p&gt;当然我也欢迎创业的合作伙伴和投资。我最近对硬件相关的领域和物联网（IoT）比较感兴趣，希望把我的技能延伸到硬件上面。但合作的范围不限于此。&lt;/p&gt;&lt;p&gt;另外有人可能误解了我工作的方式，以为我是一个理想主义者。跟我工作过的人都知道，我其实是个非常实际的人，我不做不可能有用处的事情。我把用户的需要放在首要的位置，而不是一意孤行去做自己觉得“优美”或者“酷”的产品。在过去我遇到过一些真正的理想主义者，他们用非常炫丽难懂的做法，来实现用户不需要的功能，让用户糊涂困扰。所以我不希望再跟理想主义者一起工作 :P&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">future</guid>
<pubDate>Sat, 14 May 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>关于博文的自愿付费方式</title>
<link>http://yinwang.org/blog-cn/2016/04/13/pay-blog</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;关于博文的自愿付费方式&lt;/h2&gt;&lt;p&gt;曾经有很多人跟我建议，给我的博文里面加上捐款的链接，这样我花费的时间可以得到一些回报。我一直很高尚的样子，不愿意为此收费。然而，根据经济学的原理，这是有害社会的 :P 经济的原理是这样，有价值的事物，应该在经济上受到相应的支持，这样好的东西才能受到鼓励，发扬光大，不好的东西才可能被人忘记。所以现在我决定，给我觉得价值比较大的文章加上大概的价格，这样喜欢文章的人可以自愿付费，当然也可以不付费。&lt;/p&gt;&lt;p&gt;现在我为之前写的《编程的智慧》给出一个建议零售价（MSRP），为$5美元。如果你喜欢这篇文章，觉得收获很大的话，可以通过paypal或者支付宝进行付费。你的支持将会鼓励我为社会贡献更多类似有益的信息，改良业界的风气和工作环境。谢谢你的支持！&lt;/p&gt;&lt;p&gt;【&lt;a href=&quot;http://paypal.me/yinwang0/5&quot;&gt;PayPal付款链接&lt;/a&gt;】&lt;/p&gt;&lt;p&gt;支付宝二维码：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-87cccd26dde8490a.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/200&quot; alt=&quot;&quot;&gt;&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">pay-blog</guid>
<pubDate>Wed, 13 Apr 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>到底是谁在欺负我们读书少？</title>
<link>http://yinwang.org/blog-cn/2016/04/07/cfa</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;到底是谁在欺负我们读书少？&lt;/h2&gt;&lt;p&gt;发表了之前的文章《&lt;a href=&quot;http://www.jianshu.com/p/b94a2b19ebcc&quot;&gt;我为什么不再做PL人&lt;/a&gt;》之后，我发现有人在知乎上发表文章诬蔑我。本来不想理知乎上的东西，但作者把各种刚从论文上学来的术语，似懂非懂，照本宣科列了一大堆，挺能唬人的，说起来很像那么回事儿，所以我只好破例回应一下，但是下不为例。&lt;/p&gt;&lt;p&gt;现在我把这篇文章，题名『&lt;a href=&quot;http://zhuanlan.zhihu.com/p/20699215&quot;&gt;王垠，请别再欺负我们读书少&lt;/a&gt;』的链接放在这里，供大家观看。评论的第4，第6页有我的回复，技术性比较强，不过有兴趣的人可以看看。为了方便，我也把评论整理和拷贝到这篇文章第二节。&lt;/p&gt;&lt;h3&gt;历史和事实&lt;/h3&gt;&lt;p&gt;文章作者彭飞自称导师是Jens Palsberg，我还没能验证这个事实。Palsberg似乎曾在CFA领域做过一点研究，但我印象不深，我也从来没有在批评CFA的时候点过Palsberg的名。但由于我指出了CFA领域的弊病，彭飞可能就是一心研究这个的，所以觉得“祖业”受到了攻击，想要反驳我，支持CFA的“先进性”，这样以后可以在学术界更好的混下去。这可以理解，然而彭飞的文章，其实破绽很多，处处显示出他自己的一知半解和本本主义。&lt;/p&gt;&lt;p&gt;CFA领域的理论从来没有成功实现，展示过它的功效。CFA最强大的版本，CFA2的作者Dimitris Vardoulakis，当年在Mozilla实习的时候试图在JavaScript上实现CFA2算法。最后的产物叫做“DoctorJS”，还做了一个网站让人试用。可是在不久之后DoctorJS不了了之，消失了。Dimitris这人也挺喜欢吹嘘的，自己的主页上和简历上，都在很靠近自己姓名的地方自豪的写着“CFA2的发明者”字样，仿佛CFA2是什么众所周知的伟大发明一样。&lt;/p&gt;&lt;p&gt;后来跟Mozilla的research director聊天时，他告诉我DoctorJS其实根本不好用，理论过度复杂，实现起来非常困难，而且达不到号称可以达到的效果，所以以后不想再赞助相关的项目了。Mozilla现在已经不再维护DoctorJS的代码，这两封&lt;a href=&quot;https://groups.google.com/forum/#!topic/js-tools/tZ-1jDYxGZk&quot;&gt;email&lt;/a&gt;就是我们能找到的关于Mozilla+DoctorJS最后的信息:&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://groups.google.com/forum/#!topic/js-tools/tZ-1jDYxGZk&quot;&gt;
&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-29cefd492876081e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1280&quot; width=&quot;90%&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;当然了，Dave Herman是很会说套话的。要让别人接手这样的项目，你不可能说它不好用或者很难维护，所以当然要假装它有价值。然而字里行间你却可以看出来，这理论其实非常难以实现，实现了也很容易出错，不知道到底是否正确。最后没人敢碰这样的代码，所以就不了了之了。&lt;/p&gt;&lt;p&gt;之前在Sourcegraph的时候，两位founder也试图采用DoctorJS来做JavaScript的分析，后来发现不好用，改用了&lt;a href=&quot;http://ternjs.net&quot;&gt;Tern&lt;/a&gt;，才产生了有用一点的信息。&lt;/p&gt;&lt;p&gt;PySonar2（写于2010年）是跟CFA2差不多的时间出现的，而P4F的发表比PySonar2晚了好几年。可是PySonar2到今天仍然比CFA2，P4F都要强大。原因很简单，因为它根本没有CFA所用的continuation passing style（CPS变换）所带来的所谓“call/return匹配问题”。所有的call和它们的return，被抽象解释器（abstract interpreter）自然而然的匹配好了，根本不可能错位。&lt;/p&gt;&lt;p&gt;我很惊讶的是CFA领域研究了20年，就在解决这种根本不存在的问题，把简单的问题搞复杂，然后又让它简单一些，来来回回的。PySonar2一开头就很简单，从来没出现过CFA那些乱七八糟的问题，直接就把问题给解决了。彭飞抓住PySonar2表面上的一些小问题指指点点，貌似好大个事情，而其实很多都是由于他自己理解不够深入。详情请见我的评论。&lt;/p&gt;&lt;p&gt;另外，我真的对Python，Ruby，JavaScript这些动态语言做type inference不感兴趣了。PySonar2虽然比CFA2和P4F都简单和强大，但是我从来没想维护PySonar2的“先进性”，我从来没想推广PySonar2。因为我根本不在乎Python，也没把PySonar2当回事。给Python这样的语言做一个很好的类型推导工具，有什么意义吗？未来的方向是直接写上type annotation，就像Java和C#那样，让类型检查简单，迅速又准确。所以PySonar2和CFA领域做的其实都是无用功，只不过我没花20年时间研究CFA，只用了加起来几个月时间，而且还比他们做得更好。&lt;/p&gt;&lt;p&gt;我在2014年末的样子给CFA的“祖师爷”Olin Shivers写了封email，寻找合作机会。我跟他讲述了PySonar2的做法，而且问他为什么他的call/return match用那么复杂的方法来做，然而他没有回我的email。这是一个不祥的预兆，因为我一直在犹豫是否应该告诉这些人，有简单很多倍的办法，可以达到同样的目的。他们完全可以“借鉴”我的做法，然后写进论文里面发表。所以如果他们的2016论文加入了我的想法，也不足为怪。但是真的不在乎这些了，学术界随便胡搞就胡搞呗，反正也不可能有什么大的用处。这些东西，其实做static analysis的人早就明白，CFA远远落后，只能在自己的圈子里发表点paper。&lt;/p&gt;&lt;p&gt;彭飞错误地认为我很把PySonar2当回事，然而它只是我曾经做过的一个小玩具。我一直在探索和展望更加实在，对人可以产生真正效益的领域。只是随便提了一下CFA，就得到如此强烈而具体的攻击，我对PL人士的自我保护意识真的很惊讶。&lt;/p&gt;&lt;h3&gt;技术部分&lt;/h3&gt;&lt;p&gt;以下是针对彭飞提出的pysonar的“技术缺陷”的逐一回应。说成什么“命门缺陷”，其实只有最后第4个例子发现了一个小bug，被我改了几行代码就修好了。&lt;/p&gt;&lt;h4&gt;关于命门缺陷1&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-a7dd1bf09e585f5f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;（注意上面的夸大其词 ;-）&lt;/p&gt;&lt;p&gt;回复：推导出的 &lt;code&gt;int -&amp;gt; int | bool -&amp;gt;bool&lt;/code&gt; 表示的确实是一个intersection type，而不是union type。只不过我中间用的&lt;code&gt;|&lt;/code&gt;记号跟union type一样，所以看起来比较混淆，然而内部实现确实是intersection type，而不是union type。&lt;/p&gt;&lt;p&gt;现在我把中间的分隔符改成了unicode字符&lt;code&gt;∧&lt;/code&gt;，跟intersection type的论文上一样。我想这下他该满意了吧？也就是个表面现象而已。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-cb72dbcd94667aca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/200&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;我怀疑彭飞到底明不明白什么是intersection type。这个type表示这个函数(&lt;code&gt;id&lt;/code&gt;)“同时”是&lt;code&gt;int-&amp;gt;int&lt;/code&gt;和&lt;code&gt;bool-&amp;gt;bool&lt;/code&gt;，而不是表示它“有时”是&lt;code&gt;int-&amp;gt;int&lt;/code&gt;，而另外的时候是&lt;code&gt;bool-&amp;gt;bool&lt;/code&gt;。所以如果你调用&lt;code&gt;id(1)&lt;/code&gt;，推导出的输出一定是&lt;code&gt;int&lt;/code&gt;。如果你输入&lt;code&gt;id(True)&lt;/code&gt;，它推导出的一定是&lt;code&gt;bool&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;如果这是一个union type的话，调用&lt;code&gt;id(1)&lt;/code&gt;会报错，因为&lt;code&gt;id&lt;/code&gt;的类型有可能是&lt;code&gt;bool-&amp;gt;bool&lt;/code&gt;，不能接受&lt;code&gt;int&lt;/code&gt;的输入。调用&lt;code&gt;id(True)&lt;/code&gt;也会报错，因为&lt;code&gt;id&lt;/code&gt;的类型也有可能是&lt;code&gt;int-&amp;gt;int&lt;/code&gt;，不能接受&lt;code&gt;bool&lt;/code&gt;的输入。所以就左右不是人。&lt;/p&gt;&lt;p&gt;其实如果彭飞仔细看那两个变量&lt;code&gt;a&lt;/code&gt;和&lt;code&gt;b&lt;/code&gt;的类型，就会发现这是intersection type，而不是union type。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-14109bcac813e1bd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/200&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-ea15e1e582b66548.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/200&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;可能有人对这里的intersection type有所误解。&lt;code&gt;int -&amp;gt; int ∧ bool -&amp;gt;bool&lt;/code&gt;，在这里其实不是表示这个函数只能接受&lt;code&gt;int&lt;/code&gt;或者&lt;code&gt;bool&lt;/code&gt;的输入，而只是表示这个函数在某些调用的地方输入了&lt;code&gt;int&lt;/code&gt;或者&lt;code&gt;bool&lt;/code&gt;，然后分别输出了&lt;code&gt;int&lt;/code&gt;和&lt;code&gt;bool&lt;/code&gt;。所以在“官方意义”下，这并不是这个函数的类型。那么这个函数的类型是什么呢？pysonar的哲学是这样：每一个函数的类型，就是这个函数本身。没有比函数本身更能够描述函数的特征的类型，这就是静态分析领域跟类型理论（type theory）领域的区别。虽然pysonar的分析标记出的类型并不是函数的“本质类型”，然而这并不会削弱对类型错误的检测，反而会增强它。这是因为pysonar直接通过对函数体进行分析，找到类型错误。函数体比通常的类型包含更精确的信息，所以pysonar的类型分析，其实比普通的类型系统更加精确。所以可以说，静态分析是比类型理论更加细致和精华的领域。&lt;/p&gt;&lt;p&gt;另外，pysonar本来就是放弃了他所谓的“Haskell那种polymorphic type inference”，故意要用“concrete type inference”，因为Haskell那种type inference其实对于Python是不能用的。有些人很喜欢随口冒出术语，可是Haskell那种其实不叫“polymorphic type inference”，而叫Hindley-Milner类型系统（HM）。这种类型系统最早出现在SML，后来也被OCaml和Haskell借鉴。我不知道彭飞为什么抓住“polymorphic”这个词不放，pysonar的type inference其实也是polymorphic的，因为它允许函数接受多种类型的输入。&lt;/p&gt;&lt;p&gt;彭飞指出函数&lt;code&gt;id&lt;/code&gt;可以推导出类似HM系统的&lt;code&gt;forall a. a -&amp;gt; a&lt;/code&gt;这样的类型。对于&lt;code&gt;id&lt;/code&gt;这么简单的函数是可以，然而对于稍微复杂点的Python代码，HM系统是不可行的。PySonar早在2009年的第一版，就做过HM那样的系统，确实能把&lt;code&gt;id&lt;/code&gt;推出forall a. a -&amp;gt; a那样的类型，但是后来发现遇到复杂点的Python代码就不行了。所以后来我干脆把HM系统去掉了，只留下正向的跨过程（interprocedual）类型推导。&lt;/p&gt;&lt;p&gt;HM类型系统的问题是根本性的，早在ML之类的语言里面出现过了，然后出现了一系列变通（workaround），比如所谓“&lt;a href=&quot;https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system#Let-polymorphism&quot;&gt;let-polymorphism&lt;/a&gt;”，“&lt;a href=&quot;https://en.wikipedia.org/wiki/Value_restriction&quot;&gt;value restriction&lt;/a&gt;”等等，却不能从根本上解决问题。彭飞似乎没有看过相关的内容，或者把这些丑陋的变通，当成了博大精深的发明吧？:)&lt;/p&gt;&lt;p&gt;举个简单的例子好了。下面这段完全合法的Python代码，你就没法用HM那样的系统推导出类型：&lt;/p&gt;&lt;pre&gt;
def foo(f):
    return f(1), f(True)

def id(x):
    return x

a = foo(id)
print(a)  # prints &quot;(1, True)&quot;
&lt;/pre&gt;&lt;p&gt;这段代码会毫无问题的打印出&lt;code&gt;(1, True)&lt;/code&gt;，然而它却不能通过HM系统的类型检查。如果你不信，那你可以写出等价的Haskell代码：&lt;/p&gt;&lt;pre&gt;
foo f = (f 1, f True)
a = foo id
&lt;/pre&gt;&lt;p&gt;你把这段代码交给Haskell的编译器，它会报错：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;No instance for (Num Bool) arising from the literal ‘1’
In the first argument of ‘f’, namely ‘1’
In the expression: f 1
In the expression: (f 1, f True)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这是因为Haskell所用的HM系统，无法知道&lt;code&gt;foo&lt;/code&gt;的参数&lt;code&gt;f&lt;/code&gt;是一个什么样的函数，它是同时能接受&lt;code&gt;int&lt;/code&gt;和&lt;code&gt;bool&lt;/code&gt;，还是其实能接受所有类型，也就是&lt;code&gt;forall a. a-&amp;gt;a&lt;/code&gt;呢？类型推导不能确定这个范围，所以只能假设&lt;code&gt;f&lt;/code&gt;不可以是一个polymorphic的函数，所以发现&lt;code&gt;f&lt;/code&gt;被同时输入了&lt;code&gt;1&lt;/code&gt;和&lt;code&gt;True&lt;/code&gt;，就报错了。&lt;/p&gt;&lt;p&gt;这是一个HM系统根本无法解决的问题。SML，OCaml和Haskell里面所谓的“let-polymorphism”，就是一个对此的非常局限的变通。&lt;/p&gt;&lt;p&gt;相比之下，pysonar的类型推导，却可以正确判断出这个代码其实没有问题。它能准确地推断出&lt;code&gt;a&lt;/code&gt;的类型是tuple类型&lt;code&gt;(int, bool)&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-86b8d33de25e30c8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/300&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-dc8b1cf609d0023b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/300&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;所以说得倒容易，我们请有本事的彭飞同学用CFA家族的算法，给我们show一下推导出forall类型？:)&lt;/p&gt;&lt;h4&gt;关于命门缺陷2：&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-7b0db706068707d6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;回复：打开错误报告的开关（-report），彭飞这个例子里的类型错误就会被标记出来。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-ecbddb3d5c0c5ba4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/400&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;像所有动态语言的类型推导器一样，pysonar的类型推导会出现false positive，所以pysonar现在主要用于代码检索，而不是报告类型错误。为了防止这些类型错误信息干扰视线，pysonar现在并不缺省在demo中标记类型错误，因为demo只是作为一个indexer提供信息。然而打开错误报告的开关（-report）之后，彭飞这个例子里的类型错误还是可以被发现的。&lt;/p&gt;&lt;p&gt;目前的UI会在有类型错误的地方放上一个下划线，鼠标移上去之后，会显示那里的问题。然而现在的Web UI有个问题，因为下划线离变量的链接太近，所以鼠标指到变量之上，就会提示变量的类型，而不是错误。如果你打开浏览器的inspector，就可以看到报告的错误：“warning: attribute not found in type: A”。&lt;/p&gt;&lt;p&gt;我知道报错链接的放置位置不是很合理，而且鼠标UI设计不大好，不过这只是一个粗糙的demo，也许以后有时间再改进吧。然而这并不是什么“命门缺陷”，因为类型错误确实是被发现了的。&lt;/p&gt;&lt;h4&gt;关于缺陷3：&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-f6e46f93828bf435.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/500&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;回复：有一个链接没有指向，是因为当时在Sourcegraph，由于UI和数据库存储的限制，他们需要HTML里面的链接只跳转到一个地方，所以UI上同时指向两个地方的功能就被去掉了。然而内存里面的reference其实都是可以有多个的，这个你只需要看看pysonar的内部数据结构就可以发现。或者用更简单的办法，你只需要看一下&lt;code&gt;a&lt;/code&gt;的类型：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-66f6ade7a576099d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/300&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;a&lt;/code&gt;的类型是&lt;code&gt;{B | A}&lt;/code&gt;，这说明什么呢？这说明pysonar完全知道&lt;code&gt;a.x&lt;/code&gt;可能引用两个地方，&lt;code&gt;A.x&lt;/code&gt;和&lt;code&gt;B.x&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;为了这么点UI的事情，就说“作者没有理解静态分析的本质”，然后拿各种术语，什么“抽象值”（abstract value），或者引用书本上的定义来吓唬人，这说明他根本没有试图搞明白pysonar的工作原理。“抽象值”是非常基础的概念，觉得我连这个都不理解，这种人还真以为自己学会了点术语了 :)&lt;/p&gt;&lt;p&gt;pysonar运行的时候，里面到处跑的都是抽象值，就没有几个东西不是抽象值的。小朋友可能从来没实现过类似的东西，所以很是把这些基础概念当回事。死记硬背了点书本知识，就自以为了不起。从来没有试图了解实情，有了疑惑也不来信虚心请教。抓到一点肤浅的“疑似把柄”，就背地里拿出来说成天大的事。&lt;/p&gt;&lt;h4&gt;关于缺陷4：&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-31d39adeba235cc6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;回复：这个“看似很严重的bug”确实是一个bug，然而它不像他说的那么严重。而且不像他说的那样，需要另外一遍“语义分析”。pysonar是一个强大的抽象解释器，它完全可以只做一遍分析就找到这些名字，引用和类型。&lt;/p&gt;&lt;p&gt;所以，只改了几行代码之后，现在已经能显示所有变量&lt;code&gt;n&lt;/code&gt;的类型为&lt;code&gt;int&lt;/code&gt;。pysonar大的原理和结构都是非常好的，这些小问题真是不值一提，很容易fix。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-25f8b484c6eec206.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/300&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;反复的提到“语义分析”（semantic analysis）这些空洞的名词，显示了彭飞刚入道不久，学艺肤浅。“把每个变量和它的定义联系起来”，这种做法其实是所谓data flow analysis常用的。Data flow analysis速度快，可是非常的粗略，不精确。JavaScript的分析器&lt;a href=&quot;http://ternjs.net&quot;&gt;Tern&lt;/a&gt;就是用的这种方法。这种做法根本不可能达到pysonar的带有控制流信息的分析精确程度。&lt;/p&gt;&lt;p&gt;另外，彭飞还有一些闭着眼睛肆意的歪曲，比如说pysonar的代码冗长复杂。他恐怕根本就没看过pysonar的代码，不然他可以发现pysonar的类型分析器，总共只有1200行代码，而且结构非常简单干净。&lt;/p&gt;&lt;p&gt;他说pysonar不是sound的，而CFA2是sound的，可我从来没说过PySonar2是sound的。其实CFA2和P4F，对于Python也不可能是sound的，因为对这样的语言做类型推导，本来就是undecidable的问题。这些工具能做的，只是最大限度的发现类型错误而已。它们并不能完全排除类型错误。它们的类型推导都有很多false positive，所以不可能用在编译器优化等方向。&lt;/p&gt;&lt;p&gt;不得不引用一下Linus的话（虽然我鄙视这句话）：Talk is cheap. Show me some code。我请彭飞把P4F实现出来，给我们展示一下它能生成什么样的结果？哈哈。CFA2的发明人已经在Mozilla试过了不是吗？过度复杂的理论，根本不能实现和产生实际效果。实话说吧，CFA家族的算法恐怕要再发展好几年，仔细研究PySonar2的实现，才有可能达到PySonar2的地步。&lt;/p&gt;&lt;h3&gt;到底是谁在欺负你们书读得少？&lt;/h3&gt;&lt;p&gt;彭飞的文章标题为『&lt;a href=&quot;http://zhuanlan.zhihu.com/p/20699215&quot;&gt;王垠，请别再欺负我们读书少&lt;/a&gt;』，我现在想问问大家，到底是谁在显示他读书多，欺负大家读书少？我有强调过我读书多吗？我告诉大家的是，我脑子里的东西大部分都不是看书学来的，书本知识是不可靠的，每本书里面都只有一两章好点的地方。我的知识大部分是自己动手学会的，所以我才能做到融会贯通。&lt;/p&gt;&lt;p&gt;通过这些他对pysonar技术细节的分析，我看得出来彭飞看过一些PL领域的书和论文，记住了一些皮面知识和吓人的术语。满口的术语，可是却没有深刻的理解它们后面的涵义。他读书确实也够少的，见识太少，不知道天外有天。恐怕动手能力也不高，没动手实现过CFA领域任何一个算法。拿别人的代码来随便摆弄两下，也没有深入试验和观察，就以为自己可以造出一个大新闻：看，王垠是个大骗子！&lt;/p&gt;&lt;p&gt;看了一下彭飞的知乎专栏，他似乎喜欢显示一些鸡毛蒜皮的东西，把一些刚看过，没经过实践检验的理论，当成宝一样给给其它人讲，传道授业解惑一样，试图用这种方式树立自己的“权威地位”，让大家以为他是大牛人。他的文章经常出现一些比如“牛逼到爆”，“巅峰之作”一类的词汇，跟国内小编吹嘘国外大公司差不多的语气。他当然希望大家继续崇拜PL界的权威们，这样他们就可以瞎蒙混骗，写一些看不懂，实现不了，无法验证真伪的理论，继续高高在上，高深莫测的样子。所以，到底是谁在欺负我们读书少呢？&lt;/p&gt;&lt;p&gt;知乎的民科们班门弄斧，拿起石头砸了自己的脚，已经不止第一次了。我劝这些人还是好自为之。&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">cfa</guid>
<pubDate>Thu, 07 Apr 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>我为什么不再做PL人</title>
<link>http://yinwang.org/blog-cn/2016/03/31/no-longer-pl</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;我为什么不再做PL人&lt;/h2&gt;&lt;p&gt;我不做程序语言（PL）的工作已经半年了。在这半年里，我变得快乐了很多，对世界也有了新的观点。现在我想来讲一讲，我为什么不想再做PL的工作和研究。我只希望这些观点可以给正在做PL，或者考虑进入这个领域的人们，作为一份参考。&lt;/p&gt;&lt;h3&gt;学校里的PL人&lt;/h3&gt;&lt;p&gt;PL看似计算机科学最精髓的部分，事实确实也是这样的。没有任何一个其它领域，可以让你对程序的本质形成如此深入的领悟，然而这并不等于你就应该进入PL的博士班。这是为什么呢？&lt;/p&gt;&lt;h4&gt;炒冷饭&lt;/h4&gt;&lt;p&gt;PL这个领域几十年来，已经发展到了非常成熟的阶段。这里面的问题，要么在20年前已经被人解决掉了，要么就是类似“&lt;a href=&quot;https://en.wikipedia.org/wiki/Halting_problem&quot;&gt;停机问题&lt;/a&gt;”一样，不可能解决的问题。然而，博士毕业却要求你发表“创新”的论文，那怎么办呢？于是你就只有扯淡，把别人已经解决的问题换个名字，或者制造一些看似新鲜却不管用的概念，在大会上煞有介事的宣讲。俗话说就是“炒冷饭”。&lt;/p&gt;&lt;p&gt;最开头进入这个领域的时候，你可能不觉得是这样，因为似乎有那么多的东西可以学习，那么多的大牛可以瞻仰，那么多的新鲜名词，什么“lambda calculus”啊，“语义”啊，各种各样的“类型系统”啊，这样那样的“逻辑”…… 可是时间久了，看透了，你就发现一些这个圈子里的规律。&lt;/p&gt;&lt;h4&gt;崇拜古人&lt;/h4&gt;&lt;p&gt;几乎每篇PL领域的论文，里面必有一页弯弯曲曲，让人看花眼的逻辑公式。程序语言的论文，不是用程序来描述，而是用一些老古董的逻辑符号，像这样：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-eae6c6cd2eecfb4a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/500&quot; alt=&quot;图1：PL论文里的公式&quot;&gt;&lt;/p&gt;&lt;p&gt;绝大部分PL领域的专家们，似乎都酷爱逻辑符号，视逻辑学家高人一等。这种崇尚古人的倾向，使得PL专家们看不见这些符号背后，类似电路一样的直觉。他们看不见逻辑学的历史局限，所以他们也许能够发展和扩充一个理论，却无法创造一个新的。&lt;/p&gt;&lt;p&gt;说到古人，却并不是所有古人都这么晦涩。如果你考古一下就会发现，其实现代逻辑学的鼻祖&lt;a href=&quot;https://en.wikipedia.org/wiki/Gottlob_Frege&quot;&gt;Gottlob Frege&lt;/a&gt;最初的论文里，是没有这些稀奇古怪的符号的。他整篇论文都在画图，一些像电路一样的东西。比如下图，就是Frege的创始论文《&lt;a href=&quot;https://en.wikipedia.org/wiki/Begriffsschrift&quot;&gt;Begriffsschrift&lt;/a&gt;》里最复杂的“公式”之一：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-80571c70a82c1850.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/200&quot; alt=&quot;图2：Frege的“公式”&quot;&gt;&lt;/p&gt;&lt;p&gt;你可以把这里的每根线理解成一根电线。图1里那些诡异的逻辑符号，都是一些好事的后人（比如&lt;a href=&quot;https://en.wikipedia.org/wiki/Gerhard_Gentzen&quot;&gt;Gentzen&lt;/a&gt;）加进去的，最后搞得乌七八糟，失去了Frege理论的简单性。所以PL专家们虽然崇尚古人，却没有发现大部分古人，其实并没能获得鼻祖Frege的真传。&lt;/p&gt;&lt;p&gt;如果你看透了那些公式，自己动手实现过各种解释器，就会发现PL论文里的那些公式，其实相当于解释器的代码，只不过是用一种叫做“XX逻辑”的晦涩的语言写出来的。逻辑，其实本质上是一种相当落伍的程序语言。如果你精通解释器的代码，也许就会发现，这些公式其实用非常蹩脚的方式，实现了哈希表等数据结构。逻辑语言只运行于逻辑学家的脑子里面，用它写出的代码一样可能有bug，而且由于这语言如此障眼难读，而且没有debugger，所以bug非常难发现。逻辑学家们成天为自己的设计失误和bug伤透了脑筋，PL专家们却认为他们具有数学的美感，是比自己聪明的高人 :)&lt;/p&gt;&lt;p&gt;所以当你看透了所有这些，就会发现PL的学术界，其实反反复复在解决一些早已经解决了的问题，只不过给它们起了不同的名字，使用不同的方式来描述。有时候好几个子领域，其实解决的是同一个问题，然而每个子领域的人，却都说自己的问题在本质上是不一样的，号称自己是那个子领域的鼻祖。甚至有人在20多年的时间里，制造出一代又一代的PhD和教授职位。他们的理论一代代的更新，最后却无法解决实际的问题。所谓的“控制流分析”（control-flow analysis，CFA），就是这样的一个子领域。&lt;/p&gt;&lt;h4&gt;不知道谁是真的高人&lt;/h4&gt;&lt;p&gt;进入一个领域做研究，你总该知道那些人是真正厉害的。可惜的是，PL这个领域里，你往往不知道谁是真正掌握了精髓的学者，甚至好几年之后你仍然蒙在鼓里。我的历史教训是，写教科书的人，往往不是最聪明，最理解本质的。真正深刻的PL研究者，你可能根本没听说过他们的名字。&lt;/p&gt;&lt;p&gt;一般程序员提到PL，就会跟“编译器”这个领域混淆在一起，就会想起大学时候上编译器课，看《&lt;a href=&quot;http://www.amazon.com/Compilers-Principles-Techniques-Tools-2nd/dp/0321486811&quot;&gt;龙书&lt;/a&gt;》时焦头烂额的情景。然后由于&lt;a href=&quot;https://en.wikipedia.org/wiki/Stockholm_syndrome&quot;&gt;斯德哥尔摩综合症&lt;/a&gt;，他们就会崇拜龙书的作者们。直到遇到了真正厉害的PL专家，你才发现编译器这个领域，跟PL根本是两回事，它其实比PL要低一个档次，里面充满了死记硬背的知识甚至误导。龙书的作者，其实也不是最厉害的编译器作者，他们更不是合格的PL专家。&lt;/p&gt;&lt;p&gt;上过“正统”的PL课程的学生，往往用一本经典大部头教材叫《&lt;a href=&quot;https://mitpress.mit.edu/index.php?q=books/types-and-programming-languages&quot;&gt;TAPL&lt;/a&gt;》，然后就会误认为此书的作者是最厉害的PL专家，然而他们再一次被名气给蒙蔽了。TAPL这书其实不但照本宣科，没有揭示实质，而且冗长没有选择，有用的没用的过时的理论，一股脑的灌输给你。等你研究到了所谓“交集类型”（intersection types），看到TAPL作者当年的博士论文才发现，其实他把简单的问题搞复杂了，而且那些理论几乎完全不能实用。真正厉害的intersection types专家，其实默默无闻的待在Boston University，而且研究到最后，intersection types这个领域其实被他们证明为完全不能实用。&lt;/p&gt;&lt;p&gt;由于TAPL这本书，以及&lt;a href=&quot;https://en.wikipedia.org/wiki/ML_(programming_language&quot;&gt;ML&lt;/a&gt;)，Haskell等语言在PL界的“&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E7%99%BD%E8%B1%A1&quot;&gt;白象&lt;/a&gt;”地位，于是很多人又对&lt;a href=&quot;https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system&quot;&gt;Hindley-Milner&lt;/a&gt;类型系统（HM）充满了崇敬之情，以为HM系统的发明者&lt;a href=&quot;https://en.wikipedia.org/wiki/Robin_Milner&quot;&gt;Robin Milner&lt;/a&gt;是最厉害的PL学者。他的确不错，然而等你随手就能实现出HM系统，看清了它的实质，就会发现所有这样能够“倒推”出类型的系统，其实都具有很大的局限性。&lt;/p&gt;&lt;p&gt;HM系统的“&lt;a href=&quot;https://en.wikipedia.org/wiki/Unification_(computer_science&quot;&gt;unification&lt;/a&gt;)”机制，依赖于数学上的“&lt;a href=&quot;https://en.wikipedia.org/wiki/Equivalence_relation&quot;&gt;等价关系&lt;/a&gt;”，所以它不可能兼容子类型（subtyping）关系。原因很简单：因为子类型没有交换性，不是一个等价关系。而子类型关系却是对现实世界进行直观的建模所必不可少的，于是你就发现Haskell这类基于HM系统的语言，为了弥补这些缺陷而出现各种“扩展”，却永远无法达到简单和直观。一开头就错了，所以无论Haskell如何发展，这个缺陷也无法弥补。如果没有了HM系统，Haskell就不再是Haskell。&lt;/p&gt;&lt;p&gt;Robin Milner的另外一个贡献&lt;a href=&quot;https://en.wikipedia.org/wiki/%CE%A0-calculus&quot;&gt;π-calculus&lt;/a&gt;，虽然看起来吓人，其实看透了之后你发现它里面并没有很多东西。π-calculus对并发进行“建模”，却不能解决并发所带来的各种问题，比如竞争（race condition）。实际上普通的语言也能对并发进行简单的建模，所以π-calculus其实只停留于纸面上，不可能应用到现实中去。跟π-calculus类似的一个概念&lt;a href=&quot;https://en.wikipedia.org/wiki/Communicating_sequential_processes&quot;&gt;CSP&lt;/a&gt;也有类似的问题，属于“白象理论”。很多语言（比如Go）扯着CSP的旗号，引起很多人无厘头的膜拜，可见白象的威力有多大 :)&lt;/p&gt;&lt;p&gt;我在学校研究PL的时候就是这样，每天都发现天外有天，每天都发现曾经的偶像其实很多时候是错觉。最后我发现，PL领域其实最后就剩下那么一点点实质的内容，其它的都是人们造出来的浮云。所以每当有人问我推荐PL书籍，我都比较无语，因为我的PL知识只有非常少数是看书得来的。自己动手琢磨出来的知识，才是最管用的。&lt;/p&gt;&lt;h4&gt;没人知道你是谁&lt;/h4&gt;&lt;p&gt;PL的学生还有一个问题，那就是毕业后工作不好找。只有极少数公司（像微软，Intel，Oracle）里的少数团队，可以发挥PL专家的特殊才能。绝大部分其它公司根本不知道PL是什么，PL专家是干什么的。你跟他们说你的专业是“程序语言”，他们还以为你只是学会了“编程”而已，还问你想做“前端”还是“后端” :) 诚然，PL学生一般都有很好的编程能力，然而公司往往只关心自己的实际需求。PL学生毕业之后，很容易被普通公司作为没有任何专长的人对待。&lt;/p&gt;&lt;p&gt;另外，PL的圈子相当的小，而且门派宗教观念严重，所以就算你从名师手下毕业，想进入另一个老师的门徒掌权的公司，很可能因为两个门派的敌视而无法被接纳，就算进去了也经常会因为对于PL的理念不同而发生冲突。所以，学习PL最精髓的理论是有好处的，然而进入PhD投身PL的研究，我觉得应该三思。&lt;/p&gt;&lt;h3&gt;公司里的PL人：过度工程&lt;/h3&gt;&lt;p&gt;PL人在学校里跟着教授炒冷饭，毕业进入了公司之后，他们的行为方式还是非常类似。他们喜欢在公司里做的一件事情，叫做“过度工程”。本来很直接，很容易解决的一个问题，非要给你扯到各种炫酷的PL名词，然后用无比复杂的方案来解决。&lt;/p&gt;&lt;p&gt;有一些PL人喜欢推广他们认为高大上的语言，比如Haskell，OCaml，Scala等。这些语言在PL学术界很受尊重，所以他们以为这些语言能够奇迹般的解决实际的问题，然而事实却不是这样的。事实是，这些学术界出来的语言，其实缺乏处理现实问题的机制。为了能够在学术上证明程序的所谓“正确性”，而且由于类型系统本身的局限性，这些语言往往被设计得过于简单，具有过度的约束性，以至于表达能力欠缺。&lt;/p&gt;&lt;p&gt;最后，你发现用这些语言来写代码，总是这也不能做，那也不能做，因为你要是那么做了，编译器就无法发现“类型错误”。到最后你发现，这些语言的约束，其实是无需有的。如果放宽这些约束，其实可以更优雅，更简单的对问题进行建模。对正确性的过分关注，其实导致了PL人选择蹩脚的语言，写出绕着弯子，难以理解的代码。&lt;/p&gt;&lt;p&gt;还有一类PL人，喜欢设计不必要存在的语言。因为他们认为设计语言是PL人的特异功能，所以随时随地都想把问题往“语言设计”的方向上靠。这样的趋势是非常危险的，因为有原则的PL人，其实都明白一条重要的道理：不到万不得已的时候，千万不要制造语言。&lt;/p&gt;&lt;p&gt;很多PL人在公司里盲目的制造新的语言，导致的问题是，到最后谁也无法理解这种新语言写出来的代码。这一方面是新语言必然导致的结果，另一方面是由于，并不是每一个PL人都有全面的知识和很好的“品味”。每个PL学生毕业，往往只深入研究了PL的某个子领域，而对其它方面只是浮光掠影，所以他们有可能在那上面犯错。有些PL人喜欢照猫画虎，所以可能盲目的模仿Go语言，Haskell或者Python的特性，设计出非常蹊跷难用的语法。这些新的语言，其实让其他人苦不堪言。最后你发现，他们声称新语言能解决的问题，其实用像Java一样的老语言，照样可以很容易的解决。&lt;/p&gt;&lt;p&gt;喜欢钻牛角尖，把问题搞复杂，就是很多公司里的PL人的共同点。制造语言是PL人应该尽量避免的事情，这恰恰跟PL人的专长是矛盾的。所以有原则的PL人，生活怎么可能不苦 :)&lt;/p&gt;&lt;h3&gt;PL人的天才病&lt;/h3&gt;&lt;p&gt;很多研究PL的人喜欢看低其它程序员，认为自己能设计实现程序语言，就是天之骄子。我之所以从Dan Friedman那里学到了好东西，却没有成为他的PhD学生，一方面就是因为看不惯围绕在他身边那些自认为是“天才”的人。&lt;/p&gt;&lt;p&gt;总是有那么一群本科生，自认为掌握了Friedman所讲授的精髓，所以高人一等。其实呢，他们的水平比起我这样的，其实差的天远。于是我就经常无奈的看着他们，吵吵闹闹的宣讲他们解决的“新问题”，貌似什么了不起的发明一样，受到Friedman的肯定就受宠若惊的样子。而其实呢，那些都是我几年前就已经试过并且抛弃的方案……&lt;/p&gt;&lt;p&gt;其它的PL人，包括PhD学生，也有一样的毛病。不管在三流大学，还是在Harvard，Princeton，MIT这样的“牛校”出来的，只要是PL人，几乎必然有这种天才作风。另外你可能不知道的是，牛校往往并不产出优秀的PL人才。像Stanford，Berkeley，MIT这样的传统CS牛校，其实在PL方面是相当差的。&lt;/p&gt;&lt;p&gt;这种天才病的危害在于，它蒙蔽了这些人的眼睛。他们不再能设计出让“普通人”可以容易使用的产品。如果你不会用，他们就会嘲笑你笨，而其实呢，是因为他们的设计不好。他们喜欢用含混晦涩的方式（所谓“函数式”）的写法来构造代码，让其它人阅读和修改都极其困难，……&lt;/p&gt;&lt;p&gt;这些所谓天才，看不到简单直观的解决方案，为了显示自己的聪明而采用繁复的抽象，其实是一种愚蠢。真正的天才，必须能够让事情变得简单。&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">no-longer-pl</guid>
<pubDate>Thu, 31 Mar 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>Go语言，Docker和Kubernetes</title>
<link>http://yinwang.org/blog-cn/2016/03/27/docker</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;Go语言，Docker和Kubernetes&lt;/h2&gt;&lt;p&gt;当我嘲笑Go语言的时候，有些人跟我说，你说Go语言是垃圾，可是你看像Docker和Kubernetes之类的云计算项目，为什么是Go语言写的呢？&lt;/p&gt;&lt;p&gt;其实答案很简单：这些东西并不是非得用Go语言写才可以，用其他语言实现它们其实并没有什么问题，只不过它们碰巧是用Go语言写的而已。Docker和Kubernetes之类的项目，其实只依赖于操作系统的构架细节，对语言没有特别的要求，而且也没什么性能需求，所以它们其实可以用任何语言（包括Shell，Perl，Python，Ruby，C，Java……）来实现。只因为有人跟风，用Go语言写了这些东西，并不能说明Go语言是好东西。在当今混乱的IT业界，随便你做个东西都会有人拿来用，更不要说是挂着Go-ogle的羊头的语(go)言(rou) ;)&lt;/p&gt;&lt;p&gt;如果你不相信我，可以看看这个叫“&lt;a href=&quot;https://github.com/p8952/bocker/blob/master/bocker&quot;&gt;Bocker&lt;/a&gt;”的项目，它只用了100行shell script，就实现了Docker最重要的功能。 说白了，Docker的原理就是建立一些目录，把系统文件和相关库代码拷贝进去，然后&lt;a href=&quot;https://en.wikipedia.org/wiki/Chroot&quot;&gt;chroot&lt;/a&gt;，这样你的代码在里面运行的时候，就以为自己独占一个Linux系统。Shell语言之恶劣，我已经有&lt;a href=&quot;http://www.yinwang.org/blog-cn/2013/03/29/scripting-language&quot;&gt;专文&lt;/a&gt;介绍，所以就不多说了。本来可以用shell脚本实现的项目，现在有人用Go来做，能说明Go是一个好的语言吗？&lt;/p&gt;&lt;p&gt;另外也许很多人不知道的是，Docker和Kubernetes，虽然很火，但其实并不是什么了不起的技术。Docker并不能解决Unix的根本问题。Unix从来就不是一个具有良好模块化设计的系统。各种稀奇古怪的配置文件，设计缺乏条理和章法。各种模块之间，版本逻辑依赖关系错综复杂，纠缠不清。所以不管你事后怎么补救，其实都难以变成结构清晰的设计。很多项目做成了container之后，它们之间用REST和HTTP进行通信，其实让系统模块之间的通信变得更加困难和复杂。&lt;/p&gt;&lt;p&gt;使用了Docker之后，你也许会发现，Unix的狂热分子们其实重新折腾出了Windows一开头就有的应用程序构架，然而这些应用程序之间的通信方式，却远远没有达到&lt;a href=&quot;https://en.wikipedia.org/wiki/Component_Object_Model&quot;&gt;COM&lt;/a&gt;和&lt;a href=&quot;https://en.wikipedia.org/wiki/.NET_Framework&quot;&gt;.NET&lt;/a&gt;的成熟程度。&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">docker</guid>
<pubDate>Sun, 27 Mar 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>为什么自动车完全不可以犯错误</title>
<link>http://yinwang.org/blog-cn/2016/03/19/self-driving-car-liability</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;为什么自动车完全不可以犯错误&lt;/h2&gt;&lt;p&gt;有人跟我讲，我对Google的自动车要求太苛刻了。人无完人，所以Google的产品也不需要是完美的，只要“够好用”就有市场。世界上有那么多糟糕的司机，酒后驾车的，开车时发短信的，打瞌睡的，判断失误的…… 导致了那么多的车祸，可比Google的自动车差多了。所以自动车不需要完美，只要99.9%的情况下可以正确工作，能大幅度减少车祸率，就是人类的福气了。&lt;/p&gt;&lt;p&gt;首先，现在的情况是，Google自动车现在只能在非常局限的情况下出来：白天，天气好，交通简单，而且就算是这样理想的条件下，一年之中仍然会发生270多起需要“&lt;a href=&quot;http://www.forbes.com/sites/brookecrothers/2016/01/13/google-self-driving-car-failures-total-272-over-one-year-but-improvement-seen&quot;&gt;人工干预&lt;/a&gt;”的事件，所以自动车的“驾驶技术”最后能不能超过最低级别的人类驾驶员，其实还很值得怀疑。其次，就算我们抛开这个问题不谈，假设自动车能够超过绝大部分人类驾驶员，能在99.9%的情况下判断正确，那么它也是不可行的。其实自动车必须能在100%的情况下做出正确的判断，不能犯任何错误，才有可能被人接受。这是为什么呢？&lt;/p&gt;&lt;p&gt;这其实是因为伦理和法律的原则。法律上的责任，并不是从宏观角度出发的。也就是说，法律不会因为自动车在99.9%的情况下判断正确，就免除那0.1%的情况下，Google对车祸的责任。法律的原则很简单，谁犯错误导致了车祸，谁就得负责，不管它是人还是机器都一样。是的，自动车也许不需要完美就可以用，但如果它犯错误引起了事故，责任就必须完全由Google，而不是车主来承担。因为如果车主是驾驶员，他开车引起车祸，那么车主就得负责。现在车主不是驾驶员，Google的软件才是驾驶员，所以如果自动车引起车祸，Google就得负完全的责任。&lt;/p&gt;&lt;p&gt;如果你还没有明白，我们来设想一个实例好了。假设Google自动车在99.9%的情况下，判断都是正确的，可就那么0.1%的情况下，它会判断失误而导致车祸。现在你就是这些不幸的人其中之一，你乘坐的Google自动车由于软件判断失误，导致车祸，让你双腿截肢，终生残疾。你把Google告上法庭。Google对法官讲，因为我们的自动车在99.9%的情况下都是可靠的，大幅度降低了社会的总体车祸率，对人类做出了巨大贡献。这个人很不幸，遇上了这0.1%判断失误的情况，所以Google对此不负责任。你觉得这可以接受吗？ ;)&lt;/p&gt;&lt;p&gt;0.1%的出错概率，落到一个人的头上，就等于100%的不幸。如果你本来是一个安全的驾驶员，那就更加不幸，因为如果是你自己开车，其实完全不会犯那样的错误。在这种情况下，就算自动车使得社会的总体车祸率急剧降低，对你来说其实毫无意义，因为残废的人是你。这就是为什么从伦理上讲，对机器和人，我们必须有两种不同的标准。自动车的判断力，并不是超越了大部分的驾驶员就可以的，它必须超过所有人！有些人开车时会犯的那些错误，自动车却完全不可以犯。因为坐了这辆犯错的自动车，导致身体残疾的人，他可以说：“如果是我自己开车，根本就不可能犯这样的错误。诚然，其它人在这种情况下可能会犯错，但我不会！所以Google的自动车对此负有严重的责任。”&lt;/p&gt;&lt;p&gt;明白了吗？只是能从宏观上减少车祸是不够的。自动车的驾驶技术，必须超越世界上最安全的驾驶员，它完全不可以犯错误。现在世界上虽然有许多的车祸，可是因为人是驾驶员，所以责任分摊在很多当事人的头上，谁犯错误谁负责。可是如果Google的自动车进入市场，代替了大部分的驾驶员，以后自动车引起的车祸的责任，全都会落到Google的头上。所以这样的生意，是非常困难而不切实际的。&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">self-driving-car-liability</guid>
<pubDate>Sat, 19 Mar 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>Google的眼光</title>
<link>http://yinwang.org/blog-cn/2016/03/17/google-vision</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;Google的眼光&lt;/h2&gt;&lt;p&gt;你知道吗，Google（Alphabet）要卖掉&lt;a href=&quot;http://www.bloomberg.com/news/articles/2016-03-17/google-is-said-to-put-boston-dynamics-robotics-unit-up-for-sale&quot;&gt;Boston Dynamics&lt;/a&gt;，一个它收购才没多久的机器人公司。这也意味着，Google准备完全退出机器人的领域。新闻传言说，是因为Google觉得这些机器人太吓人了，把它踢倒在地，居然能像终结者一样爬起来！还有舆论说Google研究机器人，是想抢走人类的饭碗，所以现在Google为了人类的幸福，放弃了这个计划。呵呵，这借口多么美妙呀！你们真以为Google有这么好心，会为你们的生存着想吗？&lt;/p&gt;&lt;h3&gt;Boston Dynamics&lt;/h3&gt;&lt;p&gt;卖掉Boston Dynamics（以下简称BD）真正的原因，其实是因为BD的机器人，只是一些研究性质的原型。它们离能够投入实用，其实差的老远。研究经费的需求，却是一个无底洞。你们只要仔细看看这些BD机器人的视频（&lt;a href=&quot;https://www.youtube.com/watch?v=rVlhMGQgDkY&quot;&gt;视频1&lt;/a&gt;，&lt;a href=&quot;https://www.youtube.com/watch?v=M8YjvHYbZ9w&quot;&gt;视频2&lt;/a&gt;），就会发现虽然貌似很先进的样子，跟科幻片里的很像，然而由于人工智能和机器视觉的局限性，它们其实仍然处于玩具阶段。&lt;/p&gt;&lt;p&gt;特别是从第一个视频中你可以看到，这机器人头部旋转着一个很大的光学雷达（&lt;a href=&quot;https://en.wikipedia.org/wiki/Lidar&quot;&gt;Lidar&lt;/a&gt;），虽然能拿起箱子，然而它只能在很简单，理想化的环境下才能做到，而且动作相当的缓慢和笨拙。箱子必须是方形的，而且必须有特殊的记号或者二维码在上面，这样机器人才能知道从哪里下手。拿起箱子的时候，它并不像人那样，可以感受到箱子的重心在哪里，所以它只是随意的把“手”（其实是两个橡胶垫）夹上去。箱子重心不稳，所以摇摇晃晃的，很容易滑落下来。至于机器人推门出去雪地上走的镜头，其实是&lt;a href=&quot;http://www.bloomberg.com/news/articles/2016-03-18/why-google-wants-to-sell-its-robots-reality-is-hard&quot;&gt;有人遥控&lt;/a&gt;的，它并不能完全独立的探索外面的世界。被人踢倒在地，它真的是像“终结者”一样爬起来的吗？不是的。它爬起来的动作，很像一只蚂蚱，而且很慢。我很难想象，这样的机器人在战场上被人踹倒之后，能够及时爬起并且活下来。&lt;/p&gt;&lt;p&gt;所以BD的机器人，其实是拿来做搬运工都不合格的，更不要说做士兵了。它们的“智能”，其实跟家用的&lt;a href=&quot;https://www.neatorobotics.com/&quot;&gt;机器人吸尘器&lt;/a&gt;，没有很大的差别。在如此理想化的条件下，普通的工业机器人其实就能搬运箱子，而且效率高很多。看看这些&lt;a href=&quot;https://www.youtube.com/watch?v=UtBa9yVZBJM&quot;&gt;Amazon配送中心的机器人&lt;/a&gt;就知道，制造人形的机器人来做一些事情，完全是多此一举。只要你简化环境，就可以让普通没有智能的机器人，做很多有用的事情。&lt;/p&gt;&lt;p&gt;BD之前是由美国国防部和和海军陆战队投资，进行机器人的研究。我们都知道，军方的钱是非常容易骗，可以放心大胆的烧。到时候东西做出来能不能用，就是另外一回事。拿军方的钱多舒服，没压力，所以这样的公司不拿军方的钱，把自己卖给Google，说明军方已经不想资助这样的项目了。Google的眼光有问题，买下来才发现这些个玩具，离能够投入实际使用，恐怕还需要几十年上百年。于是暗自惊呼上当，赶快转手。&lt;/p&gt;&lt;p&gt;另外一种谣言是说，Google早就知道BD的机器人是不能用的。买下这公司，其实是拿来给Android的创始人Andy Rubin做玩具（圣诞礼物）的。因为Rubin很喜欢机器人，从小就梦想做自己的机器人，却壮志未酬。哪知道Rubin后来离开了Google，所以这玩具公司也就没必要留着了。Google创始人对高层领导的宠幸和溺爱，由此可见一斑。&lt;/p&gt;&lt;h3&gt;D-Wave量子计算机&lt;/h3&gt;&lt;p&gt;Google似乎总是喜欢做这种吸引眼球的项目，显得自己高大上，却不能真正的成功。Google投资的另外一个泡沫项目，叫做D-Wave量子计算机。D-Wave是一个加拿大公司，号称利用低温超导技术，制造出了具有上千个&lt;a href=&quot;https://en.wikipedia.org/wiki/Qubit&quot;&gt;qubit&lt;/a&gt;的量子计算机，能解决NP-Complete的问题。Google图着量子计算的虚名，花了很大的价钱买了一台D-Wave的机器，于是时不时的要冒出一些新闻。比如&lt;a href=&quot;http://www.techtimes.com/articles/114614/20151209/googles-d-wave-2x-quantum-computer-100-million-times-faster-than-regular-computer-chip.htm&quot;&gt;这个新闻&lt;/a&gt;说，Google声称经过自己测试，D-Wave的计算速度，是普通计算机的一亿倍！&lt;/p&gt;&lt;p&gt;然而，真正的量子计算专家，比如&lt;a href=&quot;http://scottaaronson.com/blog/?s=dwave&quot;&gt;Scott Aaronson&lt;/a&gt;，早就揭露过，由于环境对量子的干扰，要实现一千个qubit的量子计算机，难度是非常大，甚至是不可能的。D-Wave所谓的“量子计算机”，其实并不具有正确的“量子态”，不具有真正的量子计算能力，它其实最多算是一台“模拟计算机”。对于模拟计算机，其实研究已经很多了。模拟计算机确实可以在某些非常特殊的问题上，比数字计算机快几个数量级。然而，由于模拟计算机与生俱来的“误差问题”，它不能用于通用的计算，更不能用来解决NP-Complete的问题。实际上没有任何研究表明，量子计算机是可以解决NP-Complete问题的。&lt;/p&gt;&lt;p&gt;Google声称D-Wave的机器比普通计算机快一亿倍，用的是什么样的测试呢？他们的测试并不是一个全面的benchmark，它其实只包括一个问题：模拟退火。望文生义你就可以知道，退火这问题，本来就是非常适合用模拟计算机来解决的。D-Wave是个模拟计算机，它做退火的速度，当然比数字计算机快很多了。解决一个问题快了一亿倍，可是它却不能以同样的速度解决其它的问题，甚至无法解决普通计算机能解决的那些问题。一个机器要被叫做“计算机”，它应该具有比较全面的解题能力。如果只能解决一个问题，那它根本就不算是一个计算机，最多算是个物理实验 :P&lt;/p&gt;&lt;p&gt;再来看看，D-Wave解决了量子计算机本来应该可以解决的问题吗？没有。否则的话，一千个qubit的机器，应该能实现著名的“&lt;a href=&quot;https://en.wikipedia.org/wiki/Shor%27s_algorithm&quot;&gt;Shor算法&lt;/a&gt;”，从而可以很快的分解很大的整数，从而就能破解相当长度的RSA秘钥！Google为何不用D-Wave来破解RSA，引起全球轰动和震惊呢？因为它做不到。D-Wave压根就不是量子计算机，所以不能实现快速的大数分解。&lt;/p&gt;&lt;p&gt;其实很多人早就知道，D-Wave不是真正的量子计算机，而Google却堂而皇之的以讹传讹，打着“量子计算”的招牌，发布自己的测试结果。我不知道他们是真的不知道，还是故弄玄虚，吸引外行的眼球，长自己的威风。&lt;/p&gt;&lt;h3&gt;Google Glass&lt;/h3&gt;&lt;p&gt;世界忘不了你，Google Glass。当它刚出现的时候，Google可秀了不少神奇的视频。要查地图导航，滴滴滴，Glass直接把导航路线投射到地面上，指引你前进！在书店里说想找的书名，刷刷，Glass在空气中划出一条明亮的路线，在书架之间蜿蜒穿行，指引你到摆放它的位置，…… 多么神奇，多么美好！&lt;/p&gt;&lt;p&gt;可是到最后，Google Glass做到了这些炫酷的功能吗？门都没有摸到！一开头Google就应该意识到，这样的视网膜光学投影，把虚拟的线条和人眼看到的实际物体合并在一起，是非常难办的问题。电影特效倒好做，实现起来就发现按照Google Glass的硬件能力，完全不可能。而且Google怎么可能有时间和精力，去输入书店里摆放书的位置。这年头还有多少人逛书店，这功能不是吃饱了撑着是什么 :P&lt;/p&gt;&lt;p&gt;这教训就是，一开头牛皮不要吹得太大，不然会摔得很惨。最后的Google Glass，感觉就是一个戴在头上的手机屏而已，并没有发挥头戴设备的任何特点。电池寿命不到半小时，而且它的镜腿还不能折叠，取下来就不知道该放哪里了。所以买了的人都发现没什么用处，可是价格不菲啊，只想把它转手倒卖出去。&lt;/p&gt;&lt;p&gt;Google Glass吹够了牛皮，忽然人间蒸发了。可惜的是，粉丝们仍然没有看透Google的一贯作风，他们仍然相信Google夸出的各种海口，盼望这位“巨人”制造出伟大的新产品。&lt;/p&gt;&lt;h3&gt;自动车&lt;/h3&gt;&lt;p&gt;关于Google的自动车，我已经有&lt;a href=&quot;http://www.jianshu.com/p/01d1b2542036&quot;&gt;专文&lt;/a&gt;介绍了。自动车是一个美好的幻想，可是物体识别等AI问题，却很难解决。&lt;/p&gt;&lt;p&gt;有人可能以为这种自动车“够好用”就可以，因为世界上有那么多糟糕的司机，酒后驾车的，意外情况判断失误的，…… 所以Google的自动车也不需要完美，能大幅度减少车祸概率，就是人类的福气了。然而从道德和法律意义上来讲，自动车却必须要接近完美才可以。可能有人会犯的错误，它却不可以犯。这是为什么呢？原因在于，坐这辆犯了错误的自动车，导致身体残疾的人，如果是他自己开车，他可能根本不会烦这样的错误。诚然，其它人可能在这种情况也会犯错误，但其他人会犯错误，跟这个受害的人毫无关系。他会告上法庭，说：“如果是我开车，肯定不会导致车祸，以至于我自己变成残疾。所以Google的自动车对此负有严重的责任。” 明白了吗？只是能从“宏观”意义上减少车祸是不够的。自动车的驾驶技术，必须超过世界上最安全的驾驶员，它完全不可以犯错误。&lt;/p&gt;&lt;p&gt;所以Google的自动车，离能够实用差的天远，却喜欢到处游说，甚至要求政府监管部门大开绿灯。Google为何如此执着？我的猜测是，Google并不是真的想让自动车能够投入实用。显然，研究这些东西，可以显得自己很高大上，技术实力强。这样一来，recruiter们就可以对刚毕业的学生们说：“看那，我们Google有各种刺激的，开创未来的项目。快加入我们吧！” 等你进去，才发现那些炫酷的项目，其实根本没机会进去。虽然拿着机器视觉的PhD，却无法进入自动车的项目。只有老老实实写些JavaScript，改进一下Adwords，给Gmail加个小不点的功能进去，…… 然后你走出Google的时候，就不小心变成了这个样子：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-70d90bceba863a4b.gif?imageMogr2/auto-orient/strip&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;其实完全无人控制的自动车，且不说能不能实现，它真的有必要吗？现在很多汽车公司（&lt;a href=&quot;http://www.subaru.com/engineering/eyesight.html&quot;&gt;Subaru&lt;/a&gt;，&lt;a href=&quot;http://automobiles.honda.com/accord-sedan/features.aspx#sensing&quot;&gt;本田&lt;/a&gt;，&lt;a href=&quot;https://www.mbusa.com/mercedes/benz/safety#module-2&quot;&gt;奔驰&lt;/a&gt;，……）都可以实现自动防撞刹车功能，这才是人们最需要的，而且难度不是特别高。一旦人们发现满足了基本的安全需求，就不会想要完全自动的车了。所以我预测，Google自动车很可能再过一阵子就会跟Google Glass一样，人间蒸发掉。我们走着瞧吧 :)&lt;/p&gt;&lt;h3&gt;Chromecast&lt;/h3&gt;&lt;p&gt;再来看看Chromecast吧。Chromecast刚出现的时候，有些人也是热情高涨，甚至有国内朋友托我帮他买一个寄回国。我说这玩意比起Apple TV有什么特色吗？回答说：这是Google造的，肯定很牛，比Apple TV牛很多，一定要帮我买！于是等我要帮他买的时候，发现已经供不应求断货了。&lt;/p&gt;&lt;p&gt;直到我自己用过Chromecast，才发现这东西就像一个未完工的intern项目，根本不能用！我当然不会去买个Chromecast。我用它是因为有天买了个投影机，免费附送了一个Chromecast。心想免费送的就试试呗，结果用了几次之后，发现简直bug百出。虽然我的是免费附送，但是这东西单独卖也要$35。这样质量的东西，Google你也好意思拿出来卖钱吗？！&lt;/p&gt;&lt;p&gt;放YouTube视频的时候，它可以把视频加入播放队列，或者可以立即播放。可是队列播放和立即播放的逻辑，却是混乱的。有时候你本来想让它立即播放，它却把你之前放进去的视频给放了出来，仿佛你是在队列播放。所以我后来发现，这东西总是不放我现在想看的视屏，烦死人了。&lt;/p&gt;&lt;p&gt;更搞笑的是它的Chrome插件，有时候播放列表里面，忽然出现“[object Object]”这样的东西。显然是某些初级JavaScript码工，把某个对象给直接“+”到了一个字符串上面。试试吧，在浏览器里打开开发界面，输入&lt;code&gt;&quot;&quot;+{x:1}&lt;/code&gt;，你就得到&lt;code&gt;&quot;[object Object]&quot;&lt;/code&gt;。连这么低级的bug都放进去了，我就怀疑他们到底自己有没有用过自己的产品。&lt;/p&gt;&lt;p&gt;我永远无法理解人们对这类Google产品的热情。最后，由于我对那个投影机也不是很满意，所以把投影机和Chromecast一起退给了Amazon。后来买了Apple TV，发现跟Chromecast比起来，简直天壤之别，好用顺畅很多，一点问题没有。&lt;/p&gt;&lt;p&gt;可能因为退货比例太高，Chromecast现在已经从Amazon下架了。&lt;/p&gt;&lt;h3&gt;Go语言&lt;/h3&gt;&lt;p&gt;Go语言，也是Google最爱炫耀的技术之一。我之前的&lt;a href=&quot;http://www.yinwang.org/blog-cn/2014/04/18/golang&quot;&gt;文章&lt;/a&gt;已经分析的很清楚了，Go语言就是一坨屎。每个研究过PL的人，都在嘲笑Go语言的设计，笑掉了大牙。&lt;/p&gt;&lt;p&gt;Google对于真正的计算机科学，程序语言的研究，远远不如微软，Intel，Oracle（Sun），IBM，Cisco。基本就是业余水平。很可惜的是，Google仍然可以靠着自己在网络界的影响力，面对专家们的嘲笑，明目张胆在业界推广Go这个大垃圾，祸害其他人。你说我们这些PL人士，怎么可能不鄙视Google？&lt;/p&gt;&lt;p&gt;对了，Google还有另外一个垃圾语言，叫做Dart。Google内部还有一个自用的垃圾语言，叫做Sawzall。Sawzall的&lt;a href=&quot;https://en.wikipedia.org/wiki/Rob_Pike&quot;&gt;创造者&lt;/a&gt;，后来创造了Go。此人之前设计了&lt;a href=&quot;https://en.wikipedia.org/wiki/Plan_9_from_Bell_Labs&quot;&gt;Plan 9&lt;/a&gt;操作系统，自以为超越了Unix，而其实呢继承了Unix的所有糟粕，只含有一些肤浅的界面改动，而且还不怎么好用，所以后来根本没人用。不是我有偏见哈，可我发现的规律就是，制造垃圾的自大狂，永远都只会制造垃圾。&lt;/p&gt;&lt;p&gt;因为内行人都知道Google对于语言的造诣和态度之肤浅，所以几乎没有科班出生的程序语言专家愿意去Google工作。大部分最好的PL人员进入了微软，少数去了其它地方。&lt;/p&gt;&lt;h3&gt;Google的水平&lt;/h3&gt;&lt;p&gt;另外，Google的无线路由器OnHub，出来的时候大家也是热情高涨。最后一看Amazon的review，恶评如潮。自称“speak human”，可怎么就那么不人性化，那么难用呢！&lt;/p&gt;&lt;p&gt;别忘了Blogger，别忘了Orkut，Chrome OS, Chrome book，…… 哎，Google还有其它一系列失败的的产品和项目，公司里很多人做着一些穷途末路的项目，我就不多说了……&lt;/p&gt;&lt;p&gt;所以总的来说，Google有它的特长。它是一个不错的互联网公司，Google的搜索引擎做得很好，Gmail，收购来的YouTube，地图，Android什么的，也比较好用。但是Google的特长，也就停留在那里了。做其他事情，几乎全都是业余水准，却自以为了不起，喜欢宣传自己，制造高大形象。最近AlphaGo搞得沸沸扬扬，也是一样的用意，煽风造势，以此吸引懵懂没经验的年轻人，进去为它做一些琐碎的杂活，帮助它赚更多的广告钱。&lt;/p&gt;&lt;p&gt;这就是我眼里的Google。&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">google-vision</guid>
<pubDate>Thu, 17 Mar 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>AlphaGo与人工智能</title>
<link>http://yinwang.org/blog-cn/2016/03/09/alpha-go</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;AlphaGo与人工智能&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-585d20981fef6a5b.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/300&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;在之前的一篇&lt;a href=&quot;http://www.jianshu.com/p/01d1b2542036&quot;&gt;文章&lt;/a&gt;中我指出，自动驾驶所需要的“视觉识别能力”和“常识判断能力”，对于机器来说是非常困难的问题。至今没有任何机器可以在视觉方面达到驴的水平，更不要说和人比。可是最近Google的&lt;a href=&quot;https://deepmind.com/alpha-go.html&quot;&gt;AlphaGo&lt;/a&gt;战胜了围棋世界冠军，挺闹腾的，以至于对AI的误解又加深了。&lt;/p&gt;&lt;p&gt;本来玩个游戏而已，恁要吹成是“历史性的人机大战”，说得好像是机器挑战了人类的智能，伤了人类的自尊似的。这整个项目打着一个相当高大上的招牌，叫做“&lt;a href=&quot;http://deepmind.com&quot;&gt;Deep Mind&lt;/a&gt;”。当然，其中的技术也有一些吓人的名字，什么“神经网络”啊，“深度学习”啊……&lt;/p&gt;&lt;p&gt;听到这些，总有一知半解的人，根据科幻电影的情节开始展望，这样厉害的技术，应该可以用来做更加“智能”的事情，然后就开始对“人类的未来”作出一些猜想，比如自动车就要实现，人的工作很快都要被机器取代，甚至&lt;a href=&quot;https://en.wikipedia.org/wiki/Skynet_(Terminator&quot;&gt;Skynet&lt;/a&gt;)就要控制人类，云云。&lt;/p&gt;&lt;p&gt;我只想在这里给这些人提个醒：还是别做科幻梦了，回到现实吧。&lt;/p&gt;&lt;h3&gt;棋类是相对容易的AI问题&lt;/h3&gt;&lt;p&gt;一个常见的外行想法，是以为AlphaGo真的具有“人类智能”，所以Google利用同样的技术，应该可以实现自动车。这些人不但大大的高估了所谓“AI”的能力，而且他们不明白，不同的“AI问题”的难度，其实有着天壤之别。&lt;/p&gt;&lt;p&gt;围棋是简单的，世界是复杂的。机器视觉和自动车，难度比围棋要大许多倍，根本不在一个量级。要达到准确的视觉判断能力，机器必须拥有真正的认知能力和常识，这并不是AlphaGo所用的树搜索和神经网络，就可以解决的。由于需要以极高的速度处理“模拟信号”，这根本就不是人们常用的“数字计算机”可以解决的问题。也就是说，不是写代码就可以搞定的。&lt;/p&gt;&lt;p&gt;很早以前，人工智能专家们就发现一个很有趣的现象，是这样：&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;对于人来说很难，很烦的事情（复杂的计算，下棋，推理……），对于计算机来说，其实算是相对容易的事情。&lt;/li&gt;
&lt;li&gt;对于人来说很容易的事情（认人，走路，开车，打球……），对于计算机来说，却非常困难。&lt;/li&gt;
&lt;li&gt;计算机不能应付复杂的环境，只能在相对完美的环境下工作，需要精确的，离散的输入。&lt;/li&gt;
&lt;li&gt;人对环境的适应能力很高，擅长于处理模糊的，连续的，不完美的数据。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;从以上几点你可以看出，棋类活动正好符合了计算机的特点，因为它总是处于一种隔离的，完美的环境，具有离散的，精确的，有限的输入。棋盘上就那么几十，几百个点，不是随便放在哪里都可以的。一人走一步，轮流着走，不能乱来。整个棋盘的信息是完全可见的，没有隐藏和缺损的信息。棋局的“解空间”虽然很大，却非常规整，有规律可循。如果完全不靠经验和技巧的话，围棋的第一步可以有361种情况，第二步有360种情况，……&lt;/p&gt;&lt;p&gt;这对机器是非常有利的情况，因为计算机可以有计划有步骤，兢兢业业的把各种可能出现的情况算出来，一直到许多步以后，然后从中选择最有优势的走法。所以下棋归根结底，就是一个“树搜索”问题，只不过因为规模太大，需要加入一些优化。围棋的解空间虽然大，却是一个已知数，它最多有250&lt;sup&gt;150&lt;/sup&gt;种情况。AlphaGo使用所谓“神经网络”，就是为了在搜索的时候进行优化，尽早的排除不大可能取胜的情况，免得浪费计算的时间。&lt;/p&gt;&lt;p&gt;这种精确而死板的活动，就跟计算一个比较大的乘法算式（比如2463757 x 65389）的性质类似，只不过规模大很多。显然，人做这类事情很繁，很累，容易出错，计算机对此却任劳任怨，因为它本来就是个机器。当年“深蓝”战胜国际象棋世界冠军的时候，我就已经预测到，计算机成为围棋世界冠军是迟早的事，所以没必要玩这些虐待自己脑子的游戏了。可惜的是，挺多人仍然把精通棋艺作为一种荣耀（因为“琴棋书画剑”嘛）。很多中国人认为，中国人下围棋总是输给韩国人，是一种耻辱。现在看来这是多么可笑的事情，这就像心算乘法不如韩国人快，就觉得是耻辱一样 :)&lt;/p&gt;&lt;h3&gt;认知是真正困难的AI问题&lt;/h3&gt;&lt;p&gt;现在来对比一下人们生活中的琐事，就说倒水端茶吧。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-a2a10fbeb02f06e3.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/240&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;让一个机器来给你倒水，有多难呢？意想不到的难！看看这个场景，如果你的电脑配备有摄像头，那么它怎么知道茶壶在哪里呢？要知道，茶壶的材料，颜色，形状，和角度，可以有几乎无穷多的变化。甚至有些茶壶跟哈哈镜一样，会把旁边的物体的形状都扭曲反射出来。桌上的物品附近都有各种反光和阴影，不同材料的反光特性还不一样，这些都会大幅度的影响机器对物品的识别。&lt;/p&gt;&lt;p&gt;为了识别物体，机器需要常识，它的头脑里必须有概念，必须知道什么样的东西才能叫做“茶壶”和“茶杯”。不要小看这一步的难度，这意味着机器必须理解基本的“拓扑结构”，什么叫做“连续的平面”，什么叫做“洞”，什么是“凹”和“凸”，什么是“里”和“外”…… 另外，这机器必须能够分辨物体和阴影。它必须知道水是什么，水有什么样的运动特性，什么叫做“流动”。它必须知道“水往低处流”，然后它又必须知道什么叫“低”和“高”…… 它必须知道茶杯为什么可以盛水，茶壶的嘴在哪里，把手在哪里，怎样才能拿起茶壶。如果一眼没有看见茶壶的把手，那它在哪里？茶壶的哪一面是“上面”，要怎样才可以把水从茶壶的嘴里倒出来，而不是从盖子上面泼出来？什么是裂掉的茶杯，它为什么会漏水，什么是缺口的茶杯，它为什么仍然可以盛水而不漏？干净的茶杯是什么样子的，什么是脏的茶杯，什么是茶垢，为什么茶垢不算是脏东西？如何控制水的流速和落点，什么叫做“水溅出来了”，要怎么倒水才不会溅出来？……&lt;/p&gt;&lt;p&gt;你也许没有想到，倒茶这么简单的事情，需要用到如此多的常识。所有这些变数加在一起，其实远远的大于围棋棋局的数量，人却可以不费力的完成。这能力，真是应该让人自己都吓一跳，然而人却对此不以为然，称之为“琐事”！因为其他人都可以做这样的事情，甚至猴子都可以，怎么能显得出我很了不起呢？人的自尊和虚荣，再一次的蒙蔽了他自己。他没有意识到，这其实是非常宝贵，让机器难以匹敌的能力。他说：“机器经过大量的学习，总有一天会做到的。看我们有神经网络呢，还有深度学习！”&lt;/p&gt;&lt;h3&gt;机器学习是什么&lt;/h3&gt;&lt;p&gt;有些人喜欢拿“机器学习”或者“深度学习”来吓唬人，以为出现了“学习”两个字，就可以化腐朽为神奇。而其实所谓机器学习，跟人类的学习，完全是两回事。机器的“学习能力”，并没有比石头高出很多，因为机器学习说白了，只不过是通过大量的数据，&lt;a href=&quot;https://en.wikipedia.org/wiki/Curve_fitting&quot;&gt;统计拟合&lt;/a&gt;出某些函数的参数。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-e80aecf3dfb56edf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/300&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;比如，你采集到一些二维数据点。你猜测它们符合一个简单的函数 y = ax&lt;sup&gt;3&lt;/sup&gt; + bx&lt;sup&gt;2&lt;/sup&gt; + cx + d，但不知道a, b, c和d该是多少。于是你就利用所谓“机器学习”（也就是数学统计），推断出参数a, b, c和d的值，使得采集到的数据尽可能的靠近这函数的曲线。可是这函数是怎么来的呢？终究还是人想出来的。机器无论如何也跳不出y = ax&lt;sup&gt;3&lt;/sup&gt; + bx&lt;sup&gt;2&lt;/sup&gt; + cx + d这个框子。如果数据不符合这个范式，还是只有靠人，才能找到更加符合数据特性的函数。&lt;/p&gt;&lt;p&gt;所谓神经网络，其实也是一个函数，它在本质上跟y = ax&lt;sup&gt;3&lt;/sup&gt; + bx&lt;sup&gt;2&lt;/sup&gt; + cx + d并没有不同，只不过输入的参数多一些，逻辑复杂一些。“神经网络”跟神经，其实完全没有关系，却偏喜欢说是受到了神经元的启发而来的。神经网络是一个非常聪明的广告词，它不知道迷惑了多少人。因为有“神经”两个字在里面，很多人以为它会让机器具有智能，而其实这些就是统计学家们斯通见惯的事情：拟合一个函数。你可以拟合出很好的函数，然而这跟智能没什么关系。&lt;/p&gt;&lt;h3&gt;AlphaGo并不是人工智能历史性的突破&lt;/h3&gt;&lt;p&gt;这次AlphaGo战胜了围棋冠军，跟之前IBM的“&lt;a href=&quot;http://www.theverge.com/2016/3/12/11211306/ibm-deep-blue-murray-campbell-alphago-deepmind-interview&quot;&gt;深蓝&lt;/a&gt;”电脑战胜国际象棋世界冠军，意义其实差不多。能够写出程序，在这些事情上打败世界冠军，的确是一个进步，它肯定会对某些特定的应用带来改善。然而，这并不说明AI取得了革命性的进步，更不能表明电脑具有了真正的，通用的智能。恰恰相反，电脑能够在棋类游戏中战胜人类，正好说明下棋这种活动，其实并不需要很多的智能。从事棋类活动的能力，并不足以衡量人的智力。&lt;/p&gt;&lt;p&gt;著名的认知科学家&lt;a href=&quot;http://www.theatlantic.com/magazine/archive/2013/11/the-man-who-would-teach-machines-to-think/309529&quot;&gt;Douglas Hofstadter&lt;/a&gt;（《&lt;a href=&quot;https://en.wikipedia.org/wiki/G%C3%B6del,_Escher,_Bach&quot;&gt;GEB&lt;/a&gt;》的作者），早就指出AI领域的那些热门话题，比如电脑下棋，跟真正意义上的人类智能，几乎完全不搭边。绝大部分人其实不明白思考和智能到底是什么。大部分所谓AI专家，对人脑的工作原理所知甚少，甚至完全不关心。&lt;/p&gt;&lt;p&gt;AlphaGo所用的技术，也许能够用于其它同类的游戏，然而它并不能作为解决现实问题的通用方法。特别是，这种技术不可能对自动车的发展带来突破。自动车如果只比开车技术很差的人强一点，是不可接受的。它必须要近乎完美的工作，才有可能被人接受，然而这就要求它必须具有人类级别的视觉认知能力。比如，它必须能够察觉到前面车上绑了个家具，没绑稳，快要掉下来了，赶快换车道，超过它。可惜的是，自动车的“眼睛”里看到的，只是一个个的立方块，它几乎完全不理解身边到底发生着什么，它只是在跟随和避让一些线条和方块…… 我们多希望马路都是游戏一样简单，清晰，完美，没有意外的，可惜它不是那样的。每一个细节都可能关系到人的生死，这就是现实世界。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://www.dailymail.co.uk/sciencetech/article-3491916/Google-admits-self-driving-car-got-wrong-Bus-crash-caused-software-trying-predict-driver-do.html&quot;&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-585cdc79ddbab240.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/400&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;为AlphaGo热血沸腾的人们，别再沉迷于自动车和Skynet之类的幻想了。看清AI和“神经网络”的实质，用它们来做点有用的东西就可以，没必要对实现“人类智能”抱太大的希望。&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">alpha-go</guid>
<pubDate>Wed, 09 Mar 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>不要去SeaWorld</title>
<link>http://yinwang.org/blog-cn/2016/02/25/sea-world</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;不要去SeaWorld&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;displayed&quot; src=&quot;http://www.yinwang.org/images/orca.jpg&quot;&gt;&lt;/p&gt;&lt;p&gt;很多人喜欢海洋动物，比如海豚和“杀人鲸”（orca），但是我建议不要去海洋世界看它们。海豚和杀人鲸都是有灵性的，跟人类的智慧很接近，而且对人极其友好的动物。“杀人鲸”名字吓人，但是其实根本不吃人，野生的杀人鲸从来没有伤过人。&lt;/p&gt;&lt;p&gt;事实是，像SeaWorld之类的所谓“海洋世界”，无情的把这些动物绑架，把它们从小与自己的父母分离。在SeaWorld里，这些动物如同坐牢。住的，吃的，都比它们原来的生活差很多，更是没有父母的关爱，兄弟姐妹的温暖。本来可以活上百年的杀人鲸，在SeaWorld里只能活一二十年。&lt;/p&gt;&lt;p&gt;花钱去SeaWorld之类的地方，等同于给绑架者送钱，请不要再带着小孩子去赞助这些绑架者了！如果你真的爱这些动物，请坐船去海里拜访他们吧。如果你还不明白我在说什么，建议你看看一些关于杀人鲸的片子，比如《&lt;a href=&quot;http://www.imdb.com/title/tt2545118&quot;&gt;Blackfish&lt;/a&gt;》和《&lt;a href=&quot;http://www.imdb.com/title/tt0106965&quot;&gt;Free Willy&lt;/a&gt;》。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://www.imdb.com/title/tt2545118&quot;&gt;&lt;img src=&quot;http://www.yinwang.org/images/blackfish.jpg&quot; width=&quot;45%&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;http://www.imdb.com/title/tt0106965&quot;&gt;&lt;img src=&quot;http://www.yinwang.org/images/free-willy.jpg&quot; width=&quot;45%&quot;&gt;&lt;/a&gt;&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">sea-world</guid>
<pubDate>Thu, 25 Feb 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>我看自动驾驶技术</title>
<link>http://yinwang.org/blog-cn/2016/02/12/self-driving-car</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;我看自动驾驶技术&lt;/h2&gt;&lt;p&gt;这段时间，Google的自动车，Tesla的autopilot，经常出现在新闻头条。人们热烈的讨论自动驾驶技术，对这“科幻般”的技术充满了憧憬，好奇，甚至恐惧。Google说：“自动车很安全。人类是糟糕的驾驶员。” 很多人不假思索就接受了这种观点，以为自己不久以后就会被自动车所代替，所以我今天想谈谈对这些“自动车”的看法。&lt;/p&gt;&lt;p&gt;从我的另一篇&lt;a href=&quot;http://www.jianshu.com/p/1f6f624d9815&quot;&gt;文章&lt;/a&gt;，你应该已经看到，Tesla的autopilot其实根本不算是“自动驾驶”，它完全不能和Google的自动车相比。Tesla把这种不成熟的软件推送到用户的车里，为的只是跟Google抢风头，塑造自己的高大形象。看，我们先出了自动车！可是呢，Tesla那东西顶多算一个“adaptive cruise control”，离真正的自动驾驶还很遥远。可惜的是，Tesla为了自己的名声，拿用户的性命当儿戏，还有些人为它叫好。&lt;/p&gt;&lt;p&gt;然而就算是Google的自动车，离能够投入使用，其实还差得很远。我这里说的“很远”，不是像某些人预测的10年，20年，而是至少100年，1000年…… 甚至永远无法实现。这是为什么呢？Google不是声称，每天都要让它的自动车“学习”上百万mile的行驶记录吗？难道学习了如此的“大数据”，不能让这车子变得跟人一样聪明吗？&lt;/p&gt;&lt;p&gt;如果你这么想，那你可能根本不了解人工智能（AI）。需要“学习上百万mile”，并不能说明自动车很聪明。恰恰相反，这说明它们很笨。只需要问自己一个问题：一个人要学会开车，需要开多少里程？普通人从完全不会，到能安全上路，一般只需要12节课，每节课1小时。就算这一个小时你都在高速公路上开，也就80 mile的样子。12个小时就960 mile。也就是说，普通人只需要小于1000 mile的驾驶，就能成为比较可靠的司机。&lt;/p&gt;&lt;p&gt;对比一下Google的自动车，它们每天“分析”和“学习”一百万mile的“虚拟里程”，而且经常在外面采集数据，累计上百万的mile。然而这些自动车，仍然只能在白天，天气好的时候，在道路环境非常简单的Mountain View行驶。Mountain View就是一个小镇子，总共就没几条路，路上几乎没有行人。我从未在时速超过50mph的公路上，或者交通复杂的大城市，见到过Google的自动车。&lt;/p&gt;&lt;p&gt;另外据最近的&lt;a href=&quot;http://www.forbes.com/sites/brookecrothers/2016/01/13/google-self-driving-car-failures-total-272-over-one-year-but-improvement-seen&quot;&gt;报道&lt;/a&gt;，Google的自动车在过去一年时间里，发生了272起需要“人工干预”的错误情况。如果人不及时抢过控制权，不少情况会出现车祸。在如此简单的条件下，还需要如此多的人工干预。如果环境稍微复杂一些，自动车恐怕就完全不知所措了。&lt;/p&gt;&lt;p&gt;这里还有一个“特殊关照”的问题，由于Google的自动车身上有着明显的标志，行人和其它驾驶员看到它，其实都有点提心吊胆的，不敢轻举妄动，怕它犯傻撞了自己，这也变相的降低了自动车的环境复杂度。一旦Google把车身上的标志去掉，大家看不出来谁是自动车，不对它们进行特殊的关照，我行我素，事故率恐怕就上去了。&lt;/p&gt;&lt;p&gt;所以Google的自动车，离能够投入真正的使用，差距还非常远。在这种情况下就妄言“自动车很安全”，“人类是糟糕的驾驶员”，…… 未免也太早了些吧？自动车跟人类差距到底有多远呢？天壤之别。普通人只需要开1000 mile就能学会开车，而这些自动车学习了几百万，几千万，几亿mile，仍然门都没有摸到。这说明自动车跟人类的运动神经，有着根本的区别。&lt;/p&gt;&lt;p&gt;人在运动的时候看见一个物体，他的头脑里会立即闪现与之相应的“概念”，然后很快浮现出这种东西的运动特点，以及相应的对策。相比之下，自动车看到物体，它并不能准确的判断它是什么东西：它是一个车，一个人，一棵树，一个施工路障，一个大坑，还是前面的车掉下来的床垫呢？所以自动车就像一个智障儿童，学了这么久连什么是什么都不知道，却有人指望它们在十年之内能开车穿越美国。&lt;/p&gt;&lt;p&gt;对的，自动车配备了GPS，激光，雷达，…… 它的“感官”接收到很多的数据，有些是人类无法感觉到的。然而自动车的“头脑”（电脑），是没有认知能力的，所以就算收集到了大量的数据，它仍然不知道那东西是什么，它们之间是什么关系。电脑没有这些“常识”，所以它无法为人做出正确的判断。在危急的关头，它很可能会做出危及乘客安全的决定。“认知”是一个根本性的问题，AI领域至今没有解决它，甚至根本没有动手去研究它。&lt;/p&gt;&lt;p&gt;自动车使用的所谓“机器学习”的技术，跟人类的“学习”，完全是两回事。举个例子，一个小孩从来没见过猫，你只需要给她一只猫，告诉他这是“猫咪”。下一次，当她见到不管什么颜色的猫，不管它摆出什么姿势，都知道这是“猫咪”。现在的电脑，认知能力其实比小孩子，甚至其它动物都差很多。你先让电脑分析上百万张猫的照片，各种颜色，各种姿势，各种角度，拿一只猫摆在它的摄像头面前，让它看整整一年…… 最后它仍然不理解猫是什么，不能准确的判断一个东西是否是猫。如果说电脑有智商，那么它的级别就像一个蠕虫，甚至连蠕虫都不如。电脑没有认识和适应环境的能力，所以就算它再用功，“学习”再多的数据，都是白费劲。&lt;/p&gt;&lt;p&gt;很多人听说“人工智能”（AI），或者“机器学习”（machine learning），“深度学习”（deep learning）这类很酷的名词，就想起科幻小说里的智能机器人，就以为科幻就要成为现实。等你真的进入“机器学习”这领域，才发现一堆堆莫名其妙，稀里糊涂的做法，最后其实不怎么管用。这些大口号，包括所谓“深度学习”，其实跟人的思维方式，几乎完全不搭边。所谓“机器学习”，不过是一些普通的统计方法，拟合一些函数参数。吹得神乎其神，倒让统计专业的人士笑话。&lt;/p&gt;&lt;p&gt;人工智能在80年代出现过一次热潮。当时人们乐观的相信，电脑在不久就会拥有人类的智能。日本还号称要动员全国的力量，制造所谓“第五代计算机”，发展智能的编程语言（比如Prolog）。结果最后呢？人们意识到，超越人类（动物）的智能，比他们想象的困难太多太多。浮夸的许诺没能实现，AI领域进入了冬天。最近因为“大数据”，“自动车”和“Internet of Things”等热门话题的出现，“AI热”又死灰复燃。然而当今的AI，其实并没有比80年代的进步很多。人们对于自己的脑子以及感官的工作原理，仍然所知甚少，却盲目的认为那些从统计学偷来的概念，改名换姓叫“机器学习”，就能造出跟自己的头脑媲美的机器。这些人其实大大的低估了自己身体的神奇程度。&lt;/p&gt;&lt;p&gt;视觉和认知能力，是动物（包括人类）特有的，卓越的能力。它们让动物能够准确的感知身边复杂的世界，对此作出适合自己生存的计划。一辆能够穿越整个国家的自动车，它必须适应各种复杂的环境：天气，路况，交通，意外情况…… 所以它需要动物的认知能力。我并不是说机器永远不可能具有这种能力，然而如果你根本不去欣赏，研究和理解这种能力，倒以为所谓“机器学习”就能办到这些事情，张口闭口拿“人类”说事，你又怎么可能用机器实现它呢？我的预测是，直到人类能够完全的理解动物的脑子和感官如何工作，才有可能制造出能够接近人类能力的自动车。&lt;/p&gt;&lt;p&gt;诚然，有少数人开车不小心，甚至酒后驾车，导致了很多的车祸。然而因此就声称“人类是糟糕的驾驶员”，那就是以偏概全了。大部分的人还是遵纪守法，注意安全的。很多人开车几十年，从没出过车祸。另外，我们必须把“态度”和“能力”区分开来看。酒后驾车的人，不是技术不够好，而是态度有问题。电脑当然没有态度问题，然而它的技术确实难以达到人的水平。就算那些酒后驾车的人，他们的能力其实也远远在电脑之上。我无法想象当今的电脑技术，要如何才能超越驾驶技术好的人，以及职业赛车手。&lt;/p&gt;&lt;p&gt;如果你还没明白，也许下面这个图片可以把你拉回到现实世界：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/68562-39e22022670591ee.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/400&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;一个机器，如何能知道旁边的车上正在发生什么，即将可能发生什么样的危险情况呢？它如何知道，需要赶快避开这辆车呢？它不能。一个没有认知能力的机器，是难以应付复杂多变的现实世界的。&lt;/p&gt;&lt;p&gt;现在人们对于自动车技术的关注，热情，盲目乐观和浮夸，感觉跟文化大革命，“大跃进”年代的思维方式类似。只不过现在“毛泽东”换成了Google或者Tesla，“每亩产量十万”换成了“两年之内自动驾驶穿越美国”…… 我觉得与其瞎折腾自动驾驶技术，不如做点脚踏实地，在短期内能够见效，改善人们生活的东西。&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">self-driving-car</guid>
<pubDate>Fri, 12 Feb 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>给Java说句公道话</title>
<link>http://yinwang.org/blog-cn/2016/01/18/java</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;给Java说句公道话&lt;/h2&gt;&lt;p&gt;有些人问我，在现有的语言里面，有什么好的推荐？我说：“Java。” 他们很惊讶：“什么？Java！” 所以我现在来解释一下。&lt;/p&gt;&lt;h3&gt;Java超越了所有咒骂它的“动态语言”&lt;/h3&gt;&lt;p&gt;也许是因为年轻人的逆反心理，人们都不把自己的入门语言当回事。很早的时候，计算机系的学生用Scheme或者Pascal入门，现在大部分学校用Java。这也许就是为什么很多人恨Java，瞧不起用Java的人。提到Java，感觉就像是爷爷那辈人用的东西。大家都会用Java，怎么能显得我优秀出众呢？于是他们说：“Java老气，庞大，复杂，臃肿。我更愿意探索新的语言……”&lt;/p&gt;&lt;p&gt;某些Python程序员，在论坛里跟初学者讲解Python有什么好，其中一个原因竟然是：“因为Python不是Java！” 他们喜欢这样宣传：“看Python多简单清晰啊，都不需要写类型……” 对于Java的无缘无故的恨，盲目的否认，导致了他们看不到它很重要的优点，以至于迷失自己的方向。虽然气势上占上风，然而其实Python作为一个编程语言，是完全无法和Java抗衡的。&lt;/p&gt;&lt;p&gt;在性能上，Python比Java慢几十倍。由于缺乏静态类型等重要设施，Python代码有bug很不容易发现，发现了也不容易debug，所以Python无法用于构造大规模的，复杂的系统。你也许发现某些startup公司的主要代码是Python写的，然而这些公司的软件，质量其实相当的低。在成熟的公司里，Python最多只用来写工具性质的东西，或者小型的，不会影响系统可靠性的脚本。&lt;/p&gt;&lt;p&gt;静态类型的缺乏，也导致了Python不可能有很好的IDE支持，你不能完全可靠地“跳转到定义”，不可能完全可靠地重构（refactor）Python代码。PyCharm对于早期的Python编程环境，是一个很大的改进，然而理论决定了，它不可能完全可靠地进行“变量换名”等基本的重构操作。就算是比PyCharm强大很多的PySonar，对此也无能为力。由于Python的设计过度的“动态”，没有类型标记，使得完全准确的定义查找，成为了不可判定（undecidable）的问题。&lt;/p&gt;&lt;p&gt;在设计上，Python，Ruby比起Java，其实复杂很多。缺少了很多重要的特性，有毛病的“强大特性”倒是多了一堆。由于盲目的推崇所谓“正宗的面向对象”方式，所谓“&lt;a href=&quot;https://en.wikipedia.org/wiki/Late_binding&quot;&gt;late binding&lt;/a&gt;”，这些语言里面有太多可以“重载”语义的地方，不管什么都可以被重定义，这导致代码具有很大的不确定性和复杂性，很多bug就是被隐藏在这些被重载的语言结构里面了。因此，Python和Ruby代码很容易被滥用，不容易理解，容易写得很乱，容易出问题。&lt;/p&gt;&lt;p&gt;很多JavaScript程序员也盲目地鄙视Java，而其实JavaScript比Python和Ruby还要差。不但具有它们的几乎所有缺点，而且缺乏一些必要的设施。JavaScript的各种“WEB框架”，层出不穷，似乎一直在推陈出新，而其实呢，全都是在黑暗里瞎蒙乱撞。JavaScript的社区以幼稚和愚昧著称。你经常发现一些非常基本的常识，被JavaScript“专家”们当成了不起的发现似的，在大会上宣讲。我看不出来JavaScript社区开那些会议，到底有什么意义，仿佛只是为了拉关系找工作。&lt;/p&gt;&lt;p&gt;Python凑合可以用在不重要的地方，Ruby是垃圾，JavaScript是垃圾中的垃圾。原因很简单，因为Ruby和JavaScript的设计者，其实都是一知半解的民科。然而世界就是这么奇怪，一个彻底的垃圾语言，仍然可以宣称是“程序员最好的朋友”，从而得到某些人的爱戴……&lt;/p&gt;&lt;h3&gt;Java的“继承人”没能超越它&lt;/h3&gt;&lt;p&gt;最近一段时间，很多人热衷于Scala，Clojure，Go等新兴的语言，他们以为这些是比Java更现代，更先进的语言，以为它们最终会取代Java。然而这些狂热分子们逐渐发现，Scala，Clojure和Go其实并没有解决它们声称能解决的问题，反而带来了它们自己的毛病，而这些毛病很多是Java没有的。然后他们才意识到，Java离寿终正寝的时候，还远得很……&lt;/p&gt;&lt;p&gt;&lt;em&gt;Go语言&lt;/em&gt;&lt;/p&gt;&lt;p&gt;关于Go，我已经评论过很多了，有兴趣的人可以看&lt;a href=&quot;http://www.yinwang.org/blog-cn/2014/04/18/golang&quot;&gt;这里&lt;/a&gt;。总之，Go是民科加自大狂的产物，奇葩得不得了。这里我就不多说它了，只谈谈Scala和Clojure。&lt;/p&gt;&lt;p&gt;&lt;em&gt;Scala&lt;/em&gt;&lt;/p&gt;&lt;p&gt;我认识一些人，开头很推崇Scala，仿佛什么救星似的。我建议他们别去折腾了，老老实实用Java。没听我的，结果到后来，成天都在骂Scala的各种毛病。但是没办法啊，项目上了贼船，不得不继续用下去。我不喜欢进行人身攻击，然而我发现一个语言的好坏，往往取决于它的设计者的背景，觉悟，人品和动机。很多时候我看人的直觉是异常的准，以至于依据对语言设计者的第一印象，我就能预测到这个语言将来会怎么发展。在这里，我想谈一下对Scala和Clojure的设计者的看法。&lt;/p&gt;&lt;p&gt;Scala的设计者Martin Odersky，在PL领域有所建树，发表了不少学术论文（ 包括著名的《&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1889&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;The Call-by-Need Lambda Calculus&lt;/a&gt;》），而且还是大名鼎鼎的&lt;a href=&quot;https://en.wikipedia.org/wiki/Niklaus_Wirth&quot;&gt;Niklaus Wirth&lt;/a&gt;的门徒，我因此以为他还比较靠谱。可是开始接触Scala没多久，我就很惊讶的发现，有些非常基本的东西，Scala都设计错了。这就是为什么我几度试图采用Scala，最后都不了了之。因为我一边看，一边发现让人跌眼镜的设计失误，而这些问题都是Java没有的。这样几次之后，我就对Odersky失去了信心，对Scala失去了兴趣。&lt;/p&gt;&lt;p&gt;回头看看Odersky那些论文的本质，我发现虽然理论性貌似很强，其实很多是在故弄玄虚（包括那所谓的“call-by-need lambda calculus”）。他虽然对某些特定的问题有一定深度，然而知识面其实不是很广，眼光比较片面。对于语言的整体设计，把握不够好。感觉他是把各种语言里的特性，强行拼凑在一起，并没有考虑过它们是否能够“和谐”的共存，也很少考虑“可用性”。&lt;/p&gt;&lt;p&gt;由于Odersky是大学教授，名声在外，很多人想找他拿个PhD，所以东拉西扯，喜欢往Scala里面加入一些不明不白，有潜在问题的“特性”，其目的就是发paper，混毕业。这导致Scala不加选择的加入过多的特性，过度繁复。加入的特性很多后来被证明没有多大用处，反而带来了问题。学生把代码实现加入到Scala的编译器，毕业就走人不管了，所以Scala编译器里，就留下一堆堆的历史遗留垃圾和bug。这也许不是Odersky一个人的错，然而至少说明他把关不严，或者品位确实有问题。&lt;/p&gt;&lt;p&gt;最有名的采用Scala的公司，无非是Twitter。其实像Twitter那样的系统，用Java照样写得出来。Twitter后来怎么样了呢？CEO都跑了 :P 新CEO上台就裁员300多人，包括工程师在内。我估计Twitter裁员的一个原因是，有太多的Scala程序员，扯着各种高大上不实用的口号，比如“函数式编程”，进行过度工程，浪费公司的资源。花着公司的钱，开着各种会议，组织各种meetup和hackathon，提高自己在open source领域的威望，其实没有为公司创造很多价值……&lt;/p&gt;&lt;p&gt;&lt;em&gt;Clojure&lt;/em&gt;&lt;/p&gt;&lt;p&gt;再来说一下Clojure。当Clojure最初“横空面世”的时候，有些人热血沸腾地向我推荐。于是我看了一下它的设计者Rich Hickey做的宣传讲座视频。当时我就对他一知半解拍胸脯的本事，印象非常的深刻。Rich Hickey真的是半路出家，连个CS学位都没有。可他那种气势，仿佛其他的语言设计者什么都不懂，只有他看到了真理似的。不过也只有这样的人，才能创造出“宗教”吧？&lt;/p&gt;&lt;p&gt;满口热门的名词，什么lazy啊，pure啊，STM啊，号称能解决“大规模并发”的问题，…… 这就很容易让人上钩。其实他这些词儿，都是从别的语言道听途说来，却又没能深刻理解其精髓。有些“函数式语言”的特性，本来就是有问题的，却为了主义正确，为了显得高大上，抄过来。所以最后你发现这语言是挂着羊头卖狗肉，狗皮膏药一样说得头头是道，用起来怎么就那么蹩脚。&lt;/p&gt;&lt;p&gt;Clojure的社区，一直忙着从Scheme和Racket的项目里抄袭思想，却又想标榜是自己的发明。比如Typed Clojure，就是原封不动抄袭Typed Racket。有些一模一样的基本概念，在Scheme里面都几十年了，恁是要改个不一样的名字，免得你们发现那是Scheme先有的。甚至有人把SICP，The Little Schemer等名著里的代码，全都用Clojure改写一遍，结果完全失去了原作的简单和清晰。最后你发现，Clojure里面好的地方，全都是Scheme已经有的，Clojure里面新的特性，几乎全都有问题。我参加过一些Clojure的meetup，可是后来发现，里面竟是各种喊着大口号的小白，各种趾高气昂的民科，愚昧之至。&lt;/p&gt;&lt;p&gt;如果现在要做一个系统，真的宁可用Java，也不要浪费时间去折腾什么Scala或者Clojure。错误的人设计了错误的语言，拿出来浪费大家的时间。&lt;/p&gt;&lt;h3&gt;Java没有特别讨厌的地方&lt;/h3&gt;&lt;p&gt;我至今不明白，很多人对Java的仇恨和鄙视，从何而来。它也许缺少一些方便的特性，然而长久以来用Java进行教学，用Java工作，用Java开发PySonar，RubySonar，Yin语言，…… 我发现Java其实并不像很多人传说的那么可恶。我发现自己想要的95%以上的功能，在Java里面都能找到比较直接的用法。剩下的5%，用稍微笨一点的办法，一样可以解决问题。&lt;/p&gt;&lt;p&gt;盲目推崇Scala和Clojure的人们，很多最后都发现，这些语言里面的“新特性”，几乎都有毛病，里面最重要最有用的特性，其实早就已经在Java里了。有些人跟我说：“你看，Java做不了这件事情！” 后来经我分析，发现他们在潜意识里早已死板的认定，非得用某种最新最酷的语言特性，才能达到目的。Java没有这些特性，他们就以为非得用另外的语言。其实，如果你换一个角度来看问题，不要钻牛角尖，专注于解决问题，而不是去追求最新最酷的“写法”，你就能用Java解决它，而且解决得干净利落。&lt;/p&gt;&lt;p&gt;很多人说Java复杂臃肿，其实是因为早期的&lt;a href=&quot;https://en.wikipedia.org/wiki/Design_Patterns&quot;&gt;Design Patterns&lt;/a&gt;，试图提出千篇一律的模板，给程序带来了不必要的复杂性。然而Java语言本身跟Design Patterns并不是等价的。Java的设计者，跟Design Pattern的设计者，完全是不同的人。你完全可以使用Java写出非常简单的代码，而不使用Design Patterns。&lt;/p&gt;&lt;p&gt;Java只是一个语言。语言只提供给你基本的机制，至于代码写的复杂还是简单，取决于人。把对一些滥用Design Patterns的Java程序员的恨，转移到Java语言本身，从而完全抛弃它的一切，是不明智的。&lt;/p&gt;&lt;h3&gt;结论&lt;/h3&gt;&lt;p&gt;我平时用着Java偷着乐，本来懒得评论其它语言的。可是实在不忍心看着有些人被Scala和Clojure忽悠，所以在这里说几句。如果没有超级高的性能和资源需求（可能要用C这样的低级语言），目前我建议就老老实实用Java吧。虽然不如一些新的语言炫酷，然而实际的系统，还真没有什么是Java写不出来的。少数地方可能需要绕过一些限制，或者放宽一些要求，然而这样的情况不是很多。&lt;/p&gt;&lt;p&gt;编程使用什么工具是重要的，然而工具终究不如自己的技术重要。很多人花了太多时间，折腾各种新的语言，希望它们会奇迹一般的改善代码质量，结果最后什么都没做出来。选择语言最重要的条件，应该是“够好用”就可以，因为项目的成功最终是靠人，而不是靠语言。既然Java没有特别大的问题，不会让你没法做好项目，为什么要去试一些不靠谱的新语言呢？&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">java</guid>
<pubDate>Mon, 18 Jan 2016 00:00:00 +0800</pubDate>
</item>
<item>
<title>Tesla Autopilot</title>
<link>http://yinwang.org/blog-cn/2016/01/10/tesla-autopilot</link>
<description>&lt;p&gt;
  　　
  &lt;/p&gt;&lt;h2&gt;Tesla Autopilot&lt;/h2&gt;&lt;p class=&quot;notice&quot;&gt;以下内容是《&lt;a href=&quot;http://www.yinwang.org/blog-cn/2015/12/12/tesla-model-s&quot;&gt;Tesla Model S的设计失误&lt;/a&gt;》一文中新加入的小节。由于写作时间相距太远，而且由于它的&lt;a href=&quot;http://www.reuters.com/article/us-tesla-autopilot-idUSKCN0UO0NM20160110&quot;&gt;时效性&lt;/a&gt;，现在也把它单独提出来，独立成文。&lt;/p&gt;&lt;p&gt;两个月前，Tesla通过“软件更新”，使Model S具有了初级的“自动驾驶”（autopilot）功能。这个功能可以让Model S自动地，沿着有“清晰边界线”的车道行驶，根据前后车辆的速度相应的加速和减速。&lt;/p&gt;&lt;p&gt;这貌似一个很新很酷的功能，咋一看跟Google的自动车有的一拼（其实差得天远）。然而在推出后不久，YouTube上出现了一些视频（&lt;a href=&quot;https://www.youtube.com/watch?v=MrwxEX8qOxA&quot;&gt;视频1&lt;/a&gt;，&lt;a href=&quot;https://www.youtube.com/watch?v=Lx3-epk_ztQ&quot;&gt;视频2&lt;/a&gt;，&lt;a href=&quot;https://www.youtube.com/watch?v=LJnYCEQwtHs&quot;&gt;视频3&lt;/a&gt;，&lt;a href=&quot;https://www.youtube.com/watch?v=rkZ-jhLxrVc&quot;&gt;视频4&lt;/a&gt;，&lt;a href=&quot;https://www.youtube.com/watch?v=mLOG1bw3vSM&quot;&gt;视频5&lt;/a&gt;）。它们显示，autopilot在某些情况下有可能进行错误的判断和操作，有些险些造成严重的迎面车祸。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=MrwxEX8qOxA&quot;&gt;
&lt;img src=&quot;http://www.yinwang.org/images/model-s-autopilot-frontal.png&quot; width=&quot;80%&quot;&gt;
&lt;/a&gt;&lt;/p&gt;&lt;p&gt;特别是&lt;a href=&quot;https://www.youtube.com/watch?v=MrwxEX8qOxA&quot;&gt;视频1&lt;/a&gt;显示，在路面线条清晰，天气很好的路上，autopilot忽然向左，试图转向反方向的车道，差点导致严重的对撞车祸。仔细观察autopilot转向之前的情况，是由于路面上有阳光投下来的树影。Autopilot误以为那是一个障碍物，所以试图把车转上反方向的车道！&lt;/p&gt;&lt;p&gt;从这个简单的视频我们可以看出：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Autopilot没有对图像进行基本的“阴影消除”，它不能区分阴影和障碍物。阳光强烈，阴影明显的时候，autopilot可能把阴影当成障碍物。阴影消除在计算机视觉已经研究挺多了，这说明Tesla有可能没有进行基础的计算机视觉研究。缺乏分辨阴影和障碍物的能力，这样的自动驾驶系统是完全不可接受的。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;道路中间有明显的，表示“禁止超车”的双黄线，对面有来车。Autopilot为了避开“障碍”，冒着对撞的危险，左转跨越双黄线。这表示autopilot连基本的交通规则，紧急情况下的正确操作方式都搞不清楚。或者也许这软件里面连双黄线都没有识别，甚至连这个概念都没有。&lt;/p&gt;

&lt;p&gt;对于一个有经验的驾驶员来说，如果发现前方有障碍物，正确的作法不应该是猛烈地转弯避开，而应该是紧急刹车。从视频上我们看出，车子没有刹车减速（保持在37~38），而是猛烈地左转。而且是等树影到了面前，才忽然进行操作，没有计算提前量。这说明设计autopilot的人，连基本的开车常识都不明白。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;让我感到悲哀的是，这些视频的很多评论，大部分都在谩骂车主是傻逼：“这是车主自己的责任！”，“Autopilot只能在高速公路上使用”，“只能在车道上有明确的边界线的时候使用！”，“不能在有很多弯道的地方“，“只能在能够看见前方300米道路的地方使用”，“谁叫你不看说明书的！”…… Elon Musk也在一次&lt;a href=&quot;https://www.youtube.com/watch?v=60-b09XsyqU&quot;&gt;采访&lt;/a&gt;中明确的告诉记者：“如果用户因为使用autopilot而导致了车祸，是用户自己的责任！” 他反复地声明：“autopilot还处于beta版本……” 意思是，你们小心着用！&lt;/p&gt;&lt;p&gt;我对这些说法持不同的观点。首先，Tesla根本就不应该把一个处于&quot;beta状态&quot;的功能，自动推送到所有Model S的系统里面。实际上，像autopilot这种功能，关系到人的生命安全，根本就不应该有&quot;beta版本&quot;或者“测试版本”之说。Tesla把这样不成熟的系统，强制推送给用户，然后又说如果出了事故，用户负所有责任，这是一种推卸责任的做法。要知道，没有任何人愿意拿自己的生命给Tesla做“beta测试”。&lt;/p&gt;&lt;p&gt;另外，就算是用户没有仔细阅读autopilot的使用说明，在“不该”用它的地方（比如路面线条不清晰的地方）使用了autopilot，如果出了车祸，Tesla也应该负完全的责任。理由如下：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;作为用户，他们没有义务阅读并且深刻的理解autopilot的局限性。在软件行业，存在一种习惯性的“责备用户”的不良风气。如果软件的设计有问题，用户没记住它的毛病，没能有效地绕过，那么如果出了问题，一般被认为是用户的错。Tesla想把软件行业的这种不正之风，引入到人命关天的汽车行业，那显然是行不通的。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Tesla的autopilot实现方式幼稚，局限性实在太多。天气不好的时候不行，路面上的边界线不清晰也不行，光线不好或者有阴影不行，路上有施工的路桩不行，高速出口不行，…… 实际上，在如此苛刻的限定条件下，任何一个汽车厂商都可以做出Tesla那种autopilot。&lt;/p&gt;

&lt;p&gt;我自己的便宜Honda车，就有偏离车道时发出警告的功能（Lane Drift Warning，LDW）。装个摄像头，来点最简单的图像处理就搞定。在Indiana大学的时候，我们有一门本科级别的课程，就是写代码控制一辆高尔夫球车（也是电动车呢），沿着路面上的线条自动行驶。这根本没什么难度，因为它能正确行驶的条件，实在是太苛刻了。&lt;/p&gt;

&lt;p&gt;其它汽车厂商很清楚这种功能的局限性，所以他们没有大肆吹嘘这种“线检测”的技术，或者把它做成autopilot。他们只是把它作为辅助的，提示性的功能。这些汽车厂商理解，作为一个用户，他们不可能，也不应该记住autopilot能正确工作的种种前提条件。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;用户没有足够的能力来“判断”autopilot正常工作的条件是否满足。比如，路上的线还在，但是被磨损了，颜色很浅，那么autopilot到底能不能用呢？谁也不知道。把判断这些条件是否满足的任务推给用户，就像是在要求用户帮Tesla的工程师debug代码。这显然是不可行的。如果autopilot能够在检测到道路条件不满足的情况下，自动警告用户，并且退出自动驾驶模式，那还稍微合理一些。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;用户也许没有足够的时间来响应条件的改变。Autopilot自动驾驶的时候，车子有可能最初行驶在较好的条件下（天气好，路面线条清晰），然而随着高速行驶，路面条件有可能急速的变化。有可能上一秒还好好的，下一秒路面线条就不再清晰（&lt;a href=&quot;https://www.youtube.com/watch?v=mLOG1bw3vSM&quot;&gt;视频5&lt;/a&gt;貌似这种情况）。路面条件的变化突如其来，驾驶员没有料到。等他们反应过来，想关闭autopilot的时候，车祸已经发生了。这种情况如果上诉到法庭，稍微明理一点的法官，都应该判Tesla败诉。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Autopilot显摆出的“高科技”形象，容易使人产生盲目的信任，以至于疏忽而出现车祸。既然叫做“autopilot”，这意味着它能够不需要人干预，自动驾驶一段时间。既然用户觉得它能自动驾驶，那么他们完全有理由在到达高速路口之前（比如GPS显示还有一个小时才到出口），做一些自己的事情：比如看看手机啊，看看书啊，甚至刷刷牙…… 不然，谁让你叫它是“autopilot”的呢？我坐飞机时，就见过飞行员打开autopilot，上厕所去了。如果启用了autopilot还得一秒钟不停地集中注意力，那恐怕比自己开车还累。自己开车只需要看路，现在有了autopilot，不但要看路，还要盯着方向盘，防止autopilot犯傻出错……&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Tesla把“beta版”的autopilot推送给所有的Model S，是对社会安全不负责任的做法。你要明白Murphy&#39;s Law：如果一个东西可能出问题，那么就一定会有人让它出问题。Autopilot的功能不成熟，限制条件很多，不容易被正确使用，这不但对Model S的车主自己，而且对其他人也是一种威胁。汽车不是玩具，随便做个新功能，beta版，让人来试用，是会玩出人命的。我觉得Tesla的autopilot，跟无照驾驶的人一样，应该被法律禁止。由于autopilot的复杂性和潜在的危险性，使用autopilot的用户，应该经过DMV考核，在驾照上注明“能正确使用Tesla autopilot”，才准上路。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;关系到人的生命安全的“免责声明”和“用户协议”，在法律上是无效的。在美国，到处都存在“免责声明”之说。比如你去参加学校组织的春游活动，都要叫你签一个“waiver”，说如果出了安全事故或者意外，你不能把学校告上法庭。这种免责声明，一般在法律上都是无效的。如果由于学校的过错而致使你的身体受了损伤，就算你签了这种waiver，照样可以把学校告上法庭。我估计Tesla的autopilot在启动时，也有这样的免责声明，说如果使用autopolit而出现车祸，Tesla不负责任。由于autopilot直接操控了你的车子，如果真的出了车祸，这跟其它的waiver一样，都是无效的。你照样可以上法庭告他们。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;由于意识到这个问题，知道出了问题自己是逃不掉责任的，Tesla最近又通过强制的软件更新，对autopilot的功能进行了一些&lt;a href=&quot;http://www.reuters.com/article/us-tesla-autopilot-idUSKCN0UO0NM20160110&quot;&gt;限制&lt;/a&gt;，说是为了防止用户“滥用”autopilot做一些“疯狂”的事情。Tesla很疯狂，反倒指责用户“滥用”和“疯狂”。这让人很愤慨。&lt;/p&gt;&lt;p&gt;对autopilot进行限制的同时，Tesla又推出了beta版的“&lt;a href=&quot;http://www.cnet.com/news/tesla-cars-can-now-self-park-at-your-command&quot;&gt;自动趴车&lt;/a&gt;”和“召唤”（summon）功能。这些功能貌似很酷，然而它们也附带了许多的限制条件。你只能在某些地方，满足某种特定条件，才能用这些功能。如果你违反这些条件，出了事故，Tesla声称不负责。&lt;/p&gt;&lt;p&gt;这些能够让车子自己移动的功能，跟autopilot一样，同样会给社会带来安全隐患。比如，有人在不该使用自动趴车和summon功能的地方用了它，就可能会导致车祸。这不是用户的问题，而是Tesla根本不应该发布这些不成熟的技术来哗众取巧。&lt;/p&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">tesla-autopilot</guid>
<pubDate>Sun, 10 Jan 2016 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
