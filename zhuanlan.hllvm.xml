<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>编程语言与高级语言虚拟机杂谈（仮）</title>
<link>https://zhuanlan.zhihu.com/hllvm</link>
<description>探讨编程语言的设计与实现</description>
<language>zh-cn</language>
<lastBuildDate>Mon, 19 Sep 2016 16:11:27 +0800</lastBuildDate>
<image>
<url>https://pic4.zhimg.com/4b70deef7_xl.jpg</url>
<title>编程语言与高级语言虚拟机杂谈（仮）</title>
<link>https://zhuanlan.zhihu.com/hllvm</link>
</image>
<item>
<title>[OMR/TR] Testarossa的IL设计（持续更新）</title>
<link>https://zhuanlan.zhihu.com/p/22508731</link>
<description>边读代码边更新的笔记。先写点我原本就知道的内容，后面再更新具体到OMR TR代码的知识点。&lt;p&gt;上一篇文章 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/22506697?refer=hllvm&quot; data-editable=&quot;true&quot; data-title=&quot;[新闻] IBM/Eclipse OMR的编译器部分也已开源，以及IBM即将开源J9 VM - 编程语言与高级语言虚拟机杂谈（仮） - 知乎专栏&quot; class=&quot;&quot;&gt;[新闻] IBM/Eclipse OMR的编译器部分也已开源，以及IBM即将开源J9 VM - 编程语言与高级语言虚拟机杂谈（仮） - 知乎专栏&lt;/a&gt; 提到了OMR中的编译器组件——Testarossa（以下简称OMR TR）——也终于开源的新闻。这里就来看看OMR TR的中间表现形式（Intermediate Representation，IR）的设计是怎样的。&lt;br&gt;&lt;/p&gt;&lt;p&gt;OMR TR的IR叫做Testarossa IL（Intermediate Language），下面简称TR IL。它是一种颇为传统的树形IR（Tree IR），比一般编译器前端用的抽象语法树（AST）底层一些，而比完全拉直的线性IR要高层一些。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;相信熟悉&lt;a href=&quot;https://book.douban.com/subject/1886911/&quot; data-title=&quot;虎书系列&quot; class=&quot;&quot;&gt;虎书系列&lt;/a&gt;的同学会对这种IR比较熟悉（对应虎书第7、8两章内容）。&lt;/li&gt;&lt;li&gt;如果是熟悉GCC IR的同学，TR IL跟GCC的GENERIC已经lower了控制流但尚未lower表达式树的GIMPLE比较相似。&lt;/li&gt;&lt;li&gt;如果是熟悉RyuJIT的同学，TR IL跟RyuJIT的Tree IR颇有相似之处。&lt;br&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;p&gt;TR IL比AST底层的地方在于：一般的AST设计会比较贴近源语言的语法结构，所以如果源语言有结构化控制流结构（if-then-else、while/for-loop等）的话，在AST里也会有直接对应的节点。而在一个典型的编译器后端用的树形IR中，控制流会被拆解为条件跳转与无条件跳转，树的形状会更贴近于底层控制流，而不再维持原本AST那种贴近源语言语法的层次结构。&lt;/p&gt;&lt;p&gt;TR IL比线性代码高层的地方在于：一般的线性代码跟机器语言比较贴近，就是一串线性执行的代码，没有所谓“语句”与“表达式”之分了——所有复杂表达式都被lower为一串使用临时变量的简单表达式。线性IR中的表达式大都可以用三地址代码直观地表示：dest = src1 op src2。&lt;/p&gt;&lt;p&gt;TR IL所使用的树形IR则仍然保持“语句”与“表达式”的区别。其中“语句”指的是可能有副作用的操作（例如变量赋值、函数调用等）或者是控制流跳转。语句不能嵌套，只能按顺序线性执行。而“表达式”则是纯粹的运算，没有副作用，没有控制流，可以嵌套。“表达式”的若干重要特征是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;由于没有副作用与控制流，嵌套表达式的求值顺序可以任意决定，这给优化留下了自由度；&lt;/li&gt;&lt;li&gt;一个语句中的嵌套表达式的中间结果不会被别的语句中的表达式所看到。也就是说，一个语句中的表达式中间结果的生命周期仅限于该语句内，不会“泄漏”到别的语句中。这个特征对于某些非常简易的局部优化挺有帮助，例如&lt;a href=&quot;https://www.zhihu.com/question/29355187/answer/51935409&quot;&gt;这里&lt;/a&gt;提到的超简易寄存器分配算法。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;（未完待续）&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">22508731</guid>
<pubDate>Mon, 19 Sep 2016 16:10:23 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[新闻] IBM/Eclipse OMR的编译器部分也已开源，以及IBM即将开源J9 VM</title>
<link>https://zhuanlan.zhihu.com/p/22506697</link>
<description>&lt;p&gt;OMR的组件的大类别中里最后一个重量级类别也终于来了：源自J9的JIT编译器“Testarossa”（J9/TR）的编译器架构：&lt;/p&gt;&lt;blockquote&gt;&lt;a href=&quot;https://github.com/eclipse/omr/commit/03874a48843df45292aa35086c5faf4fd83de264&quot; data-editable=&quot;true&quot; data-title=&quot;Initial contribution of compiler technology consisting of: · eclipse/omr@03874a4 · GitHub&quot; class=&quot;&quot;&gt;Initial contribution of compiler technology consisting of: · eclipse/omr@03874a4 · GitHub&lt;br&gt;&lt;br&gt;&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;Commit message:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Initial contribution of compiler technology consisting of:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;high-level optimization technology featuring classic compiler optimizations, loop optimizations, control and data flow analyses, and support data structures&lt;br&gt;&lt;/li&gt;&lt;li&gt;code generation technology with deep platform exploitation for x86 (i386 and x86-64), Power, System Z, and ARM (32-bit)&lt;br&gt;&lt;/li&gt;&lt;li&gt;a robust, tree-based intermediate representation (or IL) and support code for producing IL from different method representations&lt;br&gt;&lt;/li&gt;&lt;li&gt;expressive tracing and logging infrastructure for problem determination&lt;br&gt;&lt;/li&gt;&lt;li&gt;JitBuilder technology to simplify the effort to integrate a JIT compiler into an existing language interpreter&lt;br&gt;&lt;/li&gt;&lt;li&gt;a framework for constructing language-agnostic unit tests for compiler technology&lt;br&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p&gt;OMR编译器部分的说明：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/eclipse/omr/blob/master/compiler/README.md&quot; data-editable=&quot;true&quot; data-title=&quot;omr/README.md at master · eclipse/omr · GitHub&quot;&gt;omr/README.md at master · eclipse/omr · GitHub&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;后续会在OMR里开源的都是各个大类别（GC、compiler、threading、diagnostic等）下的一些具体功能，而没有别的大类别还没开出来了。&lt;/p&gt;&lt;p&gt;Exciting！&lt;/p&gt;&lt;p&gt;可能会有不熟悉Testarossa的同学说：这个编译器开源出来跟我有毛关系，这不是个JVM里的JIT编译器么？&lt;/p&gt;&lt;p&gt;呵呵，它可不只是个JIT编译器。其实Kevin Stoodley大大最初提出Testarossa项目的时候，是想要成为IBM XL编译器套件（C/C++/Fortran等）的一个中间优化器（大概是想替代TPO？）。但是生不逢时，一开始没能被XL编译器青睐，却正好碰上IBM开始做J9 JVM，就摇身一变成为了J9的御用JIT编译器。后来它还被用在了许多不同的场景中，例如编译C/C++的Static Testarossa（sTR，曾在Linux/z上部署过）、用于优化legacy COBOL代码性能的动态二进制翻译/优化器，等等。这是个相当通用的编译器架构，就算对OMR的其它组件不感兴趣，Testarossa也可以单独拿出来用的。所以如果想自己写个编译器来玩，后端的选择除了LLVM、libgccjit、&lt;a href=&quot;http://microvm.github.io/&quot; data-editable=&quot;true&quot; data-title=&quot;The Mu Micro &quot; class=&quot;&quot;&gt;MicroVM&lt;/a&gt;、&lt;a href=&quot;http://c9x.me/compile/&quot; data-editable=&quot;true&quot; data-title=&quot;QBE&quot; class=&quot;&quot;&gt;QBE&lt;/a&gt;之类之外，这OMR TR也是个新选择。&lt;/p&gt;&lt;p&gt;不过当然，Testarossa的代码还是可以看出它最初的正式用途是作为J9 VM配套的编译器的这个历史。例如说，请看OMR Testarossa IL默认的opcode：&lt;a href=&quot;https://github.com/eclipse/omr/blob/master/compiler/il/OMRILOpCodesEnum.hpp&quot; data-editable=&quot;true&quot; data-title=&quot;omr/OMRILOpCodesEnum.hpp at master · eclipse/omr · GitHub&quot;&gt;omr/OMRILOpCodesEnum.hpp at master · eclipse/omr · GitHub&lt;/a&gt;，拿它跟JVM的字节码来对比一下，看看名字是不是非常的相似——OMR TR IL的opcode就像是JVM字节码的扩展版一样，在功能相同的地方名字也是一样的。&lt;/p&gt;&lt;p&gt;说来，把一个老项目开源还真是改进代码质量 / 代码风格的一个好的动力来源。Testarossa的代码还没重构完，但组织决定让它尽快先放出来给大家瞄一眼。代码里使用 TR:: 命名空间的类型是已经被重构到的代码，而在全局命名空间但有 TR_ 前缀的类型则是尚未被重构（至少尚未被重命名）的代码。IBM还在继续重构中，尽量把Testarossa的代码风格从以前基本上就是C with Classes的风格改进为比较现代的C++风格；它自己带的一些数据结构库也将尽量被替换为STL的对应物。&lt;/p&gt;&lt;p&gt;==================================================&lt;/p&gt;&lt;p&gt;另外，IBM已经计划好在今年接下来的JavaOne上宣布IBM J9 VM的开源。看来OMR的开源还真是J9开源的一个敲门砖。以前我问Mark Stoodley说如果有人基于OMR写了个JVM的话会怎样，他还说：那很好啊，IBM不会介意的，如果有好想法的话可能还会取回到J9里去用；这不，J9自己干脆也决定要开源了。&lt;/p&gt;&lt;p&gt;今年的JVMLS上我问Mark说显然有不少在J9里已有的功能在OMR里尚未开放，例如说J9/TR自身支持的dependency-based speculative optimization，这方面有怎样的计划。他提到确实有不少功能因为还没想好如何抽象出来给外界使用，所以还没从J9剥离出来放到OMR里。但是他们会很欢迎外界贡献者帮忙从J9中把功能打捞到OMR去 &amp;gt;_&amp;lt;&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">22506697</guid>
<pubDate>Mon, 19 Sep 2016 13:57:57 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[新闻] Android Runtime（ART）的一些新动态，2016-08</title>
<link>https://zhuanlan.zhihu.com/p/22253472</link>
<description>ART Optimizing Compiler终于也忍不住添加了图着色寄存器分配器：&lt;p&gt;&lt;a href=&quot;https://android.googlesource.com/platform/art/+log/master/compiler/optimizing/register_allocator_graph_color.h&quot; data-editable=&quot;true&quot; data-title=&quot;googlesource.com 的页面&quot; class=&quot;&quot;&gt;compiler/optimizing/register_allocator_graph_color.h&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;这有意思啊。勇于承担更长时间的编译么。&lt;/p&gt;&lt;br&gt;&lt;p&gt;然后ART的Concurrent Copying GC近来的变化也值得关注。它有一种新的read barrier type，以前没在别的地方见过的：它会在对象头上使用一个bit来记录该对象里的引用类型字段在dereference的时候是否需要经过read barrier。这做法挺新奇的。效果是不是真的好另论，总之先学习一下这个思路的来龙去脉总是件趣事。&lt;/p&gt;&lt;br&gt;&lt;p&gt;话说之前一个关于&lt;a href=&quot;https://zhuanlan.zhihu.com/p/20569303&quot; data-editable=&quot;true&quot; data-title=&quot;ART又要考虑用基于LLVM的编译器了… - 编程语言与高级语言虚拟机杂谈（仮） - 知乎专栏&quot; class=&quot;&quot;&gt;ART又要考虑用基于LLVM的编译器&lt;/a&gt;的小道消息果然是假的么。隔了那么久并没有收到真的有这方面动静的消息。&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">22253472</guid>
<pubDate>Wed, 31 Aug 2016 15:23:52 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>架构最快最好的To JS编译器</title>
<link>https://zhuanlan.zhihu.com/p/22216448</link>
<description>自己从事&lt;a href=&quot;https://github.com/bloomberg/bucklescript&quot; data-editable=&quot;true&quot; data-title=&quot;BuckleScript&quot; class=&quot;&quot;&gt;BuckleScript&lt;/a&gt; 的编译器的开发已有近一年， 下周即将发布1.0，这里面有太多故事可以写了，知乎第一篇文章献给它。&lt;p&gt;虽然BuckleScript 才马上到1.0， 但是它已经被一些公司所采用，比如它已经被Facebook的某些产品用到了。自己也在和著名的ReactJS/ReactNative的作者Jordan 合作希望能推出 Reason On React (Powered by BuckleScript) 希望这能够给BuckleScript 带来killer app. 而BuckleScript 本身的编译器是用OCaml 写得，可以被编译成汇编和JS本身（压缩后大小700KB), 用户们可以自己感受下它的编译速度, Try here: &lt;a href=&quot;http://bloomberg.github.io/bucklescript/js-demo/&quot; data-editable=&quot;true&quot; data-title=&quot;OCaml to Javascript transpiler playground&quot;&gt;OCaml to Javascript transpiler playground&lt;/a&gt; 注意汇编的版本比JS的版本还要快一个数量级。&lt;/p&gt;&lt;p&gt;BuckleScript 早期是我的个人项目：因为注意到 现在软件行业--从互联网行业到传统软件领域--有一个很明显趋势: Javascript platform，&lt;a href=&quot;https://www.youtube.com/watch?v=jFU-wc28lF4&quot; data-title=&quot;这个唯一的跨平台语言正在吞噬着所有软件领域&quot; class=&quot;&quot; data-editable=&quot;true&quot;&gt;这个唯一的跨平台语言正在吞噬着所有软件领域&lt;/a&gt;（因为mobile的崛起Java 已经不再是一个跨平台语言了)：&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;浏览器已经不再只是deliver 内容的一个平台，越来越多的应用程序开始通过浏览器直接deploy，像上面提到的BuckleScript playground 整个工业级别的编译器直接跑在浏览器上 这甚至在5年前都是不可想象的。&lt;/li&gt;&lt;li&gt;Google最近主推的&lt;a href=&quot;https://developers.google.com/web/progressive-web-apps/&quot; data-editable=&quot;true&quot; data-title=&quot;Progressive Web APP&quot; class=&quot;&quot;&gt;Progressive Web APP&lt;/a&gt; 将会给浏览器带来更强大的API. 而最新的&lt;a href=&quot;https://webassembly.github.io/&quot; data-editable=&quot;true&quot; data-title=&quot;Web Assembly 标准&quot;&gt;Web Assembly 标准&lt;/a&gt; 将会使得JavaScript 平台可以覆盖更多的领域：比如传统的数值计算领域。WASM相当于给JavaScript 提供了一个接入native平台的FFI, JavaScript 作为这个平台的胶水语言毫无疑问有着最多的机会。&lt;/li&gt;&lt;li&gt;JavaScript 平台已经不再局限于浏览器， 相反它已经开始反噬， 开始入侵其它领域 最有名的是&lt;a href=&quot;https://nodejs.org/en/&quot; data-editable=&quot;true&quot; data-title=&quot;NodeJS&quot;&gt;NodeJS&lt;/a&gt;, &lt;a href=&quot;http://electron.atom.io/&quot; data-editable=&quot;true&quot; data-title=&quot;Electron&quot;&gt;Electron&lt;/a&gt;, &lt;a href=&quot;http://johnny-five.io/&quot; data-editable=&quot;true&quot; data-title=&quot;IoT&quot;&gt;IoT&lt;/a&gt; 等&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;p&gt;为什么要自己写一个这样的编译器呢? 虽然JavaScript平台很诱人，但是“动态语言难于构建大型程序” 基本上已经是业界共识，一旦程序规模上来了，基本上就只能Write Only. 作者所在的公司有上千万行JS, 维护起来基本上就是噩梦，在原来的Hack上添加新的if else Hack。而工业界真正有工业强度而且和JavaScript 交互良好的的编译器是微软的typescript 编译器，接下来就展开说下为什么BuckleScript 比typescript 更快更好。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;更好的平台拓展性：BuckleScript 不是一个新的语言，它是把一个已经存在将近30年的语言OCaml编译成可读的JavaScript. 而OCaml本身对很多平台存在native 的后端支持。像go一样, OCaml可以编译出汇编代码到iOS,Android, Windows,Linux, MacOS。而typescript只有JavaScript 一个后端，拥抱JavaScript 并不代表我们就要抛弃native 平台，当我们需要更快更可靠的性能的时候，我们可以有更多的选择，比如做工具链的时候: typescript 的编译器同样也是用typescript写得可以跑在浏览器里也可以泡在node上，但是它跑在node上得时候就比BuckleScript编译成汇编跑慢不止一个数量级。&lt;br&gt;&lt;/li&gt;&lt;li&gt;更好的类型安全: typescript是一个JS的超集，它存在很多历史包袱。而微软引入typescript更多的是作为一个工具来使用的比如IDE的代码补全，相对安全的代码重构。而这个类型的准确从第一天开始就不是它的设计初衷，以至于Facebook自己设计了一个相对更准确地类型系统&lt;a href=&quot;https://github.com/facebook/flow&quot; data-editable=&quot;true&quot; data-title=&quot;Flow&quot;&gt;Flow&lt;/a&gt;. 而OCaml的类型系统是已经被形式化的证明过正确的。也就是说从理论上BuckleScript 能够保证一旦编译通过是不会有运行时候类型错误的，而typescript远远做不到这点。&lt;/li&gt;&lt;li&gt;更多的类型推断，更好的语言特性：用过typescript的人都知道，typescript的类型推断很弱，基本上所有参数都需要显示的标注类型。不光是这点，像对函数式编程的支持，高阶类型系统GADT的支持几乎是没有。而OCaml本身是一个比Elm,PureScript还要强大的多的语言，它自身有一个非常高阶的module system，是为数不多的对dependent type提供支持的语言，polymorphic variant。而且pattern match的编译器也是优化过的。&lt;/li&gt;&lt;li&gt;程序优化，代码删除。BuckleScript不只是一个编译器更是一个optimizing compiler: 它做过的优化有: Code motion, Purity analysis, Cross module inliner, Constant folding/propagation, partial evaluation Strength reduction, escape analysis。我们做的benchmark显示同样的immutable data structure 比如&lt;a href=&quot;https://facebook.github.io/immutable-js/&quot; data-editable=&quot;true&quot; data-title=&quot;facebook immutablejs&quot;&gt;facebook immutablejs&lt;/a&gt;, BuckleScript的实现有时候要快两到三倍不止。而相比之下typescript编译器并不会做任何优化工作。&lt;/li&gt;&lt;/ol&gt;&lt;br&gt;&lt;p&gt;因为自己接触到的专业术语都是英文的，作者试着尽可能用中文表述，可能翻译过来的中文不太准确，尽请谅解, 接下来我还会写几篇文章讲讲它的底层设计，如果读者能够读到这里, 还请在github上友情支援一下 : )。&lt;/p&gt;&lt;p&gt;小时候读韩愈的《马说》， 不太理解这句话 “世有伯乐， 然后有千里马，千里马常有，而伯乐不常有”。 长大以后慢慢的对这句话才真的理解，真的要好好感谢一路过来给我无限指导和关怀的老师/老板们，我也庆幸自己很幸运，自己的每一任老师或者老板 ，不管自己做什么，都能够得到你们的理解和支持。&lt;/p&gt;</description>
<author>张宏波</author>
<guid isPermaLink="false">22216448</guid>
<pubDate>Mon, 29 Aug 2016 04:18:25 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>为什么Python里面的locals()是只读的</title>
<link>https://zhuanlan.zhihu.com/p/21815224</link>
<description>Python里面的各个名字空间都可以抽象成一个dictionary, 比如函数的本地变量就可以通过build-in函数locals()来取得。但是很多资料都提到通过locals()取得的dictionary是只读的，比较好奇为什么会有这个限制。下面是一个点单的对locals()的调用 （在CPython 2.7下运行得到）:&lt;code lang=&quot;python&quot;&gt;&amp;gt;&amp;gt;&amp;gt; def foo(a):
...   return locals()
...
&amp;gt;&amp;gt;&amp;gt; dis.dis(foo)
  2           0 LOAD_GLOBAL              0 (locals)
              3 CALL_FUNCTION            0
              6 RETURN_VALUE
&lt;/code&gt;&lt;p&gt;-- 补充，按R大提到的，CPython的local variable都是放在frame的localplus数组里面，而locals()返回的是dictionary对象，通过这个dictionary对象不能直接修改localplus上的值也是很直观的。&lt;/p&gt;&lt;p&gt;locals在global空间(LOAD_GLOBAL), 这个build-in方法最终在bltinmodule.c里面实现如下：&lt;/p&gt;&lt;code lang=&quot;c&quot;&gt;static PyObject *
builtin_locals(PyObject *self)
{
    PyObject *d;

    d = PyEval_GetLocals();
    Py_XINCREF(d);
    return d;
}
&lt;/code&gt;&lt;p&gt;主要是转到ceval.c的PyEval_GetLocals()上：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;PyObject *
PyEval_GetLocals(void)
{
    PyFrameObject *current_frame = PyEval_GetFrame();
    if (current_frame == NULL)
        return NULL;
    PyFrame_FastToLocals(current_frame);
    return current_frame-&amp;gt;f_locals;
}
&lt;/code&gt;&lt;p&gt;又转到frameobject.c里的PyFrame_FastToLocals(PyFrameObject *f)上。不考虑错误和cellvar的处理等，主要部分如下：&lt;/p&gt;&lt;code lang=&quot;c&quot;&gt;PyFrame_FastToLocals(PyFrameObject *f)
{
    /* Merge fast locals into f-&amp;gt;f_locals */
    PyObject *locals, *map;
    PyObject **fast;
    PyCodeObject *co;
    Py_ssize_t j;
    locals = f-&amp;gt;f_locals;
    if (locals == NULL) {
        locals = f-&amp;gt;f_locals = PyDict_New();
    }
    co = f-&amp;gt;f_code;

    map = co-&amp;gt;co_varnames;
    fast = f-&amp;gt;f_localsplus;
    j = PyTuple_GET_SIZE(map);
    if (co-&amp;gt;co_nlocals)
        map_to_dict(map, j, locals, fast, 0);
&lt;/code&gt;&lt;p&gt;最主要的map_to_dict（同在frameobject.c）就会把存在f-&amp;gt;localsplus里面的local variable (所有的local variable name在co-&amp;gt;varnames里面）放到locals所指向的dictionary, 也同时放在了当前frame里（f-&amp;gt;locals）。所有的local variable很自然成为一个名字空间放进dictionary，这里放进数组风格的f_localsplus里面是为了不用每次使用local variable都查找dictionary。可以搜索此变量名获得更多信息。&lt;/p&gt;&lt;code lang=&quot;c&quot;&gt;static void
map_to_dict(PyObject *map, Py_ssize_t nmap, PyObject *dict, PyObject **values,
            int deref)
{
    Py_ssize_t j;
    for (j = nmap; --j &amp;gt;= 0; ) {
        PyObject *key = PyTuple_GET_ITEM(map, j);
        PyObject *value = values[j];
        if (deref) {
            value = PyCell_GET(value);
        }
        if (value == NULL) {
            if (PyObject_DelItem(dict, key) != 0)
                PyErr_Clear();
        }
        else {
            if (PyObject_SetItem(dict, key, value) != 0)
                PyErr_Clear();
        }
    }
}
&lt;/code&gt;&lt;p&gt;上面的map_to_dict会遍历所有的local variable names, 如果这个variable指向了Python对象则把variable name和对象放进要返回的dictionary对象(f-&amp;gt;f_locals)，这也就意味着每次对locals()的调用都会把frame object里面的dictionary (f_locals)的所有variable name到object的映射根据当前状态刷新，就相当于给所有的local vars照相（snapshot）。这样就能比较容易理解为什么对locals()返回的dictionary是无效的的，因为直接写入这个dictionary只会影响dictionary自身而不会反映到当前frame的f_localsplus，每次调用locals()又会刷新要返回的dictionary内容。下面的例子可以帮助理解这点。&lt;/p&gt;&lt;code lang=&quot;c&quot;&gt;def f():
    x = 10
    lc = locals()
    lc[&#39;x&#39;] = 20
    # &#39;x&#39;-&amp;gt;20 remains on dictionary before locals() is called
    print lc
    # {&#39;x&#39;: 20}                 
    locals()
    # locals dictionary is refreshed in the above call to locals()
    print lc
    # {&#39;x&#39;: 10, &#39;lc&#39;: {...}}     

f()&lt;/code&gt;&lt;p&gt;&lt;a href=&quot;https://docs.python.org/2/library/functions.html#locals&quot; data-title=&quot;CPython&quot; class=&quot;&quot; data-editable=&quot;true&quot;&gt;CPython&lt;/a&gt;官网对locals()的主要描述如下，也说明返回的dictionary只是代表了local symbol table, 并不能等价使用（修改）。&lt;/p&gt;&lt;blockquote&gt;Update and return a dictionary representing the current local symbol table&lt;/blockquote&gt;</description>
<author>Thomson</author>
<guid isPermaLink="false">21815224</guid>
<pubDate>Mon, 01 Aug 2016 15:09:37 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[新闻] ChakraCore已支持运行在Linux上</title>
<link>https://zhuanlan.zhihu.com/p/21825477</link>
<description>&lt;p&gt;上周刚announce的&lt;a href=&quot;https://blogs.windows.com/msedgedev/2016/07/27/chakracore-on-linux-osx/&quot; data-title=&quot;消息&quot; class=&quot;&quot;&gt;消息&lt;/a&gt;，CharakCore已经能运行在Linux和OSX 10.9+上。目前能运行的是interpreter（pass了绝大部分tests），JIT和concurrent GC还正在进行中。同时node-chakracore也更新了，能运行在Linux上。&lt;/p&gt;</description>
<author>Thomson</author>
<guid isPermaLink="false">21825477</guid>
<pubDate>Tue, 02 Aug 2016 04:26:18 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[题外] 技术演进与代码工人</title>
<link>https://zhuanlan.zhihu.com/p/21916716</link>
<description>&lt;p&gt;娱乐一下。&lt;/p&gt;上周在开JVMLS，有机会跟很多同行大佬们聊天。其中听说的一个好玩的想法是：现在在软件开发行业有大量低端职位是不断在做重复开发，重复的低质量开发。然而这样的代码还是会被部署到生产环境，成为许多软件产品的重要组成部分。&lt;p&gt;让机器完全替代人类来写所有代码显然还不是近期能实现的。但如果我们能容忍一些不那么重要（或者或许本来应该重要）的程序是低端程序员造出来的低质量轮子，那能不能让机器来替代人类做好这部分？据说像Gilad Bracha、Erik Meijer等大牛都转向研究机器学习，目标之一就是让机器能部分代替人类写代码。多有趣。&lt;/p&gt;&lt;p&gt;这种东西真能成的话，以后就越来越不需要现在的这种低端码农了吧。就像在机械化、自动化生产线上，越来越不需要低端的人类手工劳作，而是需要高端技工去管理那些机器一样。&lt;/p&gt;&lt;p&gt;虽然不是啥新闻，但突然听说业界的前辈（特别是同做JVM以及其它managed language研发的前辈们）真的投身去做这种研究，还是不免觉得机器写代码离现实又近了一步。&lt;/p&gt;&lt;p&gt;觉得把写代码当作生产线比喻不恰当的同学，你们或许没有见识过真正的低端码农的工作环境和内容。那货真价实就是个人肉生产线，一堆人不断的重复写着一样的代码去实现略微变化的功能。这些生产线与现代软件工程的良好实践基本无缘。正好有同学开过公司做网游，听他们说起这种工作方式的时候我不禁打寒颤。虽然不好，但这样的事情现在也还大量存在。&lt;/p&gt;&lt;p&gt;（Lars Bak之前带Dart团队，后来不直接带团队了而是到处去推销Dart。现在半退休状态的他具体在干嘛了呢？&lt;/p&gt;&lt;p&gt;Erik Meijer虽然还在带Hack团队，完善Hack的类型系统的更新设计，但据说他也在涉及机器学习方向想减少人肉重复堆代码的必要性。这个好玩。）&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">21916716</guid>
<pubDate>Mon, 08 Aug 2016 11:33:22 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[八卦] LLILC项目貌似挂了…</title>
<link>https://zhuanlan.zhihu.com/p/21602080</link>
<description>刚跟同事聊天的时候听说原来我们已经好一段时间没有跟LLILC项目组的人开过定期会议了，而且近期我们在LLVM邮件列表上试着推的GC指针功能，LLILC项目的人也没人来参与讨论…&lt;p&gt;关于LLILC是什么，请跳传送门：&lt;a href=&quot;https://www.zhihu.com/question/29544174&quot; class=&quot;&quot; data-title=&quot;如何看待微软LLILC，一个新的基于LLVM的CoreCLR JIT/CoreRT AOT编译器？&quot; data-editable=&quot;true&quot;&gt;如何看待微软LLILC，一个新的基于LLVM的CoreCLR JIT/CoreRT AOT编译器？&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Andy Ayers大大会不会抓狂了，Phoenix和LLILC都挂了的话…&lt;/p&gt;&lt;p&gt;============================================&lt;/p&gt;&lt;p&gt;LLILC项目的开发过程上可能也有些隐患。&lt;/p&gt;&lt;p&gt;其中很有趣很subtle的一点是：他们在项目初期决定先实现对MSIL的大范围的支持，为此抄了些捷径：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;生成LLVM IR后，几乎不打开LLVM的优化pass，直接去生成目标代码&lt;/li&gt;&lt;li&gt;使用CoreCLR的GC的后备漠视——保守式GC（conservative GC），这样就可以让LLILC不处理栈上的托管指针，而是让CoreCLR自己去保守式扫描栈上的值去猜哪些是托管指针。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这俩捷径的好处是项目初期可以快速推进进度，把大部分MSIL指令都支持上，让LLILC可以编译一些小程序来测试。&lt;/p&gt;&lt;p&gt;但坏处在后期会慢慢浮现出来：一个编译器前端在生成LLVM IR后，如果不打开LLVM的优化pass来编译，其实无法确定到底生成的IR对不对——有没有正确实现想要表达的语义。如果有些代码生成模式已经大规模写进去了，然后才发现不对，那改起来就会极其痛苦。毕竟最终LLILC还是想要打开LLVM的优化的，不然要它来干嘛，所以这不得不面对的问题，还是早点面对了比较好。&lt;/p&gt;&lt;p&gt;而借由CoreCLR的conservative GC支持的初步运行也可能掩盖了一些其实难以解决的问题，等后面真的要尝试解决的时候才发现困难的话多头疼。&lt;/p&gt;&lt;p&gt;说来，LLILC一开始就决定放弃CoreCLR的JIT所支持的“fully interruptible code”了。这种东西用LLVM实现确实非常别扭，放弃就放弃吧。&lt;/p&gt;&lt;br&gt;&lt;p&gt;============================================&lt;br&gt;&lt;/p&gt;&lt;p&gt;不知道他们是不是遇到了什么解决起来很麻烦（我不想说“无法解决”）的技术问题，导致这个项目被放弃/搁置/降低优先级了。C# / CLR需要支持的功能确实比Java要复杂许多，因此LLILC也遇到了许多我们在我们的基于LLVM的JVM JIT编译器里不会遇到的问题。&lt;/p&gt;&lt;p&gt;同事提到，跟LLILC组的人讨论的时候，他们提出过许多问题。&lt;/p&gt;&lt;p&gt;其中一个是：C#有value type，在CLR / CoreCLR的实现中value type既可能被分配在栈帧里，也可能被box后分配在托管堆里；而且C#还支持pass-by-reference的参数传递模式，一个类型为value type的reference到底是引用着一个栈上还是堆上的value type实例，从被调用方法的一侧是无从知道的。然而如果用LLVM的address space来实现对普通内存（用默认address space）和托管堆内存（用某个自定义address space）的区分，LLVM就要求要把指针声明为对应的address space，这样一个指针就不允许既可能指向栈上对象又可能指向堆上对象，于是处理起来就有点麻烦。&lt;/p&gt;&lt;p&gt;另外，C#的value type里可以包含托管指针字段。如果一个含有托管指针字段的value type值被分配在栈上，而GC又要求对栈上的托管指针做准确式扫描（precise GC / type-exact GC），那么当然这些栈上的托管指针要能被正确处理。然而Azul给LLVM加入的&lt;a href=&quot;http://llvm.org/docs/Statepoints.html&quot; data-editable=&quot;true&quot; data-title=&quot;gc.statepoint&quot;&gt;gc.statepoint&lt;/a&gt;并不能直接处理这种情况——gc.statepoint所能指定的root set都是LLVM IR意义上的SSA value，而不包括实际在内存栈帧里的值；即便给gc.statepoint添加对栈帧内存的支持，在LLVM IR里想要精确控制&lt;b&gt;&lt;i&gt;整个栈帧&lt;/i&gt;&lt;/b&gt;在内存里的布局是非常困难甚至可能做不到的——是，每一个alloca内部的布局是可以精确控制的，但如果我们想精确控制某个slot在栈帧里的实际偏移量，做不到。而C#的value type是一个需要精确控制内存布局的聚合类型（aggregate type），我们不能说把里面的字段给打散了分别处理然后再聚合回来，而总是得保证整个value type的值打包在一起处理。&amp;lt;- 让我找找看LLILC的issues或者wiki之类的地方有没有人讨论过这个问题然后再来补充。&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">21602080</guid>
<pubDate>Fri, 15 Jul 2016 11:09:49 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[新闻] 龙芯开源了OpenJDK8的MIPS64 port</title>
<link>https://zhuanlan.zhihu.com/p/20853163</link>
<description>&lt;a href=&quot;http://mail.openjdk.java.net/pipermail/porters-dev/2016-May/000544.html&quot; data-editable=&quot;true&quot; data-title=&quot;OpenJDK 8 port for MIPS has been open sourced by Loongson&quot;&gt;OpenJDK 8 port for MIPS has been open sourced by Loongson&lt;/a&gt;&lt;p&gt;太激动了！开源世界源源不断的好消息！&lt;/p&gt;&lt;p&gt;龙芯贡献出来的这个MIPS64 port可能是国内公司对OpenJDK做出的单个最大的贡献了。就为了这个规模也值得记录在册。&lt;/p&gt;&lt;p&gt;感谢所有参与了OpenJDK移植到龙芯以及将其开源的工作的大大们 ^_^&lt;br&gt;&lt;/p&gt;&lt;p&gt;除了龙芯之外，目前国内对OpenJDK贡献最活跃的公司是华为；阿里也有向OpenJDK贡献过代码。&lt;/p&gt;&lt;p&gt;更新：敖琪大大发的宣传稿：&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4Mjc1NzIyOQ==&amp;amp;mid=2650613858&amp;amp;idx=1&amp;amp;sn=a621a8ca47688076e995f6fb9d09cf75&amp;amp;scene=0&amp;amp;pass_ticket=3nCh51VB1d%2FU9Dh8ADVjpZyfMZLpfmFxmjSmGE2%2BQVk%3D&quot;&gt;龙芯软件生态系列文章——聊聊龙芯Java开源&lt;/a&gt;&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">20853163</guid>
<pubDate>Fri, 06 May 2016 08:32:28 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[新闻] Chez Scheme开源了</title>
<link>https://zhuanlan.zhihu.com/p/20808925</link>
<description>&lt;p&gt;&lt;a href=&quot;https://github.com/cisco/ChezScheme&quot; data-editable=&quot;true&quot; data-title=&quot;GitHub - cisco/ChezScheme: Chez Scheme&quot;&gt;GitHub - cisco/ChezScheme: Chez Scheme&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;有人说不就是开源了个Scheme编译器么有啥那么激动的。&lt;/p&gt;当然激动啦。这是Chez Scheme啊。&lt;p&gt;我大三开始学Scheme和啃SICP是从Petite Chez Scheme 7.4开始的。能一睹完整版Chez Scheme的芳容真是太爽了——即便是重写过的新Chez Scheme，不应该说重写过了更好哇哈哈。&lt;/p&gt;&lt;p&gt;近来各种原本根本无法想像会开源的项目居然都开源了，特别是在编译器和托管运行时这边，整个潮流就很让人激动。传闻6月份IBM J9配套的JIT编译器Testarossa的核心部分也会开源到OMR项目中，又是一重磅产品。&lt;/p&gt;&lt;p&gt;现在的小朋友要学习这方面，从入门级到高度优化的产品级项目都有众多开源项目可参考，多方便啊。我都恨不得想迟个十来年出生了，正好能在学校里赶上这浪潮 &amp;gt;_&amp;lt;&lt;/p&gt;&lt;p&gt;相关链接：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对Chez Scheme的过往历史感兴趣的同学，请先读读作者的论文：&lt;a href=&quot;http://www.cs.indiana.edu/~dyb/pubs/hocs.pdf&quot; data-editable=&quot;true&quot; data-title=&quot;indiana.edu 的页面&quot; class=&quot;&quot;&gt;The Development of Chez Scheme&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Ikarus：&lt;a href=&quot;https://launchpad.net/ikarus&quot; data-editable=&quot;true&quot; data-title=&quot;Ikarus Scheme in Launchpad&quot;&gt;Ikarus Scheme in Launchpad&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Vicare：&lt;a href=&quot;http://marcomaggi.github.io/vicare.html&quot; data-editable=&quot;true&quot; data-title=&quot;Marco&#39;s GitHub Pages&quot;&gt;Marco&#39;s GitHub Pages&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;P.S. 请不要等我“评论”Chez Scheme，我自己还得好好学习一下它到底做了什么，都怎么做的，无力“评论”啊。我也想坐等大神来指条明路如何学习它嗯。&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">20808925</guid>
<pubDate>Wed, 27 Apr 2016 07:40:58 +0800</pubDate>
<media:thumbnail url="" />
</item>
</channel>
</rss>
