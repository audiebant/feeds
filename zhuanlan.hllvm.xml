<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>编程语言与高级语言虚拟机杂谈（仮）</title>
<link>https://zhuanlan.zhihu.com/hllvm</link>
<description>探讨编程语言的设计与实现</description>
<language>zh-cn</language>
<lastBuildDate>Wed, 31 Aug 2016 16:19:57 +0800</lastBuildDate>
<image>
<url>https://pic4.zhimg.com/4b70deef7_xl.jpg</url>
<title>编程语言与高级语言虚拟机杂谈（仮）</title>
<link>https://zhuanlan.zhihu.com/hllvm</link>
</image>
<item>
<title>[新闻] Android Runtime（ART）的一些新动态，2016-08</title>
<link>https://zhuanlan.zhihu.com/p/22253472</link>
<description>ART Optimizing Compiler终于也忍不住添加了图着色寄存器分配器：&lt;p&gt;&lt;a href=&quot;https://android.googlesource.com/platform/art/+log/master/compiler/optimizing/register_allocator_graph_color.h&quot; data-editable=&quot;true&quot; data-title=&quot;googlesource.com 的页面&quot; class=&quot;&quot;&gt;compiler/optimizing/register_allocator_graph_color.h&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;这有意思啊。勇于承担更长时间的编译么。&lt;/p&gt;&lt;br&gt;&lt;p&gt;然后ART的Concurrent Copying GC近来的变化也值得关注。它有一种新的read barrier type，以前没在别的地方见过的：它会在对象头上使用一个bit来记录该对象里的引用类型字段在dereference的时候是否需要经过read barrier。这做法挺新奇的。效果是不是真的好另论，总之先学习一下这个思路的来龙去脉总是件趣事。&lt;/p&gt;&lt;br&gt;&lt;p&gt;话说之前一个关于&lt;a href=&quot;https://zhuanlan.zhihu.com/p/20569303&quot; data-editable=&quot;true&quot; data-title=&quot;ART又要考虑用基于LLVM的编译器了… - 编程语言与高级语言虚拟机杂谈（仮） - 知乎专栏&quot; class=&quot;&quot;&gt;ART又要考虑用基于LLVM的编译器&lt;/a&gt;的小道消息果然是假的么。隔了那么久并没有收到真的有这方面动静的消息。&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">22253472</guid>
<pubDate>Wed, 31 Aug 2016 15:23:52 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>架构最快最好的To JS编译器</title>
<link>https://zhuanlan.zhihu.com/p/22216448</link>
<description>自己从事&lt;a href=&quot;https://github.com/bloomberg/bucklescript&quot; data-editable=&quot;true&quot; data-title=&quot;BuckleScript&quot; class=&quot;&quot;&gt;BuckleScript&lt;/a&gt; 的编译器的开发已有近一年， 下周即将发布1.0，这里面有太多故事可以写了，知乎第一篇文章献给它。&lt;p&gt;虽然BuckleScript 才马上到1.0， 但是它已经被一些公司所采用，比如它已经被Facebook的某些产品用到了。自己也在和著名的ReactJS/ReactNative的作者Jordan 合作希望能推出 Reason On React (Powered by BuckleScript) 希望这能够给BuckleScript 带来killer app. 而BuckleScript 本身的编译器是用OCaml 写得，可以被编译成汇编和JS本身（压缩后大小700KB), 用户们可以自己感受下它的编译速度, Try here: &lt;a href=&quot;http://bloomberg.github.io/bucklescript/js-demo/&quot; data-editable=&quot;true&quot; data-title=&quot;OCaml to Javascript transpiler playground&quot;&gt;OCaml to Javascript transpiler playground&lt;/a&gt; 注意汇编的版本比JS的版本还要快一个数量级。&lt;/p&gt;&lt;p&gt;BuckleScript 早期是我的个人项目：因为注意到 现在软件行业--从互联网行业到传统软件领域--有一个很明显趋势: Javascript platform，&lt;a href=&quot;https://www.youtube.com/watch?v=jFU-wc28lF4&quot; data-title=&quot;这个唯一的跨平台语言正在吞噬着所有软件领域&quot; class=&quot;&quot; data-editable=&quot;true&quot;&gt;这个唯一的跨平台语言正在吞噬着所有软件领域&lt;/a&gt;（因为mobile的崛起Java 已经不再是一个跨平台语言了)：&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;浏览器已经不再只是deliver 内容的一个平台，越来越多的应用程序开始通过浏览器直接deploy，像上面提到的BuckleScript playground 整个工业级别的编译器直接跑在浏览器上 这甚至在5年前都是不可想象的。&lt;/li&gt;&lt;li&gt;Google最近主推的&lt;a href=&quot;https://developers.google.com/web/progressive-web-apps/&quot; data-editable=&quot;true&quot; data-title=&quot;Progressive Web APP&quot; class=&quot;&quot;&gt;Progressive Web APP&lt;/a&gt; 将会给浏览器带来更强大的API. 而最新的&lt;a href=&quot;https://webassembly.github.io/&quot; data-editable=&quot;true&quot; data-title=&quot;Web Assembly 标准&quot;&gt;Web Assembly 标准&lt;/a&gt; 将会使得JavaScript 平台可以覆盖更多的领域：比如传统的数值计算领域。WASM相当于给JavaScript 提供了一个接入native平台的FFI, JavaScript 作为这个平台的胶水语言毫无疑问有着最多的机会。&lt;/li&gt;&lt;li&gt;JavaScript 平台已经不再局限于浏览器， 相反它已经开始反噬， 开始入侵其它领域 最有名的是&lt;a href=&quot;https://nodejs.org/en/&quot; data-editable=&quot;true&quot; data-title=&quot;NodeJS&quot;&gt;NodeJS&lt;/a&gt;, &lt;a href=&quot;http://electron.atom.io/&quot; data-editable=&quot;true&quot; data-title=&quot;Electron&quot;&gt;Electron&lt;/a&gt;, &lt;a href=&quot;http://johnny-five.io/&quot; data-editable=&quot;true&quot; data-title=&quot;IoT&quot;&gt;IoT&lt;/a&gt; 等&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;p&gt;为什么要自己写一个这样的编译器呢? 虽然JavaScript平台很诱人，但是“动态语言难于构建大型程序” 基本上已经是业界共识，一旦程序规模上来了，基本上就只能Write Only. 作者所在的公司有上千万行JS, 维护起来基本上就是噩梦，在原来的Hack上添加新的if else Hack。而工业界真正有工业强度而且和JavaScript 交互良好的的编译器是微软的typescript 编译器，接下来就展开说下为什么BuckleScript 比typescript 更快更好。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;更好的平台拓展性：BuckleScript 不是一个新的语言，它是把一个已经存在将近30年的语言OCaml编译成可读的JavaScript. 而OCaml本身对很多平台存在native 的后端支持。像go一样, OCaml可以编译出汇编代码到iOS,Android, Windows,Linux, MacOS。而typescript只有JavaScript 一个后端，拥抱JavaScript 并不代表我们就要抛弃native 平台，当我们需要更快更可靠的性能的时候，我们可以有更多的选择，比如做工具链的时候: typescript 的编译器同样也是用typescript写得可以跑在浏览器里也可以泡在node上，但是它跑在node上得时候就比BuckleScript编译成汇编跑慢不止一个数量级。&lt;br&gt;&lt;/li&gt;&lt;li&gt;更好的类型安全: typescript是一个JS的超集，它存在很多历史包袱。而微软引入typescript更多的是作为一个工具来使用的比如IDE的代码补全，相对安全的代码重构。而这个类型的准确从第一天开始就不是它的设计初衷，以至于Facebook自己设计了一个相对更准确地类型系统&lt;a href=&quot;https://github.com/facebook/flow&quot; data-editable=&quot;true&quot; data-title=&quot;Flow&quot;&gt;Flow&lt;/a&gt;. 而OCaml的类型系统是已经被形式化的证明过正确的。也就是说从理论上BuckleScript 能够保证一旦编译通过是不会有运行时候类型错误的，而typescript远远做不到这点。&lt;/li&gt;&lt;li&gt;更多的类型推断，更好的语言特性：用过typescript的人都知道，typescript的类型推断很弱，基本上所有参数都需要显示的标注类型。不光是这点，像对函数式编程的支持，高阶类型系统GADT的支持几乎是没有。而OCaml本身是一个比Elm,PureScript还要强大的多的语言，它自身有一个非常高阶的module system，是为数不多的对dependent type提供支持的语言，polymorphic variant。而且pattern match的编译器也是优化过的。&lt;/li&gt;&lt;li&gt;程序优化，代码删除。BuckleScript不只是一个编译器更是一个optimizing compiler: 它做过的优化有: Code motion, Purity analysis, Cross module inliner, Constant folding/propagation, partial evaluation Strength reduction, escape analysis。我们做的benchmark显示同样的immutable data structure 比如&lt;a href=&quot;https://facebook.github.io/immutable-js/&quot; data-editable=&quot;true&quot; data-title=&quot;facebook immutablejs&quot;&gt;facebook immutablejs&lt;/a&gt;, BuckleScript的实现有时候要快两到三倍不止。而相比之下typescript编译器并不会做任何优化工作。&lt;/li&gt;&lt;/ol&gt;&lt;br&gt;&lt;p&gt;因为自己接触到的专业术语都是英文的，作者试着尽可能用中文表述，可能翻译过来的中文不太准确，尽请谅解, 接下来我还会写几篇文章讲讲它的底层设计，如果读者能够读到这里, 还请在github上友情支援一下 : )。&lt;/p&gt;&lt;p&gt;小时候读韩愈的《马说》， 不太理解这句话 “世有伯乐， 然后有千里马，千里马常有，而伯乐不常有”。 长大以后慢慢的对这句话才真的理解，真的要好好感谢一路过来给我无限指导和关怀的老师/老板们，我也庆幸自己很幸运，自己的每一任老师或者老板 ，不管自己做什么，都能够得到你们的理解和支持。&lt;/p&gt;</description>
<author>张宏波</author>
<guid isPermaLink="false">22216448</guid>
<pubDate>Mon, 29 Aug 2016 04:18:25 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>为什么Python里面的locals()是只读的</title>
<link>https://zhuanlan.zhihu.com/p/21815224</link>
<description>Python里面的各个名字空间都可以抽象成一个dictionary, 比如函数的本地变量就可以通过build-in函数locals()来取得。但是很多资料都提到通过locals()取得的dictionary是只读的，比较好奇为什么会有这个限制。下面是一个点单的对locals()的调用 （在CPython 2.7下运行得到）:&lt;code lang=&quot;python&quot;&gt;&amp;gt;&amp;gt;&amp;gt; def foo(a):
...   return locals()
...
&amp;gt;&amp;gt;&amp;gt; dis.dis(foo)
  2           0 LOAD_GLOBAL              0 (locals)
              3 CALL_FUNCTION            0
              6 RETURN_VALUE
&lt;/code&gt;&lt;p&gt;-- 补充，按R大提到的，CPython的local variable都是放在frame的localplus数组里面，而locals()返回的是dictionary对象，通过这个dictionary对象不能直接修改localplus上的值也是很直观的。&lt;/p&gt;&lt;p&gt;locals在global空间(LOAD_GLOBAL), 这个build-in方法最终在bltinmodule.c里面实现如下：&lt;/p&gt;&lt;code lang=&quot;c&quot;&gt;static PyObject *
builtin_locals(PyObject *self)
{
    PyObject *d;

    d = PyEval_GetLocals();
    Py_XINCREF(d);
    return d;
}
&lt;/code&gt;&lt;p&gt;主要是转到ceval.c的PyEval_GetLocals()上：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;PyObject *
PyEval_GetLocals(void)
{
    PyFrameObject *current_frame = PyEval_GetFrame();
    if (current_frame == NULL)
        return NULL;
    PyFrame_FastToLocals(current_frame);
    return current_frame-&amp;gt;f_locals;
}
&lt;/code&gt;&lt;p&gt;又转到frameobject.c里的PyFrame_FastToLocals(PyFrameObject *f)上。不考虑错误和cellvar的处理等，主要部分如下：&lt;/p&gt;&lt;code lang=&quot;c&quot;&gt;PyFrame_FastToLocals(PyFrameObject *f)
{
    /* Merge fast locals into f-&amp;gt;f_locals */
    PyObject *locals, *map;
    PyObject **fast;
    PyCodeObject *co;
    Py_ssize_t j;
    locals = f-&amp;gt;f_locals;
    if (locals == NULL) {
        locals = f-&amp;gt;f_locals = PyDict_New();
    }
    co = f-&amp;gt;f_code;

    map = co-&amp;gt;co_varnames;
    fast = f-&amp;gt;f_localsplus;
    j = PyTuple_GET_SIZE(map);
    if (co-&amp;gt;co_nlocals)
        map_to_dict(map, j, locals, fast, 0);
&lt;/code&gt;&lt;p&gt;最主要的map_to_dict（同在frameobject.c）就会把存在f-&amp;gt;localsplus里面的local variable (所有的local variable name在co-&amp;gt;varnames里面）放到locals所指向的dictionary, 也同时放在了当前frame里（f-&amp;gt;locals）。所有的local variable很自然成为一个名字空间放进dictionary，这里放进数组风格的f_localsplus里面是为了不用每次使用local variable都查找dictionary。可以搜索此变量名获得更多信息。&lt;/p&gt;&lt;code lang=&quot;c&quot;&gt;static void
map_to_dict(PyObject *map, Py_ssize_t nmap, PyObject *dict, PyObject **values,
            int deref)
{
    Py_ssize_t j;
    for (j = nmap; --j &amp;gt;= 0; ) {
        PyObject *key = PyTuple_GET_ITEM(map, j);
        PyObject *value = values[j];
        if (deref) {
            value = PyCell_GET(value);
        }
        if (value == NULL) {
            if (PyObject_DelItem(dict, key) != 0)
                PyErr_Clear();
        }
        else {
            if (PyObject_SetItem(dict, key, value) != 0)
                PyErr_Clear();
        }
    }
}
&lt;/code&gt;&lt;p&gt;上面的map_to_dict会遍历所有的local variable names, 如果这个variable指向了Python对象则把variable name和对象放进要返回的dictionary对象(f-&amp;gt;f_locals)，这也就意味着每次对locals()的调用都会把frame object里面的dictionary (f_locals)的所有variable name到object的映射根据当前状态刷新，就相当于给所有的local vars照相（snapshot）。这样就能比较容易理解为什么对locals()返回的dictionary是无效的的，因为直接写入这个dictionary只会影响dictionary自身而不会反映到当前frame的f_localsplus，每次调用locals()又会刷新要返回的dictionary内容。下面的例子可以帮助理解这点。&lt;/p&gt;&lt;code lang=&quot;c&quot;&gt;def f():
    x = 10
    lc = locals()
    lc[&#39;x&#39;] = 20
    # &#39;x&#39;-&amp;gt;20 remains on dictionary before locals() is called
    print lc
    # {&#39;x&#39;: 20}                 
    locals()
    # locals dictionary is refreshed in the above call to locals()
    print lc
    # {&#39;x&#39;: 10, &#39;lc&#39;: {...}}     

f()&lt;/code&gt;&lt;p&gt;&lt;a href=&quot;https://docs.python.org/2/library/functions.html#locals&quot; data-title=&quot;CPython&quot; class=&quot;&quot; data-editable=&quot;true&quot;&gt;CPython&lt;/a&gt;官网对locals()的主要描述如下，也说明返回的dictionary只是代表了local symbol table, 并不能等价使用（修改）。&lt;/p&gt;&lt;blockquote&gt;Update and return a dictionary representing the current local symbol table&lt;/blockquote&gt;</description>
<author>Thomson</author>
<guid isPermaLink="false">21815224</guid>
<pubDate>Mon, 01 Aug 2016 15:09:37 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[新闻] ChakraCore已支持运行在Linux上</title>
<link>https://zhuanlan.zhihu.com/p/21825477</link>
<description>&lt;p&gt;上周刚announce的&lt;a href=&quot;https://blogs.windows.com/msedgedev/2016/07/27/chakracore-on-linux-osx/&quot; data-title=&quot;消息&quot; class=&quot;&quot;&gt;消息&lt;/a&gt;，CharakCore已经能运行在Linux和OSX 10.9+上。目前能运行的是interpreter（pass了绝大部分tests），JIT和concurrent GC还正在进行中。同时node-chakracore也更新了，能运行在Linux上。&lt;/p&gt;</description>
<author>Thomson</author>
<guid isPermaLink="false">21825477</guid>
<pubDate>Tue, 02 Aug 2016 04:26:18 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[题外] 技术演进与代码工人</title>
<link>https://zhuanlan.zhihu.com/p/21916716</link>
<description>&lt;p&gt;娱乐一下。&lt;/p&gt;上周在开JVMLS，有机会跟很多同行大佬们聊天。其中听说的一个好玩的想法是：现在在软件开发行业有大量低端职位是不断在做重复开发，重复的低质量开发。然而这样的代码还是会被部署到生产环境，成为许多软件产品的重要组成部分。&lt;p&gt;让机器完全替代人类来写所有代码显然还不是近期能实现的。但如果我们能容忍一些不那么重要（或者或许本来应该重要）的程序是低端程序员造出来的低质量轮子，那能不能让机器来替代人类做好这部分？据说像Gilad Bracha、Erik Meijer等大牛都转向研究机器学习，目标之一就是让机器能部分代替人类写代码。多有趣。&lt;/p&gt;&lt;p&gt;这种东西真能成的话，以后就越来越不需要现在的这种低端码农了吧。就像在机械化、自动化生产线上，越来越不需要低端的人类手工劳作，而是需要高端技工去管理那些机器一样。&lt;/p&gt;&lt;p&gt;虽然不是啥新闻，但突然听说业界的前辈（特别是同做JVM以及其它managed language研发的前辈们）真的投身去做这种研究，还是不免觉得机器写代码离现实又近了一步。&lt;/p&gt;&lt;p&gt;觉得把写代码当作生产线比喻不恰当的同学，你们或许没有见识过真正的低端码农的工作环境和内容。那货真价实就是个人肉生产线，一堆人不断的重复写着一样的代码去实现略微变化的功能。这些生产线与现代软件工程的良好实践基本无缘。正好有同学开过公司做网游，听他们说起这种工作方式的时候我不禁打寒颤。虽然不好，但这样的事情现在也还大量存在。&lt;/p&gt;&lt;p&gt;（Lars Bak之前带Dart团队，后来不直接带团队了而是到处去推销Dart。现在半退休状态的他具体在干嘛了呢？&lt;/p&gt;&lt;p&gt;Erik Meijer虽然还在带Hack团队，完善Hack的类型系统的更新设计，但据说他也在涉及机器学习方向想减少人肉重复堆代码的必要性。这个好玩。）&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">21916716</guid>
<pubDate>Mon, 08 Aug 2016 11:33:22 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[八卦] LLILC项目貌似挂了…</title>
<link>https://zhuanlan.zhihu.com/p/21602080</link>
<description>刚跟同事聊天的时候听说原来我们已经好一段时间没有跟LLILC项目组的人开过定期会议了，而且近期我们在LLVM邮件列表上试着推的GC指针功能，LLILC项目的人也没人来参与讨论…&lt;p&gt;关于LLILC是什么，请跳传送门：&lt;a href=&quot;https://www.zhihu.com/question/29544174&quot; class=&quot;&quot; data-title=&quot;如何看待微软LLILC，一个新的基于LLVM的CoreCLR JIT/CoreRT AOT编译器？&quot; data-editable=&quot;true&quot;&gt;如何看待微软LLILC，一个新的基于LLVM的CoreCLR JIT/CoreRT AOT编译器？&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Andy Ayers大大会不会抓狂了，Phoenix和LLILC都挂了的话…&lt;/p&gt;&lt;p&gt;============================================&lt;/p&gt;&lt;p&gt;LLILC项目的开发过程上可能也有些隐患。&lt;/p&gt;&lt;p&gt;其中很有趣很subtle的一点是：他们在项目初期决定先实现对MSIL的大范围的支持，为此抄了些捷径：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;生成LLVM IR后，几乎不打开LLVM的优化pass，直接去生成目标代码&lt;/li&gt;&lt;li&gt;使用CoreCLR的GC的后备漠视——保守式GC（conservative GC），这样就可以让LLILC不处理栈上的托管指针，而是让CoreCLR自己去保守式扫描栈上的值去猜哪些是托管指针。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这俩捷径的好处是项目初期可以快速推进进度，把大部分MSIL指令都支持上，让LLILC可以编译一些小程序来测试。&lt;/p&gt;&lt;p&gt;但坏处在后期会慢慢浮现出来：一个编译器前端在生成LLVM IR后，如果不打开LLVM的优化pass来编译，其实无法确定到底生成的IR对不对——有没有正确实现想要表达的语义。如果有些代码生成模式已经大规模写进去了，然后才发现不对，那改起来就会极其痛苦。毕竟最终LLILC还是想要打开LLVM的优化的，不然要它来干嘛，所以这不得不面对的问题，还是早点面对了比较好。&lt;/p&gt;&lt;p&gt;而借由CoreCLR的conservative GC支持的初步运行也可能掩盖了一些其实难以解决的问题，等后面真的要尝试解决的时候才发现困难的话多头疼。&lt;/p&gt;&lt;p&gt;说来，LLILC一开始就决定放弃CoreCLR的JIT所支持的“fully interruptible code”了。这种东西用LLVM实现确实非常别扭，放弃就放弃吧。&lt;/p&gt;&lt;br&gt;&lt;p&gt;============================================&lt;br&gt;&lt;/p&gt;&lt;p&gt;不知道他们是不是遇到了什么解决起来很麻烦（我不想说“无法解决”）的技术问题，导致这个项目被放弃/搁置/降低优先级了。C# / CLR需要支持的功能确实比Java要复杂许多，因此LLILC也遇到了许多我们在我们的基于LLVM的JVM JIT编译器里不会遇到的问题。&lt;/p&gt;&lt;p&gt;同事提到，跟LLILC组的人讨论的时候，他们提出过许多问题。&lt;/p&gt;&lt;p&gt;其中一个是：C#有value type，在CLR / CoreCLR的实现中value type既可能被分配在栈帧里，也可能被box后分配在托管堆里；而且C#还支持pass-by-reference的参数传递模式，一个类型为value type的reference到底是引用着一个栈上还是堆上的value type实例，从被调用方法的一侧是无从知道的。然而如果用LLVM的address space来实现对普通内存（用默认address space）和托管堆内存（用某个自定义address space）的区分，LLVM就要求要把指针声明为对应的address space，这样一个指针就不允许既可能指向栈上对象又可能指向堆上对象，于是处理起来就有点麻烦。&lt;/p&gt;&lt;p&gt;另外，C#的value type里可以包含托管指针字段。如果一个含有托管指针字段的value type值被分配在栈上，而GC又要求对栈上的托管指针做准确式扫描（precise GC / type-exact GC），那么当然这些栈上的托管指针要能被正确处理。然而Azul给LLVM加入的&lt;a href=&quot;http://llvm.org/docs/Statepoints.html&quot; data-editable=&quot;true&quot; data-title=&quot;gc.statepoint&quot;&gt;gc.statepoint&lt;/a&gt;并不能直接处理这种情况——gc.statepoint所能指定的root set都是LLVM IR意义上的SSA value，而不包括实际在内存栈帧里的值；即便给gc.statepoint添加对栈帧内存的支持，在LLVM IR里想要精确控制&lt;b&gt;&lt;i&gt;整个栈帧&lt;/i&gt;&lt;/b&gt;在内存里的布局是非常困难甚至可能做不到的——是，每一个alloca内部的布局是可以精确控制的，但如果我们想精确控制某个slot在栈帧里的实际偏移量，做不到。而C#的value type是一个需要精确控制内存布局的聚合类型（aggregate type），我们不能说把里面的字段给打散了分别处理然后再聚合回来，而总是得保证整个value type的值打包在一起处理。&amp;lt;- 让我找找看LLILC的issues或者wiki之类的地方有没有人讨论过这个问题然后再来补充。&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">21602080</guid>
<pubDate>Fri, 15 Jul 2016 11:09:49 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[新闻] 龙芯开源了OpenJDK8的MIPS64 port</title>
<link>https://zhuanlan.zhihu.com/p/20853163</link>
<description>&lt;a href=&quot;http://mail.openjdk.java.net/pipermail/porters-dev/2016-May/000544.html&quot; data-editable=&quot;true&quot; data-title=&quot;OpenJDK 8 port for MIPS has been open sourced by Loongson&quot;&gt;OpenJDK 8 port for MIPS has been open sourced by Loongson&lt;/a&gt;&lt;p&gt;太激动了！开源世界源源不断的好消息！&lt;/p&gt;&lt;p&gt;龙芯贡献出来的这个MIPS64 port可能是国内公司对OpenJDK做出的单个最大的贡献了。就为了这个规模也值得记录在册。&lt;/p&gt;&lt;p&gt;感谢所有参与了OpenJDK移植到龙芯以及将其开源的工作的大大们 ^_^&lt;br&gt;&lt;/p&gt;&lt;p&gt;除了龙芯之外，目前国内对OpenJDK贡献最活跃的公司是华为；阿里也有向OpenJDK贡献过代码。&lt;/p&gt;&lt;p&gt;更新：敖琪大大发的宣传稿：&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4Mjc1NzIyOQ==&amp;amp;mid=2650613858&amp;amp;idx=1&amp;amp;sn=a621a8ca47688076e995f6fb9d09cf75&amp;amp;scene=0&amp;amp;pass_ticket=3nCh51VB1d%2FU9Dh8ADVjpZyfMZLpfmFxmjSmGE2%2BQVk%3D&quot;&gt;龙芯软件生态系列文章——聊聊龙芯Java开源&lt;/a&gt;&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">20853163</guid>
<pubDate>Fri, 06 May 2016 08:32:28 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[新闻] Chez Scheme开源了</title>
<link>https://zhuanlan.zhihu.com/p/20808925</link>
<description>&lt;p&gt;&lt;a href=&quot;https://github.com/cisco/ChezScheme&quot; data-editable=&quot;true&quot; data-title=&quot;GitHub - cisco/ChezScheme: Chez Scheme&quot;&gt;GitHub - cisco/ChezScheme: Chez Scheme&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;有人说不就是开源了个Scheme编译器么有啥那么激动的。&lt;/p&gt;当然激动啦。这是Chez Scheme啊。&lt;p&gt;我大三开始学Scheme和啃SICP是从Petite Chez Scheme 7.4开始的。能一睹完整版Chez Scheme的芳容真是太爽了——即便是重写过的新Chez Scheme，不应该说重写过了更好哇哈哈。&lt;/p&gt;&lt;p&gt;近来各种原本根本无法想像会开源的项目居然都开源了，特别是在编译器和托管运行时这边，整个潮流就很让人激动。传闻6月份IBM J9配套的JIT编译器Testarossa的核心部分也会开源到OMR项目中，又是一重磅产品。&lt;/p&gt;&lt;p&gt;现在的小朋友要学习这方面，从入门级到高度优化的产品级项目都有众多开源项目可参考，多方便啊。我都恨不得想迟个十来年出生了，正好能在学校里赶上这浪潮 &amp;gt;_&amp;lt;&lt;/p&gt;&lt;p&gt;相关链接：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对Chez Scheme的过往历史感兴趣的同学，请先读读作者的论文：&lt;a href=&quot;http://www.cs.indiana.edu/~dyb/pubs/hocs.pdf&quot; data-editable=&quot;true&quot; data-title=&quot;indiana.edu 的页面&quot; class=&quot;&quot;&gt;The Development of Chez Scheme&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Ikarus：&lt;a href=&quot;https://launchpad.net/ikarus&quot; data-editable=&quot;true&quot; data-title=&quot;Ikarus Scheme in Launchpad&quot;&gt;Ikarus Scheme in Launchpad&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Vicare：&lt;a href=&quot;http://marcomaggi.github.io/vicare.html&quot; data-editable=&quot;true&quot; data-title=&quot;Marco&#39;s GitHub Pages&quot;&gt;Marco&#39;s GitHub Pages&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;P.S. 请不要等我“评论”Chez Scheme，我自己还得好好学习一下它到底做了什么，都怎么做的，无力“评论”啊。我也想坐等大神来指条明路如何学习它嗯。&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">20808925</guid>
<pubDate>Wed, 27 Apr 2016 07:40:58 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>ChakraCore的dump开关</title>
<link>https://zhuanlan.zhihu.com/p/20792855</link>
<description>&lt;a href=&quot;https://github.com/Microsoft/ChakraCore&quot; data-editable=&quot;true&quot; data-title=&quot;ChakraCore&quot;&gt;ChakraCore&lt;/a&gt;开源也有一阵了，作为最后开源的一个主流JS引擎，在GitHub上已经有了5000+的star，说明有很多人关注。对于想要研究ChakraCore的童鞋，如果直接从代码入手，不太容易下手和实验。对此，ChakraCore已经自带了不少dump开关来输出整个编译过程的中间结果，可以据此一窥整个编译的过程。这里就介绍下ChakraCore里面的常用dump开关。&lt;p&gt;ChakraCore编译出来是chakracore.dll，如果不想自己写一个host，可以用ChakraCore自带的host CH.exe. CH.exe使用的是JSRT接口来访问ChakraCore的编译功能。比如用ChakraCore运行下面的JS文件。&lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;function foo(a, b) {
    return a + b
}

print(foo(3, 4))

print(foo(5, 6))&lt;/code&gt;当CH.exe和chakracore.dll都编译好后（CH.exe依赖于后者，所以只要在Visual Studio编译CH.exe就可以），可以运行 “ch.exe foo.js -bgjit- -maxinterpretercount:1 -off:simplejit -dump:backend&quot;, 这样除了script运行的输出，编译的时候的中间结果也会输出到控制台。西面先解释下上面传入的各个参数。&lt;ul&gt;&lt;li&gt;-bgjit-，禁止JIT运行的background线程。ChakraCore里面JIT默认运行在专门的线程里面接收script线程发来的编译请求（CodeGenWorkItem), 这样的好处是不会阻塞script线程继续运行（interpret），但是也会给调试过程带来不确定性，所以不是调试相关的bug可以关掉。&lt;/li&gt;&lt;li&gt;-maxinterpretercount:1, 仅允许Javascript function被interpret一次。ChakraCore里面有Interpreter, SimpleJit, FullJit, 优化程度和耗时是依次递增，比较hot的函数也会一次进入这几个阶段。ChakraCore里面有heuristic机制来决定function何时进入下一个阶段。Debug的时候自然不能依赖这个来进入JIT，所以对interpret count设置固定值。一般这里推荐设置成1而不是0，因为需要运行一次interpreter来收集profile data供后面JIT使用。另外这个选项可以缩写成 &quot;-mic:1&quot;。&lt;/li&gt;&lt;li&gt;off:simplejit，关掉SimpleJIT。这个作为第二层优化，比FullJIT简单很多，作为interpreter和FullJIT之间的一个平衡，研究中可以关掉。&lt;/li&gt;&lt;li&gt;-dump:backend，输出JIT过程中的中间结果。Chakra的JIT分成了很多个phase（这个和UTC（VC++的c2.dll）很像，但是相比还是简单很多，其实phase dump也和UTC的很像，不得不说ChakraCore的JIT受了UTC的很大影响），第一个phase是IRBuilder把Parser生成的bytecode转成内部的IR结构（intermediate representation），后面典型的phase有Inline, GlobOpt, Lower, Encoder等。每个phase都会在IR上收集些信息供后面的phase使用，或者直接在IR上做变换。运行 ”ch.exe -?&quot;就可以看到phase列表。这里会列出相当多的phase，但实际上并不代表ChakraCore有这么多阶段来做优化，里面很多phase实际上代表了中比较具体的优化，这样可以通过 &quot;-off&quot; 选项来关闭相关的优化，比如CSE (common sub-expression elimination)，CopyProp都被列为一个phase，但是他们都是在GlobOpt里面做的。&quot;-dump&quot; 选项接收一个实际的phase做参数（比如IRBuilder, Lower)从而在相关phase结束后dump相应的中间结果。在研究JIT bug的是有经常需要把JIT的所有phase的结果都dump出来看看是哪个phase除了问题，全部都写上比较浪费时间，就有了一个“backend”来代表所有的phases。ChkaraCore的JIT主要是针对function的（另外一个是loop），这样dump一个有很多function的JS文件而已知问题出在某个function里面的时候，会很不方便，这里的dump选项还接受一个function Id来过滤，比如“-dump:backend:1” （function Id可以在不带function Id过滤的dump里面找到，如下面“#1.1”后面的1就是）。后续再介绍这里其他数字（从源代码也比较容易看出来）和每条IR的意思。最后需要注意的是所有的dump代码指编译在Debug版本的chakracore.dll里。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上面的JS在ChakraCore里面的实际dump如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;-----------------------------------------------------------------------------



************   IR after IRBuilder (FullJit)  ************
-----------------------------------------------------------------------------
Function foo ( (#1.1), #2)                        Instr Count:13

                       FunctionEntry                                          #
    s1[Object].var  =  Ld_A           0xXXXXXXXX (GlobalObject)[Object].var   #
    s2[LikelyCanBeTaggedValue_Int].var = ArgIn_A  prm2&amp;lt;40&amp;gt;.var                #
    s3[LikelyCanBeTaggedValue_Int].var = ArgIn_A  prm3&amp;lt;48&amp;gt;.var                #


  Line   2: return a + b
  Col    5: ^
                       StatementBoundary  #0                                  #0000
    s0.var          =  Add_A          s2.var, s3.var                          #0000
                       Br             $L1                                     #0004
    s0.var          =  Ld_A           0xXXXXXXXX (undefined)[Undefined].var   #0007
$L1:                                                                          #0009


  Line   3: }
  Col    1: ^
                       StatementBoundary  #1                                  #0009
                       StatementBoundary  #-1                                 #0009
                       Ret            s0.var                                  #0009

                       FunctionExit                                           #&lt;/code&gt;</description>
<author>Thomson</author>
<guid isPermaLink="false">20792855</guid>
<pubDate>Sat, 23 Apr 2016 14:51:47 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>lisp0</title>
<link>https://zhuanlan.zhihu.com/p/20689554</link>
<description>&lt;p&gt;代码没写完，广告先打起来&lt;a class=&quot;&quot; data-title=&quot;GitHub - bhuztez/lisp0: a bare minimum remake of origin LISP&quot; data-editable=&quot;true&quot; href=&quot;https://github.com/bhuztez/lisp0&quot;&gt; GitHub - bhuztez/lisp0: a bare minimum remake of origin LISP&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;学习高级语言Runtime最好的办法，当然是自己动手写一个啦。毫无疑问假如你不是特别喜欢走弯路的轮子哥，肯定选从容易的开始。那么就选最最原始的LISP好了(Brainfuck之类的过于简单，这里先忽略他们的存在)。lisp0不会像Lisp Machine是一台单独的机器，lisp0就是一个普通的运行在Linux的程序。&lt;/p&gt;&lt;p&gt;既然是把Runtime实现一遍，那么在操作系统之上全都自己来实现，连CRT和libc也不要用。因为Lisp语言自己就又栈了，所以C程序没事别递归，用的栈是非常有限的，于是用bss段里的一段内存当C语言的栈，而操作系统在启动时，分配来的栈，给Lisp用。这样虽然奇葩了点，非常省事啊。&lt;/p&gt;&lt;p&gt;因为(假装)lisp0是immutable的，所以只要简单的引用计数就可以了。不过这写起来麻烦，用一次就要增减一次。还不如先用个简单的Mark sweep GC。因为immutable，所以新的不能被旧的引用，在allocate后把他们串成一个栈，只要从新往旧扫一遍，在扫到时还没被标记，那就一定不会被标记到，可以放心的free。至于memory allocator，就用简陋的TLSF算法就好了，这算法看上去就像个增强版的Buddy allocator。&lt;br&gt;&lt;/p&gt;&lt;p&gt;既然Lisp霸占了原本给C用的栈，使用方式也就和C保持一致好了。因为GCC支持Labels as Values，所以只要在CALL之后放一个label，那个label的值就是返回地址了。同时，因为symbol只接受[_0-9A-Za-z]+，所以长度小于等于8的symbol，经过base64解码之后长度就只有6字节了，而64位机器上去掉3位tag，还有61位，完全放的下。&lt;/p&gt;&lt;p&gt;接下来，lisp0应该改用HAMT来实现environment，换一个更好的GC。本文到此就结束了。&lt;/p&gt;</description>
<author>bhuztez</author>
<guid isPermaLink="false">20689554</guid>
<pubDate>Wed, 30 Mar 2016 23:01:05 +0800</pubDate>
<media:thumbnail url="" />
</item>
</channel>
</rss>
