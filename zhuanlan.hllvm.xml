<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>编程语言与高级语言虚拟机杂谈（仮）</title>
<link>https://zhuanlan.zhihu.com/hllvm</link>
<description>探讨编程语言的设计与实现</description>
<language>zh-cn</language>
<lastBuildDate>Thu, 27 Oct 2016 17:52:55 +0800</lastBuildDate>
<image>
<url>https://pic4.zhimg.com/4b70deef7_xl.jpg</url>
<title>编程语言与高级语言虚拟机杂谈（仮）</title>
<link>https://zhuanlan.zhihu.com/hllvm</link>
</image>
<item>
<title>[新闻] Oracle开源了其Java AOT编译器</title>
<link>https://zhuanlan.zhihu.com/p/23247204</link>
<description>先放传送门：&lt;a href=&quot;http://mail.openjdk.java.net/pipermail/hotspot-dev/2016-October/025033.html&quot; data-editable=&quot;true&quot; data-title=&quot;[9] RFR(L) 8166415: Integrate AOT tool JAOTC&quot;&gt;[9] RFR(L) 8166415: Integrate AOT tool JAOTC&lt;/a&gt;&lt;p&gt;这是一个基于Graal的AOT编译器，可以跟JDK9+的HotSpot VM搭配使用。&lt;/p&gt;&lt;p&gt;这比我原本预期的要早得多。我原本以为会到明年甚至更之后才能看到这个项目开源出来。真是惊喜。&lt;/p&gt;&lt;p&gt;以后大家再也不能吐槽Java的默认实现没有AOT编译器了（逃&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">23247204</guid>
<pubDate>Thu, 27 Oct 2016 16:58:33 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[C++] GCC对C++虚函数调用的一个优化</title>
<link>https://zhuanlan.zhihu.com/p/23233548</link>
<description>这个专栏平时Java / JVM的内容偏多，今天混入一些新血液吧。来聊点C++的话题。&lt;p&gt;不过说起来还是跟JVM相关的内容。在JVM实现中，要达到高性能的一个重要方面就是要对虚方法调用做优化，要尽其所能将虚方法调用点去虚化（devirtualize），以便支持后续的优化。这是因为Java里非private的成员方法默认就是virtual的，大家愿意也好不愿意也好也很容易会写一大堆虚方法，再加上良好的面向对象风格的代码提倡要尽量写职责单一的小方法，一大堆小的虚方法如果不能好好优化，那性能是上不去的。&lt;/p&gt;&lt;p&gt;而在C++里，虚函数的开销则没Java那么引人关注，毕竟成员函数默认不是virtual的，而且还有&lt;a href=&quot;https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern&quot; data-editable=&quot;true&quot; data-title=&quot;CRTP&quot;&gt;CRTP&lt;/a&gt;之类的奇技淫巧来向别的方向取舍开销。但始终，对虚函数有优化需求这点跟Java还是很相似的。&lt;/p&gt;&lt;p&gt;很多同学都会在学习了一些C++的基础知识之后就偏执地认为C++的虚函数分派总是通过对vtable（虚函数表）的间接调用来做的，并且虚函数调用无法被内联。事实上编译器优化发展了那么多年，这种事情又怎会没有进一步的优化呢。&lt;/p&gt;&lt;p&gt;今天要说的就是相对新一些的GCC（&lt;a href=&quot;https://gcc.gnu.org/gcc-4.9/changes.html&quot; data-editable=&quot;true&quot; data-title=&quot;GCC 4.9&quot;&gt;GCC 4.9&lt;/a&gt;或更高）里的一种优化，由-fdevirtualize-speculatively参数控制的“speculative devirtualization”，或者用JVM里更常用的叫法是“guarded devirtualization”。&lt;/p&gt;&lt;p&gt;让我们先来看个例子：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;class Base {
  int value_;
public:
  virtual int foo() __attribute__ ((noinline)) {
    return 42 + this-&amp;gt;bar();
  }

  virtual int bar() {
    return value_;
  }
};

class Derived : public Base {
public:
  int bar() {
    return 256;
  }
};

int main() {
  Base* b = new Derived;
  return b-&amp;gt;foo();
}
&lt;/code&gt;&lt;p&gt;这个例子用GCC 4.9.2在-O2下编译，会发现Base::foo()里对bar()这个虚函数的调用就是普通的通过vtable分派的间接调用。用伪代码来说就是这样：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;// this-&amp;gt;bar()
bar_ptr = this-&amp;gt;_vptr[BAR_VTABLE_INDEX]; // load function entry point from vtable
tmp = bar_ptr();                         // indirect call&lt;/code&gt;&lt;p&gt;实际用GCC 4.9.2 -O2在Linux/x86-64上生成的Base::foo()函数的代码是这样的：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Base::foo():
        subq    $8, %rsp
        movq    (%rdi), %rax  # rax = this-&amp;gt;_vptr
        call    *8(%rax)      # call this-&amp;gt;_vptr[BAR_VTABLE_INDEX]
        addq    $8, %rsp
        addl    $42, %eax
        ret
&lt;/code&gt;&lt;p&gt;但是如果我们把上面代码例子中Derived::bar()的声明去掉，使得Derived类变成：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;class Derived : public Base {
};&lt;/code&gt;&lt;p&gt;再重新编译这个实验代码，就会发现Base::foo()里对bar()的调用变成了这个样子：（继续伪代码）&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;// this-&amp;gt;bar()
bar_ptr = this-&amp;gt;_vptr[BAR_VTABLE_INDEX]; // load function entry point from vtable
if (bar_ptr == Base::bar) {
  // inlined Base::bar()
  tmp = this-&amp;gt;value_;
} else {
  tmp = bar_ptr();                       // normal indirect virtual call
}&lt;/code&gt;&lt;p&gt;实际用GCC 4.9.2 -O2在Linux/x86-64上生成的新版本Base::foo()函数的代码是这样的：&lt;br&gt;&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Base::foo():
        movq    (%rdi), %rax
        movq    8(%rax), %rax
        cmpq    Base::bar(), %rax
        jne     .L3
        movl    8(%rdi), %eax
        addl    $42, %eax
        ret
.L3:
        subq    $8, %rsp
        call    *%rax
        addq    $8, %rsp
        addl    $42, %eax
        ret
&lt;/code&gt;&lt;p&gt;这种先做条件检查，然后在检查通过的分支里把虚函数调用变为非虚调用（进而可以被内联）的做法，就叫做“speculative devirtualization”或者“guarded devirtualization”。&lt;/p&gt;&lt;p&gt;GCC具体采用的做法是“function-based guarded devirtualization”，正如上面例子所演示的，它的“guard”其实还是从vtable读出了函数指针，只是读出来之后不马上去调用该函数指针，而是检查一下它是否跟预期的函数指针一致，如果一致则认为检查通过。乍一看这挺傻的，访问vtable的内存访问开销一点都没少，而且还多了个条件分支；如果能内联目标函数的话那可能还值得，否则的话这么做的好处就没多少了。&lt;/p&gt;&lt;p&gt;正因为这个优化并非总是值得的，GCC采用了很保守的策略，只在应该能提升性能的地方采用这种做法。一种情况是通过静态的类层次分析（CHA），发现一个虚函数调用点可能调用的目标函数只有1个可能性，那就生成上面所演示的“speculative devirtualized”代码，这种情况不需要profiling信息的支持。如果在做了该优化后，后续优化没能把目标函数内联进来或者至少从目标函数获取某些有利于优化的信息的话，则会撤销该优化，恢复回到普通的vtable间接调用。&lt;/p&gt;&lt;p&gt;上面演示的例子，之所以最开始的版本bar()还是用普通vtable调用而去掉Derived::bar()之后则变为“speculative devirtualized”调用，就是因为要满足上述保守策略的“只有1个可能调用的目标”的条件。&lt;/p&gt;&lt;p&gt;既然“只有1个可能调用目标”了，为啥不干脆去掉检查变为纯粹的直接调用（进而可能被内联），而要保留一个检查并在检查失败的分支中还去做普通vtable间接调用呢？&lt;/p&gt;&lt;p&gt;这主要是因为对C++程序不一点总是能做真正完备的“全程序分析”——假如碰上共享库/动态链接库，这些库里的类层次状况只能当黑盒子看待，所以总得留下一条退路给类层次分析错误的时候还能正确执行程序。&lt;/p&gt;&lt;p&gt;==================================&lt;/p&gt;&lt;p&gt;GCC选择的guard形式并非唯一的可能性。这种形式的guard在JVM里也有研究和应用，例如说IBM的JVM就有过这种形式的devirtualization。&lt;/p&gt;&lt;p&gt;但HotSpot VM没有使用这种形式的guard。HotSpot VM如果选择做guarded devirtualization的话，只会用type-based guarded devirtualization，也就是说guard检查的是被调用对象的类型，而不是目标方法的地址。&lt;/p&gt;&lt;p&gt;Type-based与function-/method-based的guard各有取舍。前者开销更小，而后者可处理的情况更多。&lt;/p&gt;&lt;p&gt;还是用本文开头的例子，如果是type-based，就可能会生成这样的代码：（还是伪代码）&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;// this-&amp;gt;bar()
if (this-&amp;gt;_vptr == vtable_of(Derived)) {
  // inlined Derived::bar()
  tmp = 256;
} else {
  this-&amp;gt;_vptr[BAR_VTABLE_INDEX](); // normal indirect virtual call
}&lt;/code&gt;&lt;p&gt;这个guard的形式显然比function-based的更轻一些，只要做一次间接读（读出_vptr字段来），而不像function-based版额外再读出bar的vtable entry出来。&lt;/p&gt;&lt;p&gt;但假如我们要调用foo()，它也是一个虚方法，但在Base与Derived中只有一个版本的实现，用type-based guard就得写成：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;if (this-&amp;gt;_vptr == vtable_of(Base) || this-&amp;gt;_vptr == vtable_of(Derived))&lt;/code&gt;&lt;p&gt;这就未必比function-based版好了。&lt;/p&gt;&lt;br&gt;&lt;p&gt;最后放个传送门：&lt;a href=&quot;https://www.zhihu.com/question/34846173/answer/60302017&quot; data-editable=&quot;true&quot; data-title=&quot;HotSpot VM有没有对invokeinterface指令的方法表搜索进行优化？ - RednaxelaFX 的回答&quot;&gt;HotSpot VM有没有对invokeinterface指令的方法表搜索进行优化？ - RednaxelaFX 的回答&lt;/a&gt;&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">23233548</guid>
<pubDate>Thu, 27 Oct 2016 16:54:38 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[新闻] IBM J9 JVM开源的消息正式宣布了——OpenJ9</title>
<link>https://zhuanlan.zhihu.com/p/22550958</link>
<description>昨天（2016-09-20 PDT）在旧金山举办的JavaOne上，IBM正式宣布了即将开源其J9 Java虚拟机的消息。开源版J9 VM的名字是：OpenJ9！&lt;p&gt;几天前这边才刚发&lt;a href=&quot;https://zhuanlan.zhihu.com/p/22506697?refer=hllvm&quot;&gt;OMR/TR终于开源的消息&lt;/a&gt;，这不，J9开源说来就来。&lt;br&gt;&lt;/p&gt;&lt;p&gt;相关资料：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;JavaOne的演讲：J9: Under the Hood of the Next Open Source JVM [CON3014]&lt;/li&gt;&lt;ul&gt;&lt;li&gt;可惜这个演讲没有录像，只有演示稿：&lt;a href=&quot;http://www.slideshare.net/DanHeidinga/j9-under-the-hood-of-the-next-open-source-jvm&quot; data-title=&quot;J9: Under the Hood of the Next Open Source JVM - SlideShare&quot; class=&quot;&quot;&gt;J9: Under the Hood of the Next Open Source JVM - SlideShare&lt;/a&gt;。链接是好的，打不开的话请自备…&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;br&gt;&lt;p&gt;根据演示稿所述，IBM目前的计划是跟随IBM Java 9一同正式发布OpenJ9。掐指一算，这大概就是明年这个时候了吧…&lt;/p&gt;&lt;p&gt;以后可以看到更多关于J9内部工作原理的资料了。怎能不一颗赛艇！&lt;/p&gt;&lt;p&gt;引用上述演示稿中的一页：&lt;/p&gt;&lt;img src=&quot;v2-f311880185afab21c28ac3d804def914.png&quot; data-rawwidth=&quot;2494&quot; data-rawheight=&quot;1402&quot;&gt;&lt;p&gt;&amp;lt;- 清晰地表明了未来OMR、OpenJ9与IBM J9之间的关系：OMR将是最上游，OpenJ9基于OMR构建出一个完整的JVM，OpenJ9 + OpenJDK Java Class Library构成一个完整的Java运行时环境，然后在此基础上添加IBM的特化功能最终构成IBM发行版J9及其配套库。&lt;br&gt;&lt;/p&gt;&lt;p&gt;这跟OpenJDK与Oracle JDK之间的关系基本上是同一个模型。&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">22550958</guid>
<pubDate>Wed, 21 Sep 2016 15:48:26 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[OMR/TR] Testarossa的IL设计（持续更新）</title>
<link>https://zhuanlan.zhihu.com/p/22508731</link>
<description>边读代码边更新的笔记。一开始肯定会有不准确的地方，慢慢逐步修正。欢迎吐槽和补充～&lt;p&gt;先写点我原本就知道的内容，后面再更新具体到OMR TR代码的知识点。本文涉及的OMR TR代码基于最初开源的版本：&lt;a href=&quot;https://github.com/eclipse/omr/commit/03874a48843df45292aa35086c5faf4fd83de264&quot; data-editable=&quot;true&quot; data-title=&quot;Initial contribution of compiler technology consisting of: · eclipse/omr@03874a4 · GitHub&quot; class=&quot;&quot;&gt;Initial contribution of compiler technology consisting of: · eclipse/omr@03874a4 · GitHub&lt;/a&gt;&lt;/p&gt;&lt;p&gt;上一篇文章 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/22506697?refer=hllvm&quot; data-editable=&quot;true&quot; data-title=&quot;[新闻] IBM/Eclipse OMR的编译器部分也已开源，以及IBM即将开源J9 VM - 编程语言与高级语言虚拟机杂谈（仮） - 知乎专栏&quot; class=&quot;&quot;&gt;[新闻] IBM/Eclipse OMR的编译器部分也已开源，以及IBM即将开源J9 VM - 编程语言与高级语言虚拟机杂谈（仮） - 知乎专栏&lt;/a&gt; 提到了OMR中的编译器组件——Testarossa（以下简称OMR TR）——也终于开源的新闻。这里就来看看OMR TR的中间表现形式（Intermediate Representation，IR）的设计是怎样的。&lt;br&gt;&lt;/p&gt;&lt;p&gt;OMR中的相关文档：&lt;a href=&quot;https://github.com/eclipse/omr/blob/master/doc/compiler/il/IntroToTrees.md&quot; data-editable=&quot;true&quot; data-title=&quot;omr/IntroToTrees.md at master · eclipse/omr · GitHub&quot; class=&quot;&quot;&gt;omr/IntroToTrees.md at master · eclipse/omr · GitHub&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;单一IR贯穿编译流程&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;OMR TR的IR叫做Testarossa IL（Intermediate Language），下面简称TR IL。&lt;br&gt;&lt;/p&gt;&lt;p&gt;Testarossa的整个编译流程中基本上都是使用同样结构的树形（DAG形）TR IL。包括从平台无关代码向平台相关代码lower，也是从平台无关TR IL转换为平台相关TR IL。大部分平台相关优化也在TR IL上做。有一个&lt;a href=&quot;https://github.com/eclipse/omr/blob/master/compiler/optimizer/GlobalRegisterAllocator.hpp&quot;&gt;全局寄存器分配器&lt;/a&gt;也是在TR IL上做的。&lt;/p&gt;&lt;p&gt;然后指令选择（instruction selection）会从TR IL生成出平台相关的Instruction对象，然后这层由Instruction对象构成的底层IR主要用于局部寄存器分配（local register allocation/assignment）、计算栈帧布局与最终的代码生成（codegen）；在z上还会做一次scheduling，而其它平台上基本上除了窥孔优化（peephole optimization）之外就不在Instruction层面上做什么别的优化了。&lt;/p&gt;&lt;p&gt;引用Testarossa编译器的创始人Kevin Stoodley大大以前&lt;a href=&quot;https://webdocs.cs.ualberta.ca/~amaral/IBM-Stoodley-talks/UofAKASWideAudience.pdf&quot; data-editable=&quot;true&quot; data-title=&quot;一个演讲&quot;&gt;一个演讲&lt;/a&gt;里对TR编译流程的介绍：&lt;/p&gt;&lt;img src=&quot;v2-ad5512a72f4e803b246af2314c897864.png&quot; data-rawwidth=&quot;1796&quot; data-rawheight=&quot;1386&quot;&gt;&lt;p&gt;这张图里的“Trees &amp;amp; CFG”就是本文所说的TR IL。&lt;/p&gt;&lt;br&gt;&lt;h2&gt;&lt;b&gt;树形IR（Tree IR） / DAG IR&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TR IL是一种颇为传统的树形IR（Tree IR），比一般编译器前端用的抽象语法树（AST）底层一些，而比完全拉直的线性IR要高层一些。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;相信熟悉&lt;a href=&quot;https://book.douban.com/subject/1886911/&quot; data-title=&quot;虎书系列&quot; class=&quot;&quot; data-editable=&quot;true&quot;&gt;虎书系列&lt;/a&gt;的同学会对这种IR比较熟悉（对应虎书第7、8两章内容）。&lt;/li&gt;&lt;li&gt;熟悉GCC IR的同学，TR IL跟GCC的GENERIC已经lower了控制流但尚未lower表达式树的GIMPLE比较相似。&lt;/li&gt;&lt;li&gt;熟悉LCC的同学，TR IL跟LCC中的DAG IR几乎是一样的东西。&lt;/li&gt;&lt;li&gt;熟悉HotSpot Client Compiler（C1）的同学，TR IL与早期的C1的IR设计相当相似。早期C1的设计可以参考2000年的论文：&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=674976&quot; data-editable=&quot;true&quot; data-title=&quot;A Compiler for the Java HotSpotTM Virtual Machine&quot;&gt;A Compiler for the Java HotSpotTM Virtual Machine&lt;/a&gt;&lt;/li&gt;&lt;li&gt;熟悉RyuJIT的同学，TR IL跟RyuJIT的Tree IR颇有相似之处。&lt;br&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;p&gt;TR IL比AST底层的地方在于：一般的AST设计会比较贴近源语言的语法结构，所以如果源语言有结构化控制流结构（if-then-else、while/for-loop等）的话，在AST里也会有直接对应的节点。而在一个典型的编译器后端用的树形IR中，控制流会被拆解为条件跳转与无条件跳转，树的形状会更贴近于底层控制流，而不再维持原本AST那种贴近源语言语法的层次结构。&lt;/p&gt;&lt;p&gt;TR IL比线性代码高层的地方在于：一般的线性代码跟机器语言比较贴近，就是一串线性执行的代码，没有所谓“语句”与“表达式”之分了——所有复杂（嵌套）表达式都被lower为一串使用临时变量的简单表达式。线性IR中的表达式大都可以用三地址代码直观地表示：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;dest = src1 op src2&lt;/code&gt;&lt;p&gt;&lt;b&gt;TR IL所使用的树形IR则仍然保持“语句”与“表达式”的区别。&lt;/b&gt;其中“语句”指的是可能有副作用的操作（例如变量赋值、函数调用等）或者是控制流跳转。语句不能嵌套，只能按顺序线性执行；换句话说，语句用于确定程序的执行顺序。而“表达式”则是纯粹的运算，没有副作用，没有控制流，可以嵌套。&lt;/p&gt;&lt;p&gt;常见的树形IR中“表达式”的若干重要特征是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;由于没有副作用与控制流，嵌套表达式的求值顺序可以任意决定，这给优化留下了自由度；&lt;/li&gt;&lt;li&gt;一个语句中的嵌套表达式的中间结果不会被别的语句中的表达式所看到。也就是说，一个语句中的表达式中间结果的生命周期仅限于该语句内，不会“泄漏”到别的语句中。这个特征对于某些非常简易的局部优化挺有帮助，例如&lt;a href=&quot;https://www.zhihu.com/question/29355187/answer/51935409&quot; data-editable=&quot;true&quot; data-title=&quot;这里&quot;&gt;这里&lt;/a&gt;提到的超简易寄存器分配算法。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不过就跟很多叫做“树形IR”但实际上却用的是有向无环图（DAG）的IR一样，&lt;b&gt;TR IL的表达式树实际上也是DAG而不总是真的树&lt;/b&gt;——表达式的中间运算结果在一个语句内可以被多个子表达式共享。像&lt;a href=&quot;http://rednaxelafx.iteye.com/blog/237822&quot; data-editable=&quot;true&quot; data-title=&quot;LINQ的Expression Tree虽然叫做树但骨子里也是DAG&quot;&gt;LINQ的Expression Tree虽然叫做树但骨子里也是DAG&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TR IL的DAG节点共享并不仅限制在一个“语句”中，而是在一个基本块或者扩展块中的语句都可以共享。&lt;/b&gt;这是DAG IR一种比较典型的做法。注意这与上面说的一般树形IR的表达式的“中间结果不会泄漏到别的语句”不一样。&lt;/p&gt;&lt;p&gt;TR IL的“语句”由&lt;a href=&quot;https://github.com/eclipse/omr/blob/master/compiler/il/OMRTreeTop.hpp&quot; data-editable=&quot;true&quot; data-title=&quot;TreeTop&quot;&gt;TreeTop&lt;/a&gt;表示。TreeTop是一个三元组：(TreeTop* prev, TreeTop* next, Node* node)，基本块里的一串TreeTop构成了指定程序执行顺序语义的双向链表。一个TreeTop节点下面挂的Node是这个语句里唯一一个可以有副作用的节点。这跟虎书第8章提到的canonical tree的设计非常相似。&lt;/p&gt;&lt;br&gt;&lt;h2&gt;&lt;b&gt;每个节点只能生成一个值&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TR IL的DAG节点，每个节点只能生成一个值。这对于大多数场景都够用。但有些特殊的平台支持，例如说一条div机器指令可能可以同时计算出商与余两个值，又比如说一条加法指令我们可能不但需要它的和，还想要它的进位（carry）值。要针对这些平台支持做优化，有些编译器会选择让IR支持某些节点生成多个值（或者说生成一个tuple然后用projection节点来提取tuple里的各个值）。&lt;/p&gt;&lt;p&gt;TR IL的设计则是坚守每个节点只生成一个值的设计。在遇到divmod、addwithcarry这样的需求时也还是用多个节点来分别表示那些原始操作，只是让优化器想办法识别出这些模式而把它们打包安排在相邻位置上。这个设计取舍是为了更容易保证构造IR时的正确性，而让优化器去解决性能问题。&lt;/p&gt;&lt;p&gt;参考文档：&lt;a href=&quot;https://github.com/eclipse/omr/blob/master/doc/compiler/il/ExtendingTrees.md#simplicity-&quot; data-editable=&quot;true&quot; data-title=&quot;Extending Trees - Simplicity&quot;&gt;Extending Trees - Simplicity&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;h2&gt;&lt;b&gt;双层IR——控制流图与数据操作&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TR IL是一种典型的双层IR，有单独一层控制流图（CFG）结构，由基本块（basic block）与控制流边构成；每个基本块代表一个最长的可线性执行的代码。基本块里是数据操作，也就是上一节提到的由“语句”和“表达式”构成的树形IR。&lt;/p&gt;&lt;p&gt;OMR TR所使用的基本块是“扩展基本块”（extended basic block）——函数调用以及其它潜在会抛出异常（有异常控制流）的IL指令并不结束一个基本块。&lt;/p&gt;&lt;p&gt;不仅如此，OMR TR在优化过程中还会进一步尝试把多个基本块粘合在一起，构成所谓的“扩展块”（extended block）——由多个原始基本块构成的单入口多出口（single-entry, multiple-exit）结构。这种扩展块结构也叫做&lt;a href=&quot;http://web.eecs.umich.edu/~mahlke/papers/1993/hwu_jsuper93.pdf&quot; data-editable=&quot;true&quot; data-title=&quot;superblock&quot;&gt;superblock&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;参考文档：&lt;a href=&quot;https://github.com/eclipse/omr/blob/master/doc/compiler/il/IntroToTrees.md#basic-blocks&quot; data-editable=&quot;true&quot; data-title=&quot;Intro To Trees - Basic Block&quot;&gt;Intro To Trees - Basic Block&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;h2&gt;&lt;b&gt;传统的IR——没有显式使用SSA形式&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TR IL相对于现代流行的编译器IR，有一个很有趣的“特点”，就是虽然它支持各种控制流/数据流分析和优化，但却没有使用直接嵌入在IR中的&lt;a href=&quot;https://en.wikipedia.org/wiki/Static_single_assignment_form&quot; data-editable=&quot;true&quot; data-title=&quot;SSA形式&quot;&gt;SSA形式&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;“取而代之”的是，TR IL里有TR_UseDefInfo这个辅助数据结构，用于记录IR中变量的use-def与def-use信息。本质上说它足以实现SSA形式所能实现的功能，只是没有把这个信息嵌入到IR里而已。&lt;/p&gt;&lt;p&gt;这个设计与Testarossa的血缘或许有很深的关系。正如前文所述，Testarossa最初的正式用途是作为J9 JVM配套的JIT编译器。而当时J9主要是针对嵌入式市场（Java ME）而开发的，配套的J9/TR自然必须严格考虑编译成本，不能做太重量级的分析与优化。后来J9逐步发展成熟，替代了IBM原本的桌面/服务器端JVM——Sovereign JVM——成为IBM JDK的唯一JVM，配套的J9/TR的功能也比以前大大丰富，单个编译器可进行不同优化级别的编译，以便支持J9的多层编译系统。&lt;/p&gt;&lt;p&gt;在最低优化级别的编译模式下，TR最主要的任务就是以最快速度从Java字节码生成出机器码，要构造SSA形式显然是太重量级了。而如果在高优化级别中为了深入做数据流分析而把IR转进一个单独的SSA形式版的TR IL，又会让IR的设计变得复杂：要么要支持两套IR，一套传统形式，一套SSA形式；要么要在同一套IR里支持传统模式与SSA模式。这两种用SSA形式的做法都有别的编译器使用，但TR选择了第三种也算常见的取舍：主IR里不直接携带use-def / def-use信息，而是在主IR之外用辅助数据结构来记录并跟踪这个信息。&lt;/p&gt;&lt;p&gt;TR IL里，TR_UseDefInfo是可选的辅助数据结构，只在需要做数据流分析/优化时才计算，可以很好地应对不同优化级别的不同需求。对应地，TR在做数据流分析时主要用的是传统的bitvector形式的分析。&lt;/p&gt;&lt;p&gt;说来，&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//book.douban.com/subject/2359859/&quot; class=&quot;&quot; data-editable=&quot;true&quot; data-title=&quot;《High-Performance Compilers for Parallel Computing》&quot;&gt;《High-Performance Compilers for Parallel Computing》&lt;/a&gt;一书的第6章，&quot;Scalar Analysis with Factored Use-Def Chains&quot;，把带有Factored Use-Def (FUD) Chain的IR与SSA形式的等价性介绍了一遍。此书作者Michael Wolfe对“SSA形式”这个叫法似乎没啥特别大的好感 &amp;gt;_&amp;lt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;（未完待续）&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">22508731</guid>
<pubDate>Mon, 19 Sep 2016 16:10:23 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[新闻] IBM/Eclipse OMR的编译器部分也已开源，以及IBM即将开源J9 VM</title>
<link>https://zhuanlan.zhihu.com/p/22506697</link>
<description>&lt;p&gt;OMR的组件的大类别中里最后一个重量级类别也终于来了：源自J9的JIT编译器“Testarossa”（J9/TR）的编译器架构：&lt;/p&gt;&lt;blockquote&gt;&lt;a href=&quot;https://github.com/eclipse/omr/commit/03874a48843df45292aa35086c5faf4fd83de264&quot; data-editable=&quot;true&quot; data-title=&quot;Initial contribution of compiler technology consisting of: · eclipse/omr@03874a4 · GitHub&quot; class=&quot;&quot;&gt;Initial contribution of compiler technology consisting of: · eclipse/omr@03874a4 · GitHub&lt;br&gt;&lt;br&gt;&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;Commit message:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Initial contribution of compiler technology consisting of:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;high-level optimization technology featuring classic compiler optimizations, loop optimizations, control and data flow analyses, and support data structures&lt;br&gt;&lt;/li&gt;&lt;li&gt;code generation technology with deep platform exploitation for x86 (i386 and x86-64), Power, System Z, and ARM (32-bit)&lt;br&gt;&lt;/li&gt;&lt;li&gt;a robust, tree-based intermediate representation (or IL) and support code for producing IL from different method representations&lt;br&gt;&lt;/li&gt;&lt;li&gt;expressive tracing and logging infrastructure for problem determination&lt;br&gt;&lt;/li&gt;&lt;li&gt;JitBuilder technology to simplify the effort to integrate a JIT compiler into an existing language interpreter&lt;br&gt;&lt;/li&gt;&lt;li&gt;a framework for constructing language-agnostic unit tests for compiler technology&lt;br&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p&gt;OMR编译器部分的说明：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/eclipse/omr/blob/master/compiler/README.md&quot; data-editable=&quot;true&quot; data-title=&quot;omr/README.md at master · eclipse/omr · GitHub&quot;&gt;omr/README.md at master · eclipse/omr · GitHub&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;后续会在OMR里开源的都是各个大类别（GC、compiler、threading、diagnostic等）下的一些具体功能，而没有别的大类别还没开出来了。&lt;/p&gt;&lt;p&gt;Exciting！&lt;/p&gt;&lt;p&gt;可能会有不熟悉Testarossa的同学说：这个编译器开源出来跟我有毛关系，这不是个JVM里的JIT编译器么？&lt;/p&gt;&lt;p&gt;呵呵，它可不只是个JIT编译器。其实Kevin Stoodley大大最初提出Testarossa项目的时候，是想要成为IBM XL编译器套件（C/C++/Fortran等）的一个中间优化器（大概是想替代TPO？）。但是生不逢时，一开始没能被XL编译器青睐，却正好碰上IBM开始做J9 JVM，就摇身一变成为了J9的御用JIT编译器。后来它还被用在了许多不同的场景中，例如编译C/C++的Static Testarossa（sTR，曾在Linux/z上部署过）、用于优化legacy COBOL代码性能的二进制翻译/优化器，等等。这是个相当通用的编译器架构，就算对OMR的其它组件不感兴趣，Testarossa也可以单独拿出来用的。所以如果想自己写个编译器来玩，后端的选择除了LLVM、libgccjit、&lt;a href=&quot;http://microvm.github.io/&quot; data-editable=&quot;true&quot; data-title=&quot;The Mu Micro &quot; class=&quot;&quot;&gt;MicroVM&lt;/a&gt;、&lt;a href=&quot;http://c9x.me/compile/&quot; data-editable=&quot;true&quot; data-title=&quot;QBE&quot; class=&quot;&quot;&gt;QBE&lt;/a&gt;之类之外，这OMR TR也是个新选择。&lt;/p&gt;&lt;p&gt;不过当然，Testarossa的代码还是可以看出它最初的正式用途是作为J9 VM配套的编译器的这个历史。例如说，请看OMR Testarossa IL默认的opcode：&lt;a href=&quot;https://github.com/eclipse/omr/blob/master/compiler/il/OMRILOpCodesEnum.hpp&quot; data-editable=&quot;true&quot; data-title=&quot;omr/OMRILOpCodesEnum.hpp at master · eclipse/omr · GitHub&quot; class=&quot;&quot;&gt;omr/OMRILOpCodesEnum.hpp at master · eclipse/omr · GitHub&lt;/a&gt;，拿它跟JVM的字节码来对比一下，看看名字是不是非常的相似——OMR TR IL的opcode就像是JVM字节码的扩展版一样，在功能相同的地方名字也是一样的。&lt;/p&gt;&lt;p&gt;对OMR TR的IR设计感兴趣的同学，请跳传送门：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/22508731&quot;&gt;[OMR/TR] Testarossa的IL设计 - 编程语言与高级语言虚拟机杂谈（仮） - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;说来，把一个老项目开源还真是改进代码质量 / 代码风格的一个好的动力来源。Testarossa的代码还没重构完，但组织决定让它尽快先放出来给大家瞄一眼。代码里使用 TR:: 命名空间的类型是已经被重构到的代码，而在全局命名空间但有 TR_ 前缀的类型则是尚未被重构（至少尚未被重命名）的代码。IBM还在继续重构中，尽量把Testarossa的代码风格从以前基本上就是C with Classes的风格改进为比较现代的C++风格；它自己带的一些数据结构库也将尽量被替换为STL的对应物。&lt;/p&gt;&lt;p&gt;==================================================&lt;/p&gt;&lt;p&gt;另外，IBM已经计划好在今年接下来的JavaOne上宣布IBM J9 VM的开源。看来OMR的开源还真是J9开源的一个敲门砖。以前我问Mark Stoodley说如果有人基于OMR写了个JVM的话会怎样，他还说：那很好啊，IBM不会介意的，如果有好想法的话可能还会取回到J9里去用；这不，J9自己干脆也决定要开源了。&lt;/p&gt;&lt;p&gt;今年的JVMLS上我问Mark说显然有不少在J9里已有的功能在OMR里尚未开放，例如说J9/TR自身支持的dependency-based speculative optimization，这方面有怎样的计划。他提到确实有不少功能因为还没想好如何抽象出来给外界使用，所以还没从J9剥离出来放到OMR里。但是他们会很欢迎外界贡献者帮忙从J9中把功能打捞到OMR去 &amp;gt;_&amp;lt;&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">22506697</guid>
<pubDate>Mon, 19 Sep 2016 13:57:57 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[新闻] Android Runtime（ART）的一些新动态，2016-08</title>
<link>https://zhuanlan.zhihu.com/p/22253472</link>
<description>ART Optimizing Compiler终于也忍不住添加了图着色寄存器分配器：&lt;p&gt;&lt;a href=&quot;https://android.googlesource.com/platform/art/+log/master/compiler/optimizing/register_allocator_graph_color.h&quot; data-editable=&quot;true&quot; data-title=&quot;googlesource.com 的页面&quot; class=&quot;&quot;&gt;compiler/optimizing/register_allocator_graph_color.h&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;这有意思啊。勇于承担更长时间的编译么。&lt;/p&gt;&lt;br&gt;&lt;p&gt;然后ART的Concurrent Copying GC近来的变化也值得关注。它有一种新的read barrier type，以前没在别的地方见过的：它会在对象头上使用一个bit来记录该对象里的引用类型字段在dereference的时候是否需要经过read barrier。这做法挺新奇的。效果是不是真的好另论，总之先学习一下这个思路的来龙去脉总是件趣事。&lt;/p&gt;&lt;br&gt;&lt;p&gt;话说之前一个关于&lt;a href=&quot;https://zhuanlan.zhihu.com/p/20569303&quot; data-editable=&quot;true&quot; data-title=&quot;ART又要考虑用基于LLVM的编译器了… - 编程语言与高级语言虚拟机杂谈（仮） - 知乎专栏&quot; class=&quot;&quot;&gt;ART又要考虑用基于LLVM的编译器&lt;/a&gt;的小道消息果然是假的么。隔了那么久并没有收到真的有这方面动静的消息。&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">22253472</guid>
<pubDate>Wed, 31 Aug 2016 15:23:52 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>架构最快最好的To JS编译器</title>
<link>https://zhuanlan.zhihu.com/p/22216448</link>
<description>自己从事&lt;a href=&quot;https://github.com/bloomberg/bucklescript&quot; data-editable=&quot;true&quot; data-title=&quot;BuckleScript&quot; class=&quot;&quot;&gt;BuckleScript&lt;/a&gt; 的编译器的开发已有近一年， 下周即将发布1.0，这里面有太多故事可以写了，知乎第一篇文章献给它。&lt;p&gt;虽然BuckleScript 才马上到1.0， 但是它已经被一些公司所采用，比如它已经被Facebook的某些产品用到了。自己也在和著名的ReactJS/ReactNative的作者Jordan 合作希望能推出 Reason On React (Powered by BuckleScript) 希望这能够给BuckleScript 带来killer app. 而BuckleScript 本身的编译器是用OCaml 写得，可以被编译成汇编和JS本身（压缩后大小700KB), 用户们可以自己感受下它的编译速度, Try here: &lt;a href=&quot;http://bloomberg.github.io/bucklescript/js-demo/&quot; data-editable=&quot;true&quot; data-title=&quot;OCaml to Javascript transpiler playground&quot;&gt;OCaml to Javascript transpiler playground&lt;/a&gt; 注意汇编的版本比JS的版本还要快一个数量级。&lt;/p&gt;&lt;p&gt;BuckleScript 早期是我的个人项目：因为注意到 现在软件行业--从互联网行业到传统软件领域--有一个很明显趋势: Javascript platform，&lt;a href=&quot;https://www.youtube.com/watch?v=jFU-wc28lF4&quot; data-title=&quot;这个唯一的跨平台语言正在吞噬着所有软件领域&quot; class=&quot;&quot; data-editable=&quot;true&quot;&gt;这个唯一的跨平台语言正在吞噬着所有软件领域&lt;/a&gt;（因为mobile的崛起Java 已经不再是一个跨平台语言了)：&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;浏览器已经不再只是deliver 内容的一个平台，越来越多的应用程序开始通过浏览器直接deploy，像上面提到的BuckleScript playground 整个工业级别的编译器直接跑在浏览器上 这甚至在5年前都是不可想象的。&lt;/li&gt;&lt;li&gt;Google最近主推的&lt;a href=&quot;https://developers.google.com/web/progressive-web-apps/&quot; data-editable=&quot;true&quot; data-title=&quot;Progressive Web APP&quot; class=&quot;&quot;&gt;Progressive Web APP&lt;/a&gt; 将会给浏览器带来更强大的API. 而最新的&lt;a href=&quot;https://webassembly.github.io/&quot; data-editable=&quot;true&quot; data-title=&quot;Web Assembly 标准&quot;&gt;Web Assembly 标准&lt;/a&gt; 将会使得JavaScript 平台可以覆盖更多的领域：比如传统的数值计算领域。WASM相当于给JavaScript 提供了一个接入native平台的FFI, JavaScript 作为这个平台的胶水语言毫无疑问有着最多的机会。&lt;/li&gt;&lt;li&gt;JavaScript 平台已经不再局限于浏览器， 相反它已经开始反噬， 开始入侵其它领域 最有名的是&lt;a href=&quot;https://nodejs.org/en/&quot; data-editable=&quot;true&quot; data-title=&quot;NodeJS&quot;&gt;NodeJS&lt;/a&gt;, &lt;a href=&quot;http://electron.atom.io/&quot; data-editable=&quot;true&quot; data-title=&quot;Electron&quot;&gt;Electron&lt;/a&gt;, &lt;a href=&quot;http://johnny-five.io/&quot; data-editable=&quot;true&quot; data-title=&quot;IoT&quot;&gt;IoT&lt;/a&gt; 等&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;p&gt;为什么要自己写一个这样的编译器呢? 虽然JavaScript平台很诱人，但是“动态语言难于构建大型程序” 基本上已经是业界共识，一旦程序规模上来了，基本上就只能Write Only. 作者所在的公司有上千万行JS, 维护起来基本上就是噩梦，在原来的Hack上添加新的if else Hack。而工业界真正有工业强度而且和JavaScript 交互良好的的编译器是微软的typescript 编译器，接下来就展开说下为什么BuckleScript 比typescript 更快更好。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;更好的平台拓展性：BuckleScript 不是一个新的语言，它是把一个已经存在将近30年的语言OCaml编译成可读的JavaScript. 而OCaml本身对很多平台存在native 的后端支持。像go一样, OCaml可以编译出汇编代码到iOS,Android, Windows,Linux, MacOS。而typescript只有JavaScript 一个后端，拥抱JavaScript 并不代表我们就要抛弃native 平台，当我们需要更快更可靠的性能的时候，我们可以有更多的选择，比如做工具链的时候: typescript 的编译器同样也是用typescript写得可以跑在浏览器里也可以泡在node上，但是它跑在node上得时候就比BuckleScript编译成汇编跑慢不止一个数量级。&lt;br&gt;&lt;/li&gt;&lt;li&gt;更好的类型安全: typescript是一个JS的超集，它存在很多历史包袱。而微软引入typescript更多的是作为一个工具来使用的比如IDE的代码补全，相对安全的代码重构。而这个类型的准确从第一天开始就不是它的设计初衷，以至于Facebook自己设计了一个相对更准确地类型系统&lt;a href=&quot;https://github.com/facebook/flow&quot; data-editable=&quot;true&quot; data-title=&quot;Flow&quot;&gt;Flow&lt;/a&gt;. 而OCaml的类型系统是已经被形式化的证明过正确的。也就是说从理论上BuckleScript 能够保证一旦编译通过是不会有运行时候类型错误的，而typescript远远做不到这点。&lt;/li&gt;&lt;li&gt;更多的类型推断，更好的语言特性：用过typescript的人都知道，typescript的类型推断很弱，基本上所有参数都需要显示的标注类型。不光是这点，像对函数式编程的支持，高阶类型系统GADT的支持几乎是没有。而OCaml本身是一个比Elm,PureScript还要强大的多的语言，它自身有一个非常高阶的module system，是为数不多的对dependent type提供支持的语言，polymorphic variant。而且pattern match的编译器也是优化过的。&lt;/li&gt;&lt;li&gt;程序优化，代码删除。BuckleScript不只是一个编译器更是一个optimizing compiler: 它做过的优化有: Code motion, Purity analysis, Cross module inliner, Constant folding/propagation, partial evaluation Strength reduction, escape analysis。我们做的benchmark显示同样的immutable data structure 比如&lt;a href=&quot;https://facebook.github.io/immutable-js/&quot; data-editable=&quot;true&quot; data-title=&quot;facebook immutablejs&quot;&gt;facebook immutablejs&lt;/a&gt;, BuckleScript的实现有时候要快两到三倍不止。而相比之下typescript编译器并不会做任何优化工作。&lt;/li&gt;&lt;/ol&gt;&lt;br&gt;&lt;p&gt;因为自己接触到的专业术语都是英文的，作者试着尽可能用中文表述，可能翻译过来的中文不太准确，尽请谅解, 接下来我还会写几篇文章讲讲它的底层设计，如果读者能够读到这里, 还请在github上友情支援一下 : )。&lt;/p&gt;&lt;p&gt;小时候读韩愈的《马说》， 不太理解这句话 “世有伯乐， 然后有千里马，千里马常有，而伯乐不常有”。 长大以后慢慢的对这句话才真的理解，真的要好好感谢一路过来给我无限指导和关怀的老师/老板们，我也庆幸自己很幸运，自己的每一任老师或者老板 ，不管自己做什么，都能够得到你们的理解和支持。&lt;/p&gt;</description>
<author>张宏波</author>
<guid isPermaLink="false">22216448</guid>
<pubDate>Mon, 29 Aug 2016 04:18:25 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>为什么Python里面的locals()是只读的</title>
<link>https://zhuanlan.zhihu.com/p/21815224</link>
<description>Python里面的各个名字空间都可以抽象成一个dictionary, 比如函数的本地变量就可以通过build-in函数locals()来取得。但是很多资料都提到通过locals()取得的dictionary是只读的，比较好奇为什么会有这个限制。下面是一个点单的对locals()的调用 （在CPython 2.7下运行得到）:&lt;code lang=&quot;python&quot;&gt;&amp;gt;&amp;gt;&amp;gt; def foo(a):
...   return locals()
...
&amp;gt;&amp;gt;&amp;gt; dis.dis(foo)
  2           0 LOAD_GLOBAL              0 (locals)
              3 CALL_FUNCTION            0
              6 RETURN_VALUE
&lt;/code&gt;&lt;p&gt;-- 补充，按R大提到的，CPython的local variable都是放在frame的localplus数组里面，而locals()返回的是dictionary对象，通过这个dictionary对象不能直接修改localplus上的值也是很直观的。&lt;/p&gt;&lt;p&gt;locals在global空间(LOAD_GLOBAL), 这个build-in方法最终在bltinmodule.c里面实现如下：&lt;/p&gt;&lt;code lang=&quot;c&quot;&gt;static PyObject *
builtin_locals(PyObject *self)
{
    PyObject *d;

    d = PyEval_GetLocals();
    Py_XINCREF(d);
    return d;
}
&lt;/code&gt;&lt;p&gt;主要是转到ceval.c的PyEval_GetLocals()上：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;PyObject *
PyEval_GetLocals(void)
{
    PyFrameObject *current_frame = PyEval_GetFrame();
    if (current_frame == NULL)
        return NULL;
    PyFrame_FastToLocals(current_frame);
    return current_frame-&amp;gt;f_locals;
}
&lt;/code&gt;&lt;p&gt;又转到frameobject.c里的PyFrame_FastToLocals(PyFrameObject *f)上。不考虑错误和cellvar的处理等，主要部分如下：&lt;/p&gt;&lt;code lang=&quot;c&quot;&gt;PyFrame_FastToLocals(PyFrameObject *f)
{
    /* Merge fast locals into f-&amp;gt;f_locals */
    PyObject *locals, *map;
    PyObject **fast;
    PyCodeObject *co;
    Py_ssize_t j;
    locals = f-&amp;gt;f_locals;
    if (locals == NULL) {
        locals = f-&amp;gt;f_locals = PyDict_New();
    }
    co = f-&amp;gt;f_code;

    map = co-&amp;gt;co_varnames;
    fast = f-&amp;gt;f_localsplus;
    j = PyTuple_GET_SIZE(map);
    if (co-&amp;gt;co_nlocals)
        map_to_dict(map, j, locals, fast, 0);
&lt;/code&gt;&lt;p&gt;最主要的map_to_dict（同在frameobject.c）就会把存在f-&amp;gt;localsplus里面的local variable (所有的local variable name在co-&amp;gt;varnames里面）放到locals所指向的dictionary, 也同时放在了当前frame里（f-&amp;gt;locals）。所有的local variable很自然成为一个名字空间放进dictionary，这里放进数组风格的f_localsplus里面是为了不用每次使用local variable都查找dictionary。可以搜索此变量名获得更多信息。&lt;/p&gt;&lt;code lang=&quot;c&quot;&gt;static void
map_to_dict(PyObject *map, Py_ssize_t nmap, PyObject *dict, PyObject **values,
            int deref)
{
    Py_ssize_t j;
    for (j = nmap; --j &amp;gt;= 0; ) {
        PyObject *key = PyTuple_GET_ITEM(map, j);
        PyObject *value = values[j];
        if (deref) {
            value = PyCell_GET(value);
        }
        if (value == NULL) {
            if (PyObject_DelItem(dict, key) != 0)
                PyErr_Clear();
        }
        else {
            if (PyObject_SetItem(dict, key, value) != 0)
                PyErr_Clear();
        }
    }
}
&lt;/code&gt;&lt;p&gt;上面的map_to_dict会遍历所有的local variable names, 如果这个variable指向了Python对象则把variable name和对象放进要返回的dictionary对象(f-&amp;gt;f_locals)，这也就意味着每次对locals()的调用都会把frame object里面的dictionary (f_locals)的所有variable name到object的映射根据当前状态刷新，就相当于给所有的local vars照相（snapshot）。这样就能比较容易理解为什么对locals()返回的dictionary是无效的的，因为直接写入这个dictionary只会影响dictionary自身而不会反映到当前frame的f_localsplus，每次调用locals()又会刷新要返回的dictionary内容。下面的例子可以帮助理解这点。&lt;/p&gt;&lt;code lang=&quot;c&quot;&gt;def f():
    x = 10
    lc = locals()
    lc[&#39;x&#39;] = 20
    # &#39;x&#39;-&amp;gt;20 remains on dictionary before locals() is called
    print lc
    # {&#39;x&#39;: 20}                 
    locals()
    # locals dictionary is refreshed in the above call to locals()
    print lc
    # {&#39;x&#39;: 10, &#39;lc&#39;: {...}}     

f()&lt;/code&gt;&lt;p&gt;&lt;a href=&quot;https://docs.python.org/2/library/functions.html#locals&quot; data-title=&quot;CPython&quot; class=&quot;&quot; data-editable=&quot;true&quot;&gt;CPython&lt;/a&gt;官网对locals()的主要描述如下，也说明返回的dictionary只是代表了local symbol table, 并不能等价使用（修改）。&lt;/p&gt;&lt;blockquote&gt;Update and return a dictionary representing the current local symbol table&lt;/blockquote&gt;</description>
<author>Thomson</author>
<guid isPermaLink="false">21815224</guid>
<pubDate>Mon, 01 Aug 2016 15:09:37 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[新闻] ChakraCore已支持运行在Linux上</title>
<link>https://zhuanlan.zhihu.com/p/21825477</link>
<description>&lt;p&gt;上周刚announce的&lt;a href=&quot;https://blogs.windows.com/msedgedev/2016/07/27/chakracore-on-linux-osx/&quot; data-title=&quot;消息&quot; class=&quot;&quot;&gt;消息&lt;/a&gt;，CharakCore已经能运行在Linux和OSX 10.9+上。目前能运行的是interpreter（pass了绝大部分tests），JIT和concurrent GC还正在进行中。同时node-chakracore也更新了，能运行在Linux上。&lt;/p&gt;</description>
<author>Thomson</author>
<guid isPermaLink="false">21825477</guid>
<pubDate>Tue, 02 Aug 2016 04:26:18 +0800</pubDate>
<media:thumbnail url="" />
</item>
<item>
<title>[题外] 技术演进与代码工人</title>
<link>https://zhuanlan.zhihu.com/p/21916716</link>
<description>&lt;p&gt;娱乐一下。&lt;/p&gt;上周在开JVMLS，有机会跟很多同行大佬们聊天。其中听说的一个好玩的想法是：现在在软件开发行业有大量低端职位是不断在做重复开发，重复的低质量开发。然而这样的代码还是会被部署到生产环境，成为许多软件产品的重要组成部分。&lt;p&gt;让机器完全替代人类来写所有代码显然还不是近期能实现的。但如果我们能容忍一些不那么重要（或者或许本来应该重要）的程序是低端程序员造出来的低质量轮子，那能不能让机器来替代人类做好这部分？据说像Gilad Bracha、Erik Meijer等大牛都转向研究机器学习，目标之一就是让机器能部分代替人类写代码。多有趣。&lt;/p&gt;&lt;p&gt;这种东西真能成的话，以后就越来越不需要现在的这种低端码农了吧。就像在机械化、自动化生产线上，越来越不需要低端的人类手工劳作，而是需要高端技工去管理那些机器一样。&lt;/p&gt;&lt;p&gt;虽然不是啥新闻，但突然听说业界的前辈（特别是同做JVM以及其它managed language研发的前辈们）真的投身去做这种研究，还是不免觉得机器写代码离现实又近了一步。&lt;/p&gt;&lt;p&gt;觉得把写代码当作生产线比喻不恰当的同学，你们或许没有见识过真正的低端码农的工作环境和内容。那货真价实就是个人肉生产线，一堆人不断的重复写着一样的代码去实现略微变化的功能。这些生产线与现代软件工程的良好实践基本无缘。正好有同学开过公司做网游，听他们说起这种工作方式的时候我不禁打寒颤。虽然不好，但这样的事情现在也还大量存在。&lt;/p&gt;&lt;p&gt;（Lars Bak之前带Dart团队，后来不直接带团队了而是到处去推销Dart。现在半退休状态的他具体在干嘛了呢？&lt;/p&gt;&lt;p&gt;Erik Meijer虽然还在带Hack团队，完善Hack的类型系统的更新设计，但据说他也在涉及机器学习方向想减少人肉重复堆代码的必要性。这个好玩。）&lt;/p&gt;</description>
<author>RednaxelaFX</author>
<guid isPermaLink="false">21916716</guid>
<pubDate>Mon, 08 Aug 2016 11:33:22 +0800</pubDate>
<media:thumbnail url="" />
</item>
</channel>
</rss>
